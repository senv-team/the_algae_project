{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8ba54a-7297-4ccc-ba4f-880efccd8dda",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb1939e-4dd1-46d0-ba17-b10c6eb1f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor  # Use RandomForestClassifier for classification\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84bd3e5-4388-4ff8-a737-e1871cd945a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a8789c-319d-4217-8265-2ccb4bc67dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Example: Generate some synthetic data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 30\n",
    "    n_features = 12\n",
    "\n",
    "    # Create a DataFrame with random features\n",
    "    input_features = pd.DataFrame(np.random.randn(n_samples, n_features), columns=[f'feature_{i}' for i in range(n_features)])\n",
    "    # Generate a continuous target variable (for regression)\n",
    "\n",
    "    doy_label = np.random.randn(n_samples) * 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d757c-a3e4-4095-950b-5b2e8ac65805",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c5e63e2-422a-4d2d-9ba4-bf9aaf591a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "   year  DJF  JFM  FMA  MAM  AMJ  MJJ  JJA  JAS  ASO  SON  OND  NDJ\n",
      "0  1950 -1.5 -1.3 -1.2 -1.2 -1.1 -0.9 -0.5 -0.4 -0.4 -0.4 -0.6 -0.8\n",
      "1  1951 -0.8 -0.5 -0.2  0.2  0.4  0.6  0.7  0.9  1.0  1.2  1.0  0.8\n",
      "2  1952  0.5  0.4  0.3  0.3  0.2  0.0 -0.1  0.0  0.2  0.1  0.0  0.1\n",
      "3  1953  0.4  0.6  0.6  0.7  0.8  0.8  0.7  0.7  0.8  0.8  0.8  0.8\n",
      "4  1954  0.8  0.5  0.0 -0.4 -0.5 -0.5 -0.6 -0.8 -0.9 -0.8 -0.7 -0.7\n",
      "after\n",
      "   ONI_AMJ_prev  ONI_MJJ_prev  ONI_JJA_prev  ONI_JAS_prev  ONI_ASO_prev  \\\n",
      "0          -1.1          -0.9          -0.5          -0.4          -0.4   \n",
      "1           0.4           0.6           0.7           0.9           1.0   \n",
      "2           0.2           0.0          -0.1           0.0           0.2   \n",
      "3           0.8           0.8           0.7           0.7           0.8   \n",
      "4          -0.5          -0.5          -0.6          -0.8          -0.9   \n",
      "\n",
      "   ONI_SON_prev  ONI_OND_prev  ONI_NDJ_prev  year  ONI_DJF  \n",
      "0          -0.4          -0.6          -0.8  1951     -0.8  \n",
      "1           1.2           1.0           0.8  1952      0.5  \n",
      "2           0.1           0.0           0.1  1953      0.4  \n",
      "3           0.8           0.8           0.8  1954      0.8  \n",
      "4          -0.8          -0.7          -0.7  1955     -0.7  \n"
     ]
    }
   ],
   "source": [
    "df_feature_ONI = pd.read_csv('../../datasets/csv/ONI_data.csv')\n",
    "df_feature_ONI = df_feature_ONI.rename(columns={'Year': 'year'})\n",
    "\n",
    "print(\"before\")\n",
    "print(df_feature_ONI.head())\n",
    "\n",
    "df_before_amj = df_feature_ONI.iloc[:, 1:2]  # From DJF\n",
    "df_before_amj.columns = [\"ONI_\" + col for col in df_before_amj.columns]\n",
    "df_before_amj[\"year\"] = df_feature_ONI[\"year\"]\n",
    "\n",
    "df_after_amj = df_feature_ONI.iloc[:, 5:]   # From AMJ to NDJ (after AMJ)\n",
    "df_after_amj.columns = [\"ONI_\" + col + '_prev' for col in df_after_amj.columns]\n",
    "df_after_amj[\"year\"] = df_feature_ONI[\"year\"] + 1 # Increment the year for the second part (starting from AMJ)\n",
    "\n",
    "\n",
    "\n",
    "df_feature_ONI = pd.merge(df_after_amj, df_before_amj, on='year', how='inner').dropna()\n",
    "\n",
    "print(\"after\")\n",
    "print(df_feature_ONI.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cd95cc0-bb4c-426f-9cd4-fe73806b2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  doy_cherry_peak_bloom\n",
      "0  1953                    146\n",
      "1  1954                    139\n",
      "2  1955                    140\n",
      "3  1956                    134\n",
      "4  1959                    127\n"
     ]
    }
   ],
   "source": [
    "# Replace 'filename.csv' with the path to your CSV file\n",
    "df_label = pd.read_csv('../../datasets/csv/cherry/doy_cherry_peak_bloom_Japan_Abashiri.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7aedd79-a9a1-41d2-8c88-9b4af1ac841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and remove rows with missing values\n",
    "merged_df = pd.merge(df_label, df_feature_ONI, on='year', how='inner').dropna()\n",
    "\n",
    "# Split back into two DataFrames without 'ID'\n",
    "df_label = merged_df[['doy_cherry_peak_bloom']]\n",
    "df_feature_ONI = merged_df.drop(columns=['doy_cherry_peak_bloom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f158237-9080-4912-bd7b-035409b09d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "            51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_ONI.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85d2e728-ec0b-4363-ac3d-b0e5b88796db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ONI_AMJ_prev</th>\n",
       "      <th>ONI_MJJ_prev</th>\n",
       "      <th>ONI_JJA_prev</th>\n",
       "      <th>ONI_JAS_prev</th>\n",
       "      <th>ONI_ASO_prev</th>\n",
       "      <th>ONI_SON_prev</th>\n",
       "      <th>ONI_OND_prev</th>\n",
       "      <th>ONI_NDJ_prev</th>\n",
       "      <th>ONI_DJF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1953</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  ONI_AMJ_prev  ONI_MJJ_prev  ONI_JJA_prev  ONI_JAS_prev  ONI_ASO_prev  \\\n",
       "0  1953           0.2           0.0          -0.1           0.0           0.2   \n",
       "1  1954           0.8           0.8           0.7           0.7           0.8   \n",
       "2  1955          -0.5          -0.5          -0.6          -0.8          -0.9   \n",
       "3  1956          -0.8          -0.7          -0.7          -0.7          -1.1   \n",
       "4  1959           0.7           0.6           0.6           0.4           0.4   \n",
       "\n",
       "   ONI_SON_prev  ONI_OND_prev  ONI_NDJ_prev  ONI_DJF  \n",
       "0           0.1           0.0           0.1      0.4  \n",
       "1           0.8           0.8           0.8      0.8  \n",
       "2          -0.8          -0.7          -0.7     -0.7  \n",
       "3          -1.4          -1.7          -1.5     -1.1  \n",
       "4           0.4           0.5           0.6      0.6  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_ONI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545f98d-f359-4062-b169-8e92f5b0dac8",
   "metadata": {},
   "source": [
    "## eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b2e5ce0-b238-4e5d-b2c6-237f22b53adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAIzCAYAAACA+nNIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd3gUVdvH8e9uNr1tOpDQew+9d0QERbE8imJHAcEKCIqijwXsFcFeEB/LC4ICoii99yK9lwTSKyFls7vvH4sLa8AWyW6S3+e6csnO3DN7z3E2mzP3mTOGrKwsOyIiIiIiIiJySRndnYCIiIiIiIhIZaAOuIiIiIiIiEgZUAdcREREREREpAyoAy4iIiIiIiJSBtQBFxERERERESkD6oCLiIiIiIiIlAF1wEVERERERETKgDrgIiIiIiIiUimtXr2am266icaNG2M2m/niiy/+dJtdu3YxYMAAqlSpQuPGjXnxxRex2+1/6f3UARcREREREZFKKS8vjyZNmvDCCy/g7+//p/E5OTkMHjyY6OholixZwgsvvMDbb7/N1KlT/9L7mUqbsIiIiIiIiEh51K9fP/r16wfAfffd96fx//d//0d+fj7Tp0/H39+fJk2asH//fqZNm8bo0aMxGAx/uL0q4CIiIiIiIiJ/wYYNG+jUqZNLtbxPnz6cOnWKY8eO/en2qoD/y0JDQ92dgoiIiIiIVDLZ2dnuTuFfsSqy/SXbd9e0DaXeR0pKCtWqVXNZFhUV5VxXq1atP9xeHfBLYIF3Q3enUC4NtOwD4Mp7drs5k/Jp/gdNALjijh1uzqR8WvhpCwD63FT6X8yV1eKvHF+YfYdscnMm5dMvX7YFoOf1a92cSfm0bFYnQOffP/Xb+Xf57dvcm0g59dNn8QB0H7zKvYmUYyvmdAWg61XL3ZxJ+bRqXg93pyB/kTrgIiIiIiIi4hEM3n98D7W7RUdHk5qa6rLst9fR0dF/ur3uARcRERERERH5C9q3b8/atWspKChwLlu6dClVq1alZs2af7q9OuAiIiIiIiLiEYwmwyX7uZDTp0+zY8cOduzYgc1mIyEhgR07dnDixAkA/vvf/zJo0CBn/PXXX4+/vz/33Xcfu3fv5vvvv+eNN97gvvvu+9MZ0EEdcBEREREREamktm7dSvfu3enevTv5+flMmTKF7t27M3nyZACSkpI4cuSIMz40NJQ5c+Zw6tQpevXqxbhx4xg1ahSjR4/+S++ne8BFRERERETEIxi8y7ZG3K1bN7Kysi66fvr06SWWNW3alIULF/6j91MFXERERERERKQMqAIuIiIiIiIiHuFi92pXFKqAi4iIiIiIiJQBVcBFRERERETEI3j6c8BLSx1wERERERER8Qgagi4iIiIiIiIipaYKuIiIiIiIiHiEij4EXRVwERERERERkTKgCriIiIiIiIh4BN0DLiIiIiIiIiKlpgq4iIiIiIiIeASDlyrgIiIiIiIiIlJKqoBXEC0+mEz0gJ4UpaSzotVVF4xp8vpEovv3wJpfwPa7J5CzdTcAsbdeQ/3HRgJwYMp0Ej+fW1Zpe5x7b4qhbfNgCotsvPHJSQ4dLygRU7eGHw/fWQ0fHyObfs3l/a+SAQgKMDJ+eBwxEd4kp1t44b0E8s7YyvoQ3GrELdVo18LRfq9+mMChY/klYurV9OeRYXH4+hjZuCOXd784CcDdN1alQ3wwxcV2TqUU8dpHJypd+426vQYdWpkpLLTx0vTDHDh6pkRM/doBPDqyDr4+RtZvzeKdz467rL9hYBVG3FqDwfdsISe3uKxS9wijbq9O+/hQCotsvDT9KAcv1n4jauHjY2TDtmze+ewEAHfcUI3Obc3YbJCVY+Hld4+Snmkp60Nwu/vvqkXHVmEUFFl5YeohDhzJKxHToE4gE0bVw9fHyLqtmbz98VGX9f+5qir33V6Lq+/cSLbOwRIxOgcvbuQtsbRvGUJBkY1XPzjOwQt9h9TyZ+ywGvj6GNmwPYfpXyQCMOzGanSMD8FitXMqpZBXPzxB3hlrWR+CWz1wdx06tgmjsNDGlLf3s//whT+/jz/QAB8fI+s2Z/LWR4ed664dUJXBV1TFZrOzdnMm7844WobZu9+D99alU5sICgqtTH5zH/sPnS4R07BuEI8/1BBfHy/Wbk7nzfcPOdddd2U1rh0Yi81mZ83GDKZ/erjE9vLXGFUBl/Ig4bNv2XDlsIuuj+rfncB6tVjWuB+/jnySZlOfBsA7LJQGT4xmdZf/sKrzDTR4YjQmc0gZZe1Z2jYLolq0L/dOPMjUz09x3y1VLxg3amhV3v78FPdOPEi1aF/aNAsC4IYrItm+J497nzjE9j153HBFZFmm73btWgRTLcaHu8fv461PExl9W+wF40bfHstbnyZy9/h9VIvxoW3zYAC27sxlxMT93PfkARKTCrlxYHRZpu927eNDiavqx20P7eC1D47w4LBaF4x76O5avPb+EW57aAdxVf1oHx/qXBcV4UObFqEkpxaWUdaeo318KLFV/Lj94Z28/sExHry7xgXjHryrJq99cIzbH95JbBU/2rV0/L77Zn4S947fzYjHdrNuSzZDr73w578i69DKTFxVP265fyuvvnuYh++tfcG4h++pwyvvHuKW+7c6zsFWZue6qAgf2rY0k6RzUOfg39SuRTCxVXy589E9vPnJCe6/Pe6CcQ/cHscbn5zgzkf3EFvFl7YtHN8hW3blcu/EvYx8Yh+JSYXcdGXl+g7p2DqMuGp+3HzfZl6efpBHhte7YNyYEfV4adpBbr5vM3HV/OjQOgyAVs1C6do+grse3srtD27lq+8SyzJ9t+vYJpzq1QK4afgGXn5nP2NH1r9g3Jj76vPS1P3cNHwD1asF0LFNOACtmpvp1iGSO+7fxK2jNvHlnBNlmb6UM+qAl4LV6jlXVjNWbcKSkX3R9TGD+pA4cy4AWeu34x0agm+VKKL6dSV18WosmdkUZ+WQung10Zd3K6OsPUuH+GCWrMsCYN/hfAIDjISFug4SCQs14e9nZN9hx1X5Jeuy6Bgf7Nx+8VrH/4PFa7OdyyuLjq1CWLw6C4C9h84QFOB1wfYL8Dey95CjKrR4dRadWjv++Nyy6zS2swXvvYfOEBnuXWa5e4IubcNYtCINgD0H8wgK8CLc7NoG4WZvAvy92HPQUdVYtCKNLm3DnOvvu60G739xHHvZpe0xOrcx8/PKdOC39jNdpP2Mzvb7eWW6s/3O5J8bbeHvZ6QyNmKXduH8tCwVgN0HTl+0DQMDvNh9wFEZ+mlZKl3bhTvXj76jFu99fgzsla8BdQ6WTqfWofyyOgNwfAcEBngR/rvvkPBQEwF+Xs7vkF9WZ9C5teMi5Jaduc7vkD2HzhAZVrm+Q7q2D+enpSkA7N6fS1CgFxG/a4OIMMd3yO79uQD8tDSFbu0dn9+r+1fhi29PYCl2nHhZ2ZVr9EW3jhH8uCQJgF37cgkKNBER5uMSExHmQ2CAiV37HO3345IkunWMAGDwgKrMnHW80rbfv81gNFyyH09QaYagP//884SFhXHfffcB8OyzzxIZGYnFYmHOnDkUFhZy5ZVX8vjjjwNw8803k5iYSGFhISNGjOCOO+4AIDY2ljvuuINly5bxyiuv0KlTJ3cd0t/iVy2G/IQk5+uCxCT8YmPwqxZDwYnzlick41ctxh0pul1EmIm0jHO/MNMzi4kwm8jMPjeEMsJschkSmJ5ZTESY42NkDjkXm5ldjDmk0ny8AMcXe1pGkfN1WmYRkWHeLu0XGebt0sZpmUVEhJlL7Ktf93CWr8+6lOl6nMhwH1LTz7VfakYRkeE+ZGRZXGPOb+OzMeD44z8to4jDx0sO2awMIsO9L9B+3r9rP9fzLzW9yOVCz53/ieWy7hHknbEy9tl9ZZO4B4mKKHkORkW4noOOmMISMQBd2oWRmlHEoWMlh11XBjoHSycyzJvU9PO+HzIsRIR5k3H+d3CYN2mZrjEX6mhf3i2c5RuyLmm+niYywpeU88+/9CIiw31d/maJDPd1PUfTi4iM8AWgejV/WjQJ5Z5balFksTHt0yPsPVhyCHZFFRnhS0raud9tKemFREb4kJ5ZdF6MD6nnx6Sd334BtGgayr231qbQYuOdjw+z90Bu2R1ABWPwqtg14op9dOcZOnQoX331FQA2m43Zs2cTExPDoUOHWLJkCatWrWL79u2sXr0agHfeeYfly5ezdOlS3nvvPTIyHFdl8/LyaNu2LatXry43nW9xk0pWvfi33HRVNFarnaVrs9ydSrnh62Pk5sHV+PSbyjVk8N/2yTeJ3Dx6B0tWp3P15ZVr+Gpp+foYueXaWD75WsMuS0PnYOkNuSoGq83OkjWZ7k6lXPHyMhASZGLE+O1M/+wI/x3byN0plSuO9vPm3rFbmfbxYZ4Z39jdKYkHqzQlupo1axIeHs727dtJTU2lRYsWbNmyhSVLltCtm2PIdV5eHocOHaJLly68++67zJ8/H4DExEQOHTpEeHg4Xl5eDBo0yJ2H8o8UnEzGP64Kv30d+cVWoSAxmYKTyYT3aO+M84uLIWP5Bvck6QYDe4ZxeXfH8L8DR/LPViIcFcSIMBPpWa4TCKVnFbsM6YoIM5Ge6YjJyikmLNRRBQ8LNZFVCSYfurJPBP17OIav7T9y5mw11lH9igzzcalUAKRlWlyqPZFhPi5X5/t2DaN9y2Aee6lyTFxydb9oBvSOAmDfoTxnJREgKtzHZUQBOCreUeHnYiLPxlSL8aVKlC/vv9TMue27U5oyauJuMivwMLhBl0U522//4Qu13+/OvwzX8y8qomQMwOJVGTw/vj4zZp28RJl7jmv6x3BlH8eop72HTpdow/OrZeComEWdrficH1Otih9Vo/346JUWjuURvrz/UgtGPvarSwW4otE5WDpX9Ynkih6OIbz7j5whKsIbDjjWRYZ7l5iELj3TteIdGe5aEb+sazjt40OY8OLBS5+8Bxh8RVWuvOzs5/fgaaLPP/8ifEjLcJ2LIS2j0PUcjfAh7eyIltS0IlasO3sLxYHT2Ox2QkNMZOdU3L9lrh1Qjasud8y1sOdALtGR5363RUf4kva7339p6UVEnR8TeX77FbJ8bZpzX3YbmEO8ycqpuL//LqWKPglbpemAA9x2223873//IyUlhaFDh7J8+XIeeeQR7rzzTpe4lStXsnz5cn7++WcCAgIYOHAgBQWO2bD9/Pzw8vJyR/qlkjJvCTXvG8rJrxdg7tCS4pxcCpNSSV20iobPPuKceC2qb1f2TXzNzdmWnQXLMlmwzHFZom3zIK7sFc6KDTk0rOPPmXyby/BpcAwtzy+w0bCOP/sO59O7o5n5SxyjI9Zvz6VPp1Bm/ZhOn06hrN9W8YcezV+czvzFji/sdi2DuapPBMvXZ9GobgB5+dYLtt+ZfBuN6gaw99AZ+nQxM+8Xx/ZtmgdxwxVRPPrCIQqLKsfwge8WpfDdIsc9ex1ahXLN5TEsXZNB43qB5J2xlui4ZGRZOJNvpXG9QPYczKNf90jm/JjMkRP5XD98qzPui7dbMvLxXRV+FvTvf07l+58d9yx3aBXK1f2i/0L72Zztd1m3COb+5Gj/2Cq+JCY5/pDq3NbMiZOVYyj/3B+Tmfuj40kOHVubGXxFFZasTqdJ/aCLtmHeGStN6gex+8BpLu8Zxbc/JHHk+BkG373JGffVtFYMH/9rhZ8FXedg6cxbnMa8xY5OS/uWIQzqG8mydY7vkDP5Vpfh5wAZ2cWcKbA6v0P6dgnnu7Pt37Z5MDcMiGbclAOV5jtkzsJTzFl4CoCObcK4dkBVFq9Ko0mDYPLOWC94AeNMvpUmDYLZvT+Xy3tF8+0Cx/YrN6TTqnkoW3dmE1fND2+TsUJ3vgG+/eEk3/7guMjVqW04110Zyy8rUmnaMJjTZ4pdhp8DpGcWkXemmKYNg9m1L5f+vaswa55j5NmKdWm0bmFm669ZVK/mj8lkUOdbLqpSdcCvvPJKJk+ejMVi4cMPP8RkMvH8889zww03EBQUxMmTJ/H29iYnJ4fQ0FACAgLYv38/mzZt+vOdu1n8568S0aM9PpFh9D6ynAPPvI3B2/G/9/j7X5GycDlRV/Sg596fsebns2OY4153S2Y2ByZPo+vaWQAceP4dLJkXn8ytItv062naNg/ig+frOR5D9um5ysNbk+rwwDOOquy0L045HkPmbWTzztNs2um4R2rWwnQmDI+jX1czKWcfQ1aZbNyeS7sWwXz8UkMKCm28/tG545/6TH1GT3KUNd6Zkcgjw6rj62Ng445cNu5wXKi4b2gs3iYDz4+rAzgm4Zn6WeUZUr1+azYd4s18/mYLCgptvPzuEee6915oyvAJuwB48+NjPDqytuMRPNuy2bCtcn5ef2/91mzax4cy441mFBbaePm9o851705pwojHHI9dfOuTY4wbURtfHwMbtuU422/YTXHEVfPDbreTnFrEGx8dc8dhuNW6LVl0aB3GF1NbUVho48Vp56qIH77cgmHjdgDwxoeHmTCqnuMxWluzWL81y00Zexadg6WzYXsO7VoE88nLjSkstPHqh+cesTjtmYbcN8lxT/zbnyUw9p4ajkeB7shxfoeMujUOb5OBKeMcs3/vPZTHW59Vnu/hdZsz6dQmjC+ntzn7GLIDznUfvRbP3Y9sA+C19w7x2AP1HY+y3JLJui2OIsQPi5OZMLo+n77ZimKLnclv7XfHYbjN2k0ZdGobztfvt3c+huw3n7zZhjsf3AzAq9MPMPGhRo7HMG7OYN1mRxFmwS9JPPZAQ2ZMbYul2Mbzb1SuORz+bZ4yWdqlYsjKyqoclwnPevjhhwkNDeXpp58GYPr06Xz++ecABAYG8v7771OtWjVuueUWjh8/Tr169cjOzmbChAl069aN2NhYEhMv3ikIDQ1lgXfDsjiUCmegxfHL6sp7drs5k/Jp/gdNALjijh1uzqR8WvipY+hsn5sqzy0Y/7bFXzluZ+k7xPMvWnqiX75sC0DP69e6OZPyadksx7wsOv/+md/Ov8tv3+beRMqpnz6LB6D74FXuTaQcWzGnKwBdr1ru5kzKp1XzepCdXTEuyu/t3++S7bvRj4su2b7/qkpVAbfZbGzcuJHPPvvMuWzkyJGMHDmyROysWbMuuI8/6nyLiIiIiIjIP1fR7wGvNLOg7927l1atWtGjRw/q1q3r7nRERERERESkkqk0FfBGjRqxfft2d6chIiIiIiIiF2Go4BXwStMBFxEREREREc9mMFbsQdoV++hEREREREREPIQq4CIiIiIiIuIRKvpjyFQBFxERERERESkDqoCLiIiIiIiIR9BjyERERERERESk1FQBFxEREREREY+ge8BFREREREREpNRUARcRERERERGPoOeAi4iIiIiIiEipqQIuIiIiIiIiHqGi3wOuDriIiIiIiIh4BD2GTERERERERERKTRVwERERERER8QgVfQi6KuAiIiIiIiIiZcCQlZVld3cSFUloaKi7UxARERERkUomOzvb3Sn8K07edf0l23e1j2ddsn3/VaqAi4iIiIiIiJQB3QN+CVx5z253p1Auzf+gCQALvBu6OZPyaaBlHwCbe3VxcyblU5ulqwFIf+ZeN2dSfkVMeh+AgtmvuzmT8snvuocBOLP8KzdnUj4F9LgJgNPr57k5k/IpqMNVAORuWODmTMqn4PYDAZ1/pfHbOZi35ls3Z1I+BXa+1t0p/Gt0D7iIiIiIiIiIlJoq4CIiIiIiIuIRVAEXERERERERkVJTBVxEREREREQ8QkWvgKsDLiIiIiIiIh7BYKzYg7Qr9tGJiIiIiIiIeAhVwEVERERERMQjGL0q9hB0VcBFREREREREyoAq4CIiIiIiIuIRKvokbKqAi4iIiIiIiJQBVcBFRERERETEI2gWdBEREREREREpNVXARURERERExCNU9HvA1QEXERERERERj1DRO+Aagi4iIiIiIiJSBlQBFxEREREREY+gSdhEREREREREpNRUAa9g7r0phrbNgykssvHGJyc5dLygREzdGn48fGc1fHyMbPo1l/e/SgYgKMDI+OFxxER4k5xu4YX3Esg7YyvrQ3CLFh9MJnpAT4pS0lnR6qoLxjR5fSLR/XtgzS9g+90TyNm6G4DYW6+h/mMjATgwZTqJn88tq7Q9Ski7DlQf/RB4GUlbMI/kL2e6rPeJiaHmo49jCjVjzc3hyPPPYElLxScmhrrPTAGjEYPJRMq3s0ibN9ctx+BO3nWbEnj5jWA0UrB1FQWrf3RZH9DvP3jXagiAwdsHQ2AwmS895FjX51q86zcHIH/FAop2byrT3D3B6v3HeXH+amw2O4PbNebuHq1KxPy04yDvLt4MBmhYJYIXbuoLwOsL17Ji33Hsdjsd68Ux/souGAwV+/6z31u98wAvf70Qm83ONV1bc9cV3UrELNq0k3fnLcMANKhehSnDrgdg1Jufs+NwAq3q1eCt+28p28Q9yJode3ll5ndYbTau6dGBO6/q7bL++5UbefOr+USHhQLwn75dGNyzAwBvfT2fVdv2ADDs6svo1zG+THP3BGt27OGVz+dis9m4pmdH7riqj8v6eSs28OZX886132VduaZnRwDe/HIeq7fvxma306FpA8beOrjSfYZ1/pXO6l/38cr/5mO12RjcvR13DuxZImbRhh28993is78DqzJ5xE0AzFu1mQ/nLQVg2FW9uKprmzLMvGKq6PeAqwNegbRtFkS1aF/unXiQhnX8ue+WqoyZcqRE3KihVXn781PsO5zP0w/UoE2zIDbvPM0NV0SyfU8es35M5/r+EdxwRSSfzk5xw5GUvYTPvuXotJnEf/ziBddH9e9OYL1aLGvcD3OHljSb+jRruvwH77BQGjwxmlUdr8Nut9Nt/bckz1tCcVZOGR+BmxmN1HhwDPvHPYQlNYVG735I9ppVFBw76gyJGzGa9EU/kvHTQoJbtSb2nhEcnfIslvR09o4ejt1iwejnT5NPPid7zSos6WnuO56yZjAQeMXN5Mx8HVtOJqHDHseybzvWtFPOkDOLvnH+269dL7yq1ADAu35zvKrWIPu9Z8FkIvS2sVgO7sReVPLiW0VltdmY/P0q3rvrSmJCArl52rf0bFSTujHhzphjaVl8tHwrn424hhB/X9JP5wOw7VgS244lMeuBGwC4473v2HTkJO3qxLrlWNzBarPxwv8WMP3h24gJC+GWye/To2VD6laLdsYcS07n44Ur+fTRuwkJ9Ccj57Rz3W39ulBQZGH2isp34ec3VpuNF2bMYdqj9xITHsqtT71Jj9ZNqBNbxSWuX4eWjL/tWpdlK7ftZu/RRP733CNYiou5d/J0OrdsRJC/X1kegltZbTZe/Oxb3hk/gpjwUG6b9DrdWzct0X6XdYhn/O3XuSzbvv8I2w8c4cvJ4wAY9uzbbN57iLaN65VZ/u6m8690rDYbL37+PdPG3k1MeAhDn3mHHvGNqRMb44w5npTGJwuW8cnjI1x+B2afPsP73y9m5qTRGAwGbvnv2/Ro1YSQQH93HY6UA/9oCHpiYiJDhgyhdevWxMfHM378eIqKili5ciVms5mFCxc6Y2+88UZWrlwJwMCBA9m6desf7nvHjh2YzWZ++eUXl+Vms5l7773X+bq4uJi6dety4403AvDFF18wbty4f3I4FUaH+GCWrMsCYN/hfAIDjISFul5jCQs14e9nZN9hxx+fS9Zl0TE+2Ln94rXZACxem+1cXhlkrNqEJSP7outjBvUhceZcALLWb8c7NATfKlFE9etK6uLVWDKzKc7KIXXxaqIvL1k5qugCGzWm4GQCRadOYi8uJnPJYsxdXNvBr1ZtcrdsBiB36xbnentxMXaLBQCDj3elq1oAmGJrY81MwZaVBjYrhbs24t2w5UXjfZq1p2jXBgC8IqtSfOwA2G1gKaI4JQHvek3LKnWPsDMhheoRIcSFh+Bt8qJ/i7os23PUJebbjXu4qWMzQvx9AYgIcvxxZDBAYbEVi9VGUbGVYpuNiKCAsj4Et9p5JJHq0eHERYXjbTJxebtmLNu+1yVmzsrN/Kdne+cfleEhQc51HRrXIdDPp0xz9jS7Dh2nenQEcdEReJtM9OsYz7Itu/7StkcSk2nVsA4mLy/8fX2pX70aa3bs/fMNK5Bdh45TPSbyvPZrxfLNO//StgaDgSJLMZbiYiyWYoqtViJCKs/fL6Dzr7R2Hj5BXHQEcdFnfwe2b8myrXtcYr5dsZH/9O5U4nfg2p376dCkPqFBAYQE+tOhSX3W/LqvzI+hojEYjZfsxxP87Szsdju33norAwcOZMuWLWzevJm8vDyeffZZAGJjY3n11Vf/cUKzZ8+mU6dOzJo1y2V5YGAgu3fvJj/f0XFcunQpVatW/cfvcyHFxcX/6v7KWkSYibQMi/N1emYxEWbXDniE2UR65u9iwhwx5hATmdmONsjMLsYcogESv/GrFkN+QpLzdUFiEn6xMfhVi6HgxHnLE5LxqxZzoV1UaN6RUVhSzo2WKEpNwTsyyiUm/9ABwrr3AMDcrQdegYF4hYQ4to+KpvGHn9Hi6zkkffVF5ap+A8ZgM7bsDOdrW04WXsFhF44NDcfLHInliOMPJGvy2Q63yQeDfxDetRpiDAm/4LYVVUp2HlVCz3UIo0ODSM7Jc4k5lpbNsbQsbn93DkOnf8vq/ccBaFmjCu3qxNJ3ygz6TvmczvXjqBN94bavqFKycogJD3W+jjGHkpqZ6xJzLDmd48np3PHih9w25QNW7zxQ1ml6tJTMbGIizM7XMeFmUjNLXtRdvPFXbpz4Ko++/RlJ6VkA1K9RjbW/7iO/sIjM3Dw27TlIckZW2STuIVIys4kJNztfR4ebSblA+y3ZuIObHn+ZR9/6lKT0TABa1K9F28b16H//01x+/9N0bN6I2rGV63tY51/ppGbmUOW834HR4SElzr/jSWkcS07jzuff5bZnp7H6bCc75XfbxoSHkJJZyUZByt/2tzvgK1aswNfXl6FDhwLg5eXF5MmTmTlzJvn5+TRr1oyQkBCWLl36t5Ox2+3MnTuXadOmsWzZMgoKXIdQ9uvXj0WLFgEwa9Ysrr/++r+875EjR/Lwww/Ts2dP2rRpw48/Ou6v/OKLL7jpppu46qqrGDRoEHl5eYwaNYrevXvTrVs3FixYAEDfvn3Zs+fc1bC/Us0v9+zuTkAqkoTp7xDUohWN3/+EoJbxFKWmgNUxx4AlNYU9w25n59Abieh3BaawytUB+jt8mrajcM9msDs+oJbDu7Ec2EnoXeMJum4YxQmHHdVwcVFss3EsPZsP7xnECzf25b9zlpOTX8jx9GyOpGayaPyt/DzhVjYcOsmWI6f+fIeVjNVm43hKOh+MuZMp91zPs59/T+6ZfHenVa50j2/C/Ncm8vXzY+jQtAFPvf8lAJ2aN6RLy0bc9exUJk6bSfN6NfEyeEaVxpN0a9WUea8/yVeTx9GhWQOefs/RfieSUzlyMpkf3nyKhW89xabdB9i677Cbs/U8Ov9Kp9hm5URyGu+Pv4cpI27iuU/m6HfgpWQwXLofD/C3P2F79uwhPj7eZVlISAhxcXEcPuz4hTdmzBhefvnlv53M+vXrqVmzJrVr16Zr16789NNPLuuvvfZaZs+eTUFBAbt27aJNm783ycHx48dZsmQJ33zzDY888oizg79jxw5mzJjBDz/8wKuvvkr37t1ZsmQJ8+bNY9KkSeTl5TF48GDmzJkDQFJSEsnJybRqVXKSn7I2sGcYb02qw1uT6pCZVUxkuLdzXUSYifQs16p+elYxEWG/i8l0xGTlFDuHrIeFmsjKLd8jAv5NBSeT8Y87dy+VX2wVChKTKTiZjF/185bHxVBwMtkdKbqVJS0V7+hz94v6REVjSUt1jUlP4/BTj7Pn3js5+eH7AFjzTpeIyT96mKDmFx9+XRHZcrMwhp6rWhtDzFhzMy8Y69u0HUU7N7gsy1/1A9nvP0vuzDcAsKZXrnMwOjSQpOxz51JK9mliQgJdYmJCg+jZuBbeXl7EhYdQM8LM8fRsluw6QvPqMQT4ehPg602XBtXZft6olsog2hxC8nm34CRnZRMV5jqENzoshB4tG+Ft8iI2MoyaMREcT8n4/a4qreiwUJLPVhQBkjOyiAoLdYkxBwfi4+34jr2mZwf2HE10rrt7UF++fO4Rpo0fjt0ONaq6jiCq6KLDQl2qrikZWc7Jwn7j2n4d2XM0AYClm36leb2aBPj5EuDnS+cWjdhx4GhZpe4RdP6VTlRYCEnn/Q5Mycgpcf7FhIXSPb6x43dgVDg1qkRyPCmN6N9tm5yRQ3RYSJnlLuXTJbnE1aVLFwDWrl37t7abPXs2113nmFzjt872+Zo1a8bx48eZNWsW/fr1+9t5XXPNNRiNRurWrUvNmjXZv38/AD179iTsbMVtyZIlvPHGG3Tt2pUrr7ySwsJCEhISGDx4MN9//z0Ac+bM4eqrr/7b738pLFiWyQPPHOaBZw6zdlsuvTuaAWhYx58z+TbnkPLfZGYXk19go2Edxz0svTuaWb/NMdRw/fZc+nRy/MLp0ynUuVwgZd4SYodeA4C5Q0uKc3IpTEolddEqovp2xWQOwWQOIapvV1IXrXJvsm6Qt3cvfrFx+FSpisFkIqx3H7LWuLaDV0io88pjlVtuJW2hY3SJd2QUBh/H/aNeQcEENWtBwYnjZXsAblaceBSv8GiM5ggweuHbtB2W/dtLxBkjqmDwD3BUuX9jMGDwd3Q2vaJj8YqJw3Jod1ml7hGaxkZzPC2bhIwcLMVWftxxiB6Na7nE9G5Si02HTwKQmZfPsfQs4sJDqGIOYvORkxRbbVisVjYfOUXtqMo1AqNprWocT8kgMS0TS3ExP23cSc+WjVxiesU3YtN+x6Sembl5HEtOJzaycrXTH2lSpzonktNITE3HUlzMonXb6NHKdS6G1PMm51y+ZRe1z05yZ7XZyMp13DJx4PhJDp44ScdmDcoueQ/QpE51TiSlkpjyW/ttpXvrZi4xaee134otO53tVyUijC17D1FstVJcbGXL3sPUrmS3gun8K52mteM4kZJGYmqG43fghu30aNXYJaZn6yZs3uv47s3MzeN4Uhqx0eF0ataAdbsOkJOXT05ePut2HaBTJWu/S8FgNFyyH0/wt2/ybdSoEd99953LspycHBISEqhTp45z6PnYsWN55ZVXMJn+2ltYrVa+//57fvjhB1555RXsdjuZmZnk5uYSHHzuSvwVV1zBk08+yfz588nI+HtX338/udNvrwMDz1VK7HY7M2bMoH79+iW2DwsLY+fOncyZM4fXXnvtb713Wdj062naNg/ig+frOR5D9ulJ57q3JtXhgWccvzimfXHK8RgybyObd55m005H5WjWwnQmDI+jX1czKWcfQ1ZZxH/+KhE92uMTGUbvI8s58MzbGM5eKT7+/lekLFxO1BU96Ln3Z6z5+ewY9jgAlsxsDkyeRte1jjkLDjz/DpYL3HdV4dmsHH/rdeq/9BoGoxdpC+dTcPQIVe8cxpl9e8les4rg+FbE3jMC7HZO79jO8Tcdc0X41axF3MjROO55MJD8zZcUHKlkwwftNvIWfknILQ+BwUjhttVYU0/h33MQxSePOTvjvs3aUbRro+u2Ri9C7nBMQGkvLOD0nI8q3RB0k5eRxwZ1ZeQnC7DZ7VzTpiH1YsJ55+eNNI2LomfjWnSuX501BxIY/PrXGI0GHu7fCXOAH5c1q8OGQ4lc/9Y3GDDQuUF1ev6u817Rmby8GD9kAPe98Tk2m42ru7SibrVopn23hCY1q9EzvhGdm9Zj7e5DXPvUVLwMBh66rh/ms5PV3fXSRxxJSiO/sIjLH32Vp26/ms5NK88M1OBow0dvG8zolz7Aardzdfd21I2rwvTZP9KkdnV6tG7KV4tWsWLrLryMRkKCAnj6HscjjIqLrQx7/h0AAv39eHbEzZi8vNx5OGXO5OXFuNuu5f6X38dqszGoe3vqxlXh3dkLaVy7Oj1aN+Orn1a4tt+9QwDo074lG3cf4KbHX8aAgU4tGtG9deWaiFLnX+mYvLwYf8sgRr36MTabnUHd2lI3Nobpc36mSa1YerRqQudmDVi38wDXTXzd8TvwxiswBzn6D8Ou6s3QZ6YCcM+g3oRWsok8LwVPmSztUjFkZWX9rTt97XY7vXr1Yvjw4QwZMgSr1crDDz9McHAw/fv3Z+rUqXz99dcA9OnTh+TkZKZPn063bt0YOHAgzz333AWHbi9ZsoSpU6fy7bffOpeNGDGCHj16MGTIEGJjY0lMTCQxMZF58+YxYsQIVq5c6Xy/L774gm3btl106PvIkSNJS0vj66+/5tixY85J5GbPnu2y3TPPPENubi4vvfQSBoOB7du307KlYzjsBx98wMaNG9mxYwfr1q274PuEhoZy5T2Vq/r0b5n/QRMAFng3dHMm5dNAi2NCkM29urg5k/KpzdLVAKQ/c++fRMrFRExy3FpQMPt1N2dSPvld9zAAZ5Z/5eZMyqeAHo4Oxen189ycSfkU1OEqAHI3LHBzJuVTcPuBgM6/0vjtHMxb8+2fRMqFBHa+luzsilEEynt6xCXbd+DT716yff9Vf/vygsFgYObMmcydO5fWrVvTpk0bfH19mTRpUonYMWPGkJDw16qos2bN4sorr3RZNmjQoBLD0GNjYxkxouT/FKvVio/PHz8GJS4ujt69e3P99dfz2muv4edX8hmH48aNw2Kx0KVLFzp27MjkyZOd666++mpmz57NNddc85eOSURERERERP46DUG/gLi4OGeV+3zdunWjW7dzz/4dMGAAWVlZzte/zSh+IdOmTSuxbMCAAQwYMABwPHv8j95vz5491K1b9w/z7tmzJ6+/7lqZueWWW7jlllucr/39/XnjjTcuuH10dDTp6el/+B4iIiIiIiIiF1IhHvR8/fXXU1RUxIQJE9ydioiIiIiIiPxDFf0ecLd0wPv06UNhYaHLsvfee4+mTf/ZpBmzZs1y/vuVV15h7ty5LuuvueYapk+f/o/2LSIiIiIiIvJvcEsHfPHixZds32PHjmXs2LGXbP8iIiIiIiJyaXjKvdqXSsWu74uIiIiIiIh4iApxD7iIiIiIiIiUf6qAi4iIiIiIiEipqQIuIiIiIiIinqGCz4JesY9OREREREREyg2DwXDJfv7Ihx9+SIsWLYiJiaFHjx6sWbPmD+P/7//+j65du1K1alUaNGjAvffeS3Jy8p8enzrgIiIiIiIiUml9++23TJgwgTFjxrBixQrat2/PDTfcwIkTJy4Yv27dOoYPH86QIUNYu3YtX3zxBXv37uWee+750/dSB1xEREREREQ8gsFovGQ/F/POO+9w8803c/vtt9OwYUNefvllYmJi+Pjjjy8Yv3HjRqpVq8aoUaOoVasW7dq1495772Xz5s1/enzqgIuIiIiIiEilVFRUxLZt2+jdu7fL8t69e7N+/foLbtOhQweSk5NZuHAhdrud9PR0vv32Wy677LI/fT9NwiYiIiIiIiIeoawfQ5aeno7VaiUqKspleVRUFCkpKRfcpn379nz00Ufce++95OfnU1xcTK9evZg+ffqfvp8q4CIiIiIiIiJ/0d69exk/fjzjxo1j2bJlzJ49m+TkZB566KE/3VYVcBEREREREfEMZfwYsoiICLy8vEhNTXVZnpqaSnR09AW3ee2112jdujUPPPAAAM2aNSMgIIArrriCSZMmERsbe9H3UwVcREREREREKiUfHx/i4+NZunSpy/KlS5fSoUOHC26Tn5+Pl5eXy7LfXttstj98P1XARURERERExCOU9T3gAKNGjWL48OG0adOGDh068PHHH5OUlMSdd94JwPDhwwF47733AOjfvz8PPvggH330EX369CEpKYnHHnuMli1bUr169T98L0NWVpb90h5O5RIaGuruFEREREREpJLJzs52dwr/CtvUCZds38bRL1x03Ycffsibb75JcnIyjRs3ZvLkyXTp0gWAgQMHArBgwQJn/Hvvvccnn3zCsWPHCAkJoXv37jz99NN/OPwc1AH/16kDLiIiIiIiZU0d8D/3Rx3wsqIh6JfAFXfscHcK5dLCT1sAsLlXFzdnUj61WboagAXeDd2cSfk00LIPgDVt27k5k/Kr86aNABy6baCbMymf6s5wXFVPmXiHexMpp6Kf/xSAzCn3uTeRcirssWkAZL042s2ZlE/m8VMByH75fjdnUn6FjnsbUBv+U7+1X4XghiHoZUmTsImIiIiIiIiUAVXARURERERExCMYyvgxZGWtYh+diIiIiIiIiIdQBVxEREREREQ8gjseQ1aWVAEXERERERERKQOqgIuIiIiIiIhnMFTsGnHFPjoRERERERERD6EKuIiIiIiIiHiES3kPuP2S7fmvUwdcREREREREPIMeQyYiIiIiIiIipaUKuIiIiIiIiHgEg6FiD0FXBVxERERERESkDKgCLiIiIiIiIp5B94CLiIiIiIiISGmpAi4iIiIiIiIe4VI+hswTqAIuIiIiIiIiUgZUAa9gRtxSjXYtgikssvHqhwkcOpZfIqZeTX8eGRaHr4+RjTtyefeLkwDcfWNVOsQHU1xs51RKEa99dIK8M7ayPgS3CWnXgeqjHwIvI2kL5pH85UyX9T4xMdR89HFMoWasuTkcef4ZLGmp+MTEUPeZKWA0YjCZSPl2Fmnz5rrlGNylxQeTiR7Qk6KUdFa0uuqCMU1en0h0/x5Y8wvYfvcEcrbuBiD21muo/9hIAA5MmU7i53PLKm2PYu7Uidpjx4DRSMrc70j87DOX9b5VqlB30iS8w8wU5+Rw4MlJFKWkANBp/TrOHDwEQGFyEnsfGVPm+bubf/M2RA69F4PRSM7yRWTN/z+X9aaIKKLveQRjYCAYjGR88ylndmwiqFNPzAOuc8b5VK9FwqQHKTp+uKwPwa186jcnaODNYDRSsGkFZ1YscFlvDA0n5Pp7MPgFYDAaOf3T/1G0fwcG/0BCbx6NKbY2BVtXcXrezIu8Q8VnqtOEgL43gNFA4bY1FK5b5LLev891mGo2AMDg7YMhIJjs18c61vUajHfdpmAwYjm6h/yf/6/E/is6U+3G+Pe5HoxGiravoXD9zy7r/Xpfi3cNR/vh7YMxIIjsNx91rOt5Nd51m4HBQPGRveQvnlXW6budqVZj/Ppc5ziHdqylcMPv2q/XtZhq1D8b7Gi/nLfH41W9Pv69r3XGGcNjODPvU4oP7ijL9N1O7edhDBW7RqwOeAXSrkUw1WJ8uHv8PhrVDWD0bbE8/OzBEnGjb4/lrU8T2XvoDM88Uou2zYPZ9GsuW3fm8sn/ncJmg7tuqMKNA6P5+P+S3HAkbmA0UuPBMewf9xCW1BQavfsh2WtWUXDsqDMkbsRo0hf9SMZPCwlu1ZrYe0ZwdMqzWNLT2Tt6OHaLBaOfP00++ZzsNauwpKe573jKWMJn33J02kziP37xguuj+ncnsF4tljXuh7lDS5pNfZo1Xf6Dd1goDZ4YzaqO12G32+m2/luS5y2hOCunjI/AzYxG6ox/lF2jRlOUnEyLGZ+RsWIF+UeOOENqPvQgqQsWkLpgASFt21Jj9CgOTnoKAFthIdtvucVd2bufwUjUbSM5+dITFGekEfff18nbsg7LyRPOkLBBN3F6w0pylvyAd7XqVB3zX46PuYvTa5dxeu0yAHzialLlwScrXecbg4Hgq24l85OXseVkEDbyKQr3bMWaetIZEthrEIW/biB/w1K8oqphvv0R0l8Zi73YQt4v3+IVE4cpJtaNB+FmBgMB/W7k9FdvYcvJIviO8VgO7MCWfu47NH/xbOe/fdv0xCsmDgCv2DqY4uqQ89HzAATfOgZTjfoUHz9QtsfgTgYD/pf9h7yvp2LLzSL49nFYDv7q0n4FS76l4Oy/fVr3OK/9amOKrUPux5MBCLrlEUzV61N8onK1n99lN5D3zTvYc7MIunUclkO/a7+l3zr/7dOqu7P9rCcOcPozx3e3wS+AoGGTKD66p2zzdze1n+fREPQ/l5iYyJAhQ2jdujXx8fGMHz+eoqIiVq5cidlsZuHChc7YG2+8kZUrVwIwcOBAtm7detH9Nm/enCuuuMJlWdeuXenUqRMAK1eu5MYbbwTgiy++YNy4cf/G4ZRbHVuFsHh1FgB7D50hKMCLsFDXayxhoSYC/I3sPXQGgMWrs+jUOgSALbtOYztb8N576AyR4d5llru7BTZqTMHJBIpOncReXEzmksWYu3RzifGrVZvcLZsByN26xbneXlyM3WIBwODjfUmfXeipMlZtwpKRfdH1MYP6kDhzLgBZ67fjHRqCb5Uoovp1JXXxaiyZ2RRn5ZC6eDXRl3e76H4qqqCmTck/cYLCxETsxcWkLfqZ8B49XGICatche9MmAHI2bSK8e3d3pOqRfOs2wJJykuLUJLAWc3rdCgJbd3SJsdvtGP0DADAGBGLNyiixn6COPTi9fkWZ5OxJTHF1KM5IxpaZClYrhTvW49u4lWuQ3Y7B1x8Ag58/tpxMx3JLEZZjB+Ds78DKyqtaLWyZqdiy0sFmxbJnMz4NWl403qdJW4p2bzr7yg5e3uBlcvwYvbDl5ZZN4h7Cq2otbFlp2LId7Ve0Zwve9VtcNN6nSRssexzfx9gB0+/a70zluojrVbUmtsw07Gfbz7J3M971ml803rvxee13HlODeIqP7IbiyvV5VvtJWSt1B9xut3PrrbcycOBAtmzZwubNm8nLy+PZZ58FIDY2lldfffUf7z83N5eEhAQA9u3bV9p0/1BxcfEl3f+lFhHmTVpGkfN1WmYRkWGunejIMG/SMiwuMRFhJTva/bqHs3FH5fkDwDsyCsvZ4bwARakpeEdGucTkHzpAWHdHp8jcrQdegYF4hTguXnhHRdP4w89o8fUckr76olJVv/8Kv2ox5CecdyU5MQm/2Bj8qsVQcOK85QnJ+FWLcUeKbuUbHUVRcrLzdVFKMj7Rrudf3oH9RPTqBUB4r16YgoIwhYYCYPTxocWMz2j+ycclOu6VgSksguLzPnPFGWmYwiJcYjLnfEFQ517UfOMzqo75L6mfv1tiP0EdunN67fJLnq+n8QoJw5Z97oKELScTY2iYS0zekrn4xXci4tHXMN/+CLnzK+9Q8wsxBpnPXZQAbLmZGIJDLxwbEo7RHEHxMcffNNbEIxQf30/o/VMw3/8ClsN7XCpvlYExOLRE+xmDLtx+hpAwjKHntd/JIxQfP0DoqOcJHT2Z4iN7sKUnX3DbisoQZMaee377ZWEIMl849rf2O76/xDqfRhfuWFZ0aj/PYzAYL9mPJyh1FitWrMDX15ehQ4cC4OXlxeTJk5k5cyb5+fk0a9aMkJAQli5d+o/2P3jwYObMmQPArFmzuP766//RfkaOHMnDDz9Mz549adOmDT/++CPgqJzfdNNNXHXVVQwaNIi8vDxGjRpF79696datGwsWOO6D69u3L3v2nBtS8mfV+/LspquisVrtLF2b5e5UPErC9HcIatGKxu9/QlDLeIpSU8DqGDJgSU1hz7Db2Tn0RiL6XYEpLOxP9iby9xx9401CWremxRczCWndmsLkZOxWKwCbrxrEjttuZ/8TT1JrzCP4xlbiocAXEdSpB7krf+HYQ7dz6tWniBk+Bs4breJbpyG2okKKEo+5MUvP5duiI/lbVpP+0iNkffYaITfc69J+8td5N2lD0d6tYLcDYAyLwiuiCtlTJ5I19XG8azXAFFfXzVl6Lp/GbbDs23au/cyReEXEkD3tCbLfmYipZgO81H4X5d2oDZb925zt9xtDYAjGqKoaPv0n1H7ybyh1B3zPnj3Ex8e7LAsJCSEuLo7Dhx330Y0ZM4aXX375H+1/0KBBzJs3D4Aff/yR/v37/+Ncjx8/zpIlS/jmm2945JFHKChw3E20Y8cOZsyYwQ8//MCrr75K9+7dWbJkCfPmzWPSpEnk5eW5XAhISkoiOTmZVq1a/dHblYkr+0Qw9Zn6TH2mPhnZFiLDfZzrIsN8SMt0HQaTlmlxGVoeGeZD+nkxfbuG0b5lMC+9d/zSJ+9BLGmpeEdHO1/7REVjSUt1jUlP4/BTj7Pn3js5+eH7AFjzTpeIyT96mKDmFx96WBkVnEzGP66K87VfbBUKEpMpOJmMX/XzlsfFUHCyclUuAApTHJP5/cYnOoailN+df2lp7Hv0UXbcMpTj06YBYD3tOP+KUh2xhYmJ5GzeQlCjhmWUuWcozkzHFBHpfG0Kj6Q4M90lJqR7P05vcNz+VHhwLwZvH7yCQpzrgzp25/S6ylf9BrDmZGIMDXe+NoaEYcvOdInxb9Odwp0bACg+cQiDyRtDQFCZ5unJbKezMIacu/BqDA7Dnnvh23J8Gp8//By8G7Sk+OQRsBSCpRDLoV14xda55Dl7Eltudon2s52+cPt5N25D0Z7ft99RsBQ5bok4vAtTtdqXOmWPYj+dhSH4/PYzYz+ddcFYn0atL1il9W7YiuIDO3Dei1iJqP08kNFw6X48QJnU4bt06QLA2rVr//a24eHhmM1mZs+eTcOGDfH39//HeVxzzTUYjUbq1q1LzZo12b/fMXykZ8+ehJ2tWC5ZsoQ33niDrl27cuWVV1JYWEhCQgKDBw/m+++/B2DOnDlcffXV/ziPf9P8xemMnnSA0ZMOsHZLDn26mAFoVDeAvHwrmdmuw+ozs4s5k2+jUV3HvZB9uphZt9Vxr1Sb5kHccEUU/33zKIVFrlf2Krq8vXvxi43Dp0pVDCYTYb37kLVmlUuMV0ios+JT5ZZbSVvoGB3hHRmFwcdx4cMrKJigZi0oOFG5LmD8mZR5S4gdeg0A5g4tKc7JpTApldRFq4jq2xWTOQSTOYSovl1JXbTqj3dWAZ3evRv/6jXwrVYNg8lEZL/LyFjhei+yKfTc+Rd35x2kfO+4MOkVHIzB29sZE9yyBWcOH6EyKTy8H++YWEyRMeBlIqhjd/K2rneJKU5PJaBJPADe1apj8PbG+lsHyWAgqH1XTq+rfPd/AxQnHsEUEYMxLBK8vPBt0YHCva4jvKzZ6fjUaQKAV1RVMHljr2T3Kf8R68ljGMOiMYZGgNHL0Uk8UHIWZGN4DAa/AKyJ5yb6s+VkYqpe3zHrr9GIqUb9SjcE3XrqGMawKGf7+TRujeUCs0gbw2Mw+gVgTTz3O87RfvXOtV/1+lgrXfsdxyssCsNv51+jNlgO/loiznn+nSz5HeG4sFE5h0+r/aSslXoW9EaNGvHdd9+5LMvJySEhIYE6deo4h56PHTuWV155BZPp77/l4MGDGTt2LNPOVn3+qd9PjvXb68DAQOcyu93OjBkzqF+/fontw8LC2LlzJ3PmzOG1114rVS6XwsbtubRrEczHLzWkoNDG6x8lONdNfaY+oyc5ZgR9Z0Yijwyrjq+PgY07cp33et83NBZvk4HnxzmuvO89dIapnyWW/YG4g83K8bdep/5Lr2EwepG2cD4FR49Q9c5hnNm3l+w1qwiOb0XsPSPAbuf0ju0cf9Mxt4FfzVrEjRyNYyYYA8nffEnBkco1i3L8568S0aM9PpFh9D6ynAPPvI3B2/FZP/7+V6QsXE7UFT3oufdnrPn57Bj2OACWzGwOTJ5G17WOR8YceP4dLJkXn8ytwrJaOfzySzR5+y0MXl4kf/89+YcPU334cE7v2UPmihWEtm1DjVGjwG4nZ+tWDr/4EgABtWtT5/HHHFfdjUYSP/vMZfb0SsFmI23GdKo++iwGg5GcFT9jSTxO2LVDKTxygDNb15P25YdE3fUAof2vBjukfPC6c3O/hs0ozkhzTOJWGdls5M6bifmOsRgMRvK3rMSacpLAPoOxJB6haO82Tv/wFcGD78S/Sz8Acmd/6Nw8YuwrGHz9wMuEb+PWZH3yissM6pWC3caZn78m6KbRYDBStGMttrRT+HW7EuupY84/5n2atMVyXvUWwLJ3C941GxAy7AnAjuXw7gv+8V+h2W3k//wNgf8ZBQYDRb+uw5aWhF/XgRQnHaf4t/a7QCfHsm8rppoNCL77cbDbsRzZQ/Ghne44Cvex28j/5f8IvP4+MBqw/LoOW3oSvl0GYE067mwP70atKdq7pcTmhpBwjMFhWE+UfHJOpaD28zgGo2fcq32pGLKyskpV6rTb7fTq1Yvhw4czZMgQrFYrDz/8MMHBwfTv35+pU6fy9ddfA9CnTx+Sk5OZPn063bp1Y+DAgTz33HMXHcrdvHlzli1bho+PDx999BH33Xcfp06d4qabbmLt2rWsXLnSuf8vvviCbdu2XXSo+8iRI0lLS+Prr7/m2LFjzknjZs+e7bLdM888Q25uLi+99BIGg4Ht27fTsqVjOPEHH3zAxo0b2bFjB+vWrbvg+4SGhnLFHXr23z+x8FPHjKebe3VxcyblU5ulqwFY4F25hh//WwZaHBP6rGnbzs2ZlF+dN20E4NBtA92cSflUd4ZjVE3KxDvcm0g5Ff38pwBkTrnPvYmUU2GPOYocWS+OdnMm5ZN5/FQAsl++382ZlF+h494G1Ib/VOi4t8nOrhhFDO9Z/3wC7z9juX7MJdv3X1XqywsGg4GZM2cyd+5cWrduTZs2bfD19WXSpEklYseMGeOc0fzvCA4O5qGHHsLHx8dludVqdS47/98XExcXR+/evbn++ut57bXX8PPzKxEzbtw4LBYLXbp0oWPHjkyePNm57uqrr2b27Nlcc801f/sYRERERERE5E8YDJfuxwOUegg6ODq2v1W5z9etWze6dTv3TN8BAwaQlZXlfP3bDOMX8+uvJYdg1axZ03kv+Z49e6hdu7bz33Xr/vGslz179uT11193WXbLLbdwyy23OF/7+/vzxhtvXHD76Oho0tPTL7hORERERERE5I/8Kx1wdxg9ejR79uzhk08+4frrr6eoqIgJEya4Oy0RERERERH5pyr4PeAe0QHv06cPhYWFLsvee+89mjZtetFtpk6d6vz3rFmznP9+5ZVXmDt3rkvsNddcw/Tp0/+dZEVEREREROTS8JCh4peKR3TAFy9e/K/ta+zYsYwdO/Zf25+IiIiIiIjIv8EjOuAiIiIiIiIiFf0xZBX76EREREREREQ8hCrgIiIiIiIi4hkMFbtGXLGPTkRERERERMRDqAIuIiIiIiIinsFYsWdBVwVcREREREREpAyoAi4iIiIiIiIewaB7wEVERERERESktFQBFxEREREREc9Qwe8BVwdcREREREREPIOGoIuIiIiIiIhIaakCLiIiIiIiIp7BULGHoKsCLiIiIiIiIlIGDFlZWXZ3J1GRhIaGujsFERERERGpZLKzs92dwr/C95ePL9m+C/vedcn2/VepAi4iIiIiIiJSBnQP+CXQ56YN7k6hXFr8VXsA0p+5182ZlE8Rk94HYE3bdm7OpHzqvGkjAAu8G7o5k/JroGUfAEvrt3RzJuVTrwPbAdjSp6ubMymfWi9eBcDeG/q5OZPyqdH/LQJg/5D+bs6kfGrw5Y+A2q801Ial81v7VQiaBV1ERERERERESksVcBEREREREfEMxoo9C7o64CIiIiIiIuIZNARdREREREREREpLFXARERERERHxDIaKPQRdFXARERERERGRMqAKuIiIiIiIiHgGY8WuEVfsoxMRERERERHxEKqAi4iIiIiIiGfQPeAiIiIiIiIiUlqqgIuIiIiIiIhn0HPARURERERERKS0VAEXERERERERz1DBZ0FXB1xEREREREQ8gyZhExEREREREZHSUgVcREREREREPIMmYRMRERERERGR0lIFvIIZdXsNOrQyU1ho46Xphzlw9EyJmPq1A3h0ZB18fYys35rFO58dd1l/w8AqjLi1BoPv2UJObnFZpe523nWbEnj5jWA0UrB1FQWrf3RZH9DvP3jXagiAwdsHQ2AwmS895FjX51q86zcHIH/FAop2byrT3D2BuVMnao8dA0YjKXO/I/Gzz1zW+1apQt1Jk/AOM1Ock8OBJydRlJICQKf16zhz8BAAhclJ7H1kTJnn724tPphM9ICeFKWks6LVVReMafL6RKL798CaX8D2uyeQs3U3ALG3XkP9x0YCcGDKdBI/n1tWaXuM8G6dqf/EePAycuqbORx//2OX9b7VqtJ4yn/xDg/Dkp3NnrGPU5iUgrlDO+pNHOuMC6hTm90PjSftl6VlfQhuFdKuA3GjHgSjkfQf5pP81UyX9T7RMdQY9xjeZjPFObkcnfIMlrRU/OvWo/pDY/EKCASblaQvZpC5bImbjsK9AuPbEn3nSAxGI1mLfyRj7tcu602RUVQdNQ6vwCAwGkn94iPytm4Ek4kq9z6IX90GYLOR8sl0zuze4aajcJ+Alm2Ivm0kGI1kL/2RzO+/cVlvioiiysixGAMDMRi9SPvyY/K2bQQvL2LufQi/WvXAy4uclYvJ/O7ri7xLxaX2Kx21n4ep4PeAqwNegbSPDyWuqh+3PbSDxvUCeXBYLUY/sbtE3EN31+K194+w52AeUyY0oH18KBu2ZQMQFeFDmxahJKcWlnX67mUwEHjFzeTMfB1bTiahwx7Hsm871rRTzpAzi879MvZr1wuvKjUA8K7fHK+qNch+71kwmQi9bSyWgzuxFxWU+WG4jdFInfGPsmvUaIqSk2kx4zMyVqwg/8gRZ0jNhx4kdcECUhcsIKRtW2qMHsXBSU8BYCssZPstt7gre4+Q8Nm3HJ02k/iPX7zg+qj+3QmsV4tljfth7tCSZlOfZk2X/+AdFkqDJ0azquN12O12uq3/luR5SyjOyinjI3Ajo5EGTz/OtjuGU5iUTNvZ/yNtyTLOHDzsDKk34RGS5s4jac48zB3bU2fMg+wZN5Gs9RvZNOhGAEyhIXT8ZT4Zq9a660jcw2ik+gOPcODRh7GkptBw2odkr11FwbGjzpDYEaPJ+PlHMhb9SFB8a6oNG86xF57DVljIsReeozAxAe+ICBpN/4icjRuw5p123/G4g9FIzN2jOfHsBCwZadSa8janN62lKOHcBe7I624hd+0KshbNxyeuBtUfe45Do27D3OcKAI6OGY5XiJnqE5/n6ITRYLe762jKnsFI9J2jSJz8OJb0NGo+/xZ5m9dRlHiu/cIHDyF33Qqyf1mAT2wNYsc/y5EHbie4QzcMJm+OjR+JwceXWq+8T+7qZRSnJbvxgMqY2q901H5Sxv7VIeiJiYkMGTKE1q1bEx8fz/jx4ykqKmLlypWYzWYWLlzojL3xxhtZuXIlAAMHDmTr1q0X3W/z5s1JT08HIDY21mXdhAkTaNy4MTab7d88lHKpS9swFq1IA2DPwTyCArwIN3u7xISbvQnw92LPwTwAFq1Io0vbMOf6+26rwftfHKcSfe0DYIqtjTUzBVtWGtisFO7aiHfDlheN92nWnqJdGwDwiqxK8bEDYLeBpYjilAS86zUtq9Q9QlDTpuSfOEFhYiL24mLSFv1MeI8eLjEBteuQvckxMiBn0ybCu3d3R6oeK2PVJiwZ2RddHzOoD4kz5wKQtX473qEh+FaJIqpfV1IXr8aSmU1xVg6pi1cTfXm3MsraM4S0aEb+sRMUnEjEbikmecGPRPbp6RITWK8umWsdn9msdRuI7NuzxH6i+l9G+opV2Aoq0cUzILBRYwoTEyg6dRJ7cTGZS38htHNXlxi/mrXI3boFgNPbtmDu7DjHChNOUJiYAIAlPR1LVhYms7lM8/cEfvUaUpR0EktKEhQXk7N6OUFtO7vE2O12jP4BABgDArFkOv6u8Y2ryZmd2wCw5mRhzTvtqIZXIn71GmJJOuVoP2sxOWuXE9i2k2uQHZf2Kz7bfgBGXz8wGjH4+GAvtmDLzyvL9N1O7Vc6aj8PZDReuh8P8K9lYbfbufXWWxk4cCBbtmxh8+bN5OXl8eyzzwKOjvOrr776b70dADabjfnz5xMbG8uqVatKvb/i4vI93Doy3IfU9CLn69SMIiLDfUrGZJyLSTsvpnMbM2kZRRw+nl82CXsQY7AZW3aG87UtJwuv4LALx4aG42WOxHJkLwDW5LMdbpMPBv8gvGs1xBgSXiZ5ewrf6CiKks9d7S1KScYnOsolJu/AfiJ69QIgvFcvTEFBmEJDATD6+NBixmc0/+TjEh13cfCrFkN+QpLzdUFiEn6xMfhVi6HgxHnLE5LxqxbjjhTdxrdKNAWnzrVBYVIKvjGubXB67z6iLu8DQGS/Po7zzxzqEhMzsD8p811vPakMvCOjKEpNcb62pKbiHen6+c0/dBBzN8dn09y1O16BgXiFhLjEBDRsjNFkovBk4qVP2sN4h0dSnJ7qfF2ckYp3RIRLTNo3nxPSvQ913/2C6o89R/LH0wAoOHaYoLadwGjEO7oKfnXq4x3h2v4VnSkswrX90tPwDnNtv/TZMwnp2pvaUz8n9tFnSPnU0X6561diKyygzvT/Ueftz8mcPxtbJRuBofYrHbWflLV/rQO+YsUKfH19GTp0KABeXl5MnjyZmTNnkp+fT7NmzQgJCWHp0n/vvrqVK1fSuHFj7rrrLmbPnv2HsVOmTOHee+/lsssuo3Xr1nx29v7UlStXcsUVV3DTTTfRoUMHrFYrTz75JL169aJz58588sknANx111389NNPzv2NHDmS77777l87Fnfz9TFy8+BqfPpN5fvD6e/yadqOwj2bncMDLYd3Yzmwk9C7xhN03TCKEw47quHi4ugbbxLSujUtvphJSOvWFCYnY7daAdh81SB23HY7+594klpjHsH3dyNdRErr4AuvYW7flrbffY25fRsKkpLBeu5z6hMVSWDDemSsXOPGLD1X4ntTCW4RT6N3PyaoZStHh/289jOFR1DrsSc5+vKUyjV0+m8I6dqLnKWLODTiFk5MeYJq9z8KBgPZS36kOD2NWi++Q/QdI8jftxu7RvWVENy5JzkrfubI6FtJfGkSVe4bBwYDfnUbgs3G4ftu4ciDtxM28Dq8o6u4O12Po/YrHbVf2bIbDJfsxxP8a/eA79mzh/j4eJdlISEhxMXFcfiw4z68MWPG8Pzzz9PrbBWstGbPns11113HgAEDePbZZ7FYLHh7e180fteuXfzyyy+cOXOG7t27069fPwC2b9/OmjVrqFWrFp9++qnzQkFhYSGXX345vXr1YvDgwcyZM4fLL7+coqIiVqxYwWuvvfavHEdpXN0vmgG9HVfK9x3KIyriXMU7KtyHtPOq3eCoeEedVxWPPBtTLcaXKlG+vP9SM+e2705pyqiJu8nMtpTBkbiXLTcLY+i5qrUxxIw1N/OCsb5N25G38H8uy/JX/UD+qh8ACBp8N9b0ynXvT2FKKj7nVRx9omMoSkl1ibGkpbHv0UcBMPr7E9G7F9bTjqvERamO2MLERHI2byGoUUMKE3Ux6HwFJ5Pxj6vCb2elX2wVChKTKTiZTHiP9s44v7gYMpZvcE+SblKYlIJf1XN/8PhWiaYw2fUzWJSSys5RjwDgFeBP1OV9Kc7Nda6PHtCPtEVLsJfzkVD/hCUtFZ+oaOdr76goLGm/+/ymp3P46YkAGP38MXfr4bzP2xgQQL3JL3Hy4/c5s2dX2SXuQSwZaZjOq1qbwqOwpKe7xJh7X86J5x1tWLB/DwZvH7yCQ7HmZJHy2bvOuBrPvU7RqYSySdxDFGemu7ZfRKRziP5vQntdTuKUs+134Lf2CyGkSy/ytm8GqxVrTjb5+3fhW6e+YzhxJaH2Kx21n5S1Mh0I36VLFwDWri39BDdFRUX8/PPPDBw4kJCQENq0acPixYv/cJsBAwbg7+9PREQEXbt2ZfPmzQC0bt2aWrVqAbBkyRK++uorunbtSp8+fcjIyODw4cNcdtllrFq1isLCQn7++Wc6d+6Mv79/qY+jtL5blMLwCbsYPmEXqzdl0q97JACN6wWSd8ZKRpZr5zkjy8KZfCuN6wUC0K97JKs3ZXLkRD7XD9/KLfdv55b7t5OaUcSIx3ZVis43QHHiUbzCozGaI8DohW/Tdlj2by8RZ4yogsE/wFHl/o3BgMHf0Z5e0bF4xcRhOVRy8ruK7PTu3fhXr4FvtWoYTCYi+11GxooVLjGm0FDnrJZxd95ByvfzAPAKDsZw9sKZKTSU4JYtOHP4COIqZd4SYodeA4C5Q0uKc3IpTEolddEqovp2xWQOwWQOIapvV1IXlf6WnPIk99dd+NeqgV9cLAZvEzED+5O2eLlLjHeY2Xn+1Rh+N0mz5rqsj77yCpIr4fBzgLy9e/GNrY5PlaoYTCbCevUle81qlxivkHOf3yo330r6jwsAMJhM1PnvZNIX/UjWimVlnbrHKDi4D5+qsY7Kl8lESJcenN7k+reOJS2VwObxAPjEVsfg7YM1JwuDjy8GXz8AAlq0BqvNZfK2yqDg0D68q1TDFBUDXiZCOvUgb/M6l5jitBQCmrUCwKdadYw+PlhzsrGkpRDQ1DFni8HXF796jSg6WbkuYKj9Skft54EMxkv34wH+tQp4o0aNSgzJzsnJISEhgTp16jiHno8dO5ZXXnkFk6l0b7148WKys7Pp3NkxyUl+fj7+/v7079//otsYfjfs4LfXgYGBzmV2u52XXnqJPn36lNi+S5cuLF68mDlz5nDttdeWKv9LYf3WbDrEm/n8zRYUFNp4+d1znZj3XmjK8AmOysSbHx/j0ZG18fUxsmFbtnMG9ErNbiNv4ZeE3PIQGIwUbluNNfUU/j0HUXzymLMz7tusHUW7Nrpua/Qi5I5xjt0UFnB6zkeVbwi61crhl1+iydtvYfDyIvn778k/fJjqw4dzes8eMlesILRtG2qMGgV2Ozlbt3L4xZcACKhdmzqPPwY2GxiNJH72mcvs6ZVF/OevEtGjPT6RYfQ+spwDz7yNwdvxe/L4+1+RsnA5UVf0oOfen7Hm57Nj2OMAWDKzOTB5Gl3XzgLgwPPvYMmsXJ9pu9XK/v9OoeXH0zF4GTk1ay5nDh6i9oP3kfPrLtKXLMfcoS11xjwAdsjauJn9/53s3N4vthp+VaqQtaHyPT4QAJuVE2+/Rr0XX8NgNJK+cAEFx45Q9Y67ObNvL9lrVxMc34pqdw8H4PSObZx4yzECLKxnb4JbxGMKCSXi8gEAHHvpefIPHXTb4biFzUbyR1OpPnHy2ccY/URRwjEib7yNgkP7Ob1pHSkz3qPK8IcJG+j4++HUO68AYAo1E/fEZLDZKc5I4+TbF34SQoVms5H66TTiHnsejEZyli2iKOEYEdffSsGRA+RtXkfqzA+IuedBwgYMxm63kzTdMa9Q1qJ5VBkxhpovvwdAzvKfKTpeyb5D1H6lo/bzPB7SUb5UDFlZWf/KzVp2u51evXoxfPhwhgwZgtVq5eGHHyY4OJj+/fszdepUvv7a8Vy8Pn36kJyczPTp0+nWrRsDBw7kueeeo1WrVhfcd/PmzVm2bBkRERHExsaSmJjIsGHD6N+/P9dffz0AeXl5tGzZkh07dhAQEFBiH1OmTGHBggUuQ9B//vlnDh486JLbp59+yqJFi/jss8/w9vbm4MGDVK1alcDAQH766SdmzJjBtm3b2Lp1Kz4+PiXeJzQ0lD43Va7hn/+WxV85htGmP3OvmzMpnyImvQ/Amrbt3JxJ+dR5k+PCygLvhm7OpPwaaNkHwNL6F3+CgFxcrwOOC31b+nT9k0i5kNaLHSM/9t7Qz82ZlE+N/m8RAPuHXLyQIRfX4EvHCBq13z+nNiydBl/+SHZ2xbgA77P1h0u276JWAy7Zvv+qf+3ygsFgYObMmcydO5fWrVvTpk0bfH19mTRpUonYMWPGkJDw14dnWK1WfHx8KC4uxsfHhzNnzvDLL7847+EGRxW7Y8eO/PjjxYcQNm3alKuuuoq+ffsybtw4qlatWiLmtttuo1GjRvTo0YNOnTrx0EMPOWdH7927N6tXr6ZHjx4X7HyLiIiIiIjIP6dJ2P6GuLg4ZyX5fN26daNbt3PPpR0wYABZWVnO1wsWLLjoPtPS0rDb7QQHB/Prr79Su3ZtAgICOHr0aInYmTNn/mF+zZo147333vvD3IxGI5MmTbrghQNvb+8Lvq+IiIiIiIjIn/HoAfY//PADV1xxBZMmTeLjjz9m2LBhPPHEE+5OS0RERERERC4FTcJWdvr06UNhYaHLsk8//ZSmTZsCjmdx/5mZM2fy7rvvuizr2LEjr7zyyr+XqIiIiIiIiMjf5FEd8D97jNhfMXToUIYOHfovZCMiIiIiIiJlyk33an/44Ye89dZbJCcn06hRI6ZMmeJ84taFFBUV8fLLL/P111+TlJREdHQ0o0ePZsSIEX/4Ph7VARcREREREREpS99++y0TJkzg1VdfpWPHjnz44YfccMMNrFu3jurVq19wm7vuuouTJ0/y5ptvUqdOHVJTU8nPz//T91IHXERERERERDyDsezv1X7nnXe4+eabuf322wF4+eWXWbx4MR9//DFPPfVUifglS5awYsUKtm7dSkREBAA1a9b8S+/lGXeii4iIiIiISKVX1o8hKyoqYtu2bfTu3dtlee/evVm/fv0Ft1mwYAGtWrXinXfeoUmTJrRu3ZpHH32U06dP/+nxqQIuIiIiIiIilVJ6ejpWq5WoqCiX5VFRUaSkpFxwm6NHj7Ju3Tp8fX2ZMWMG2dnZPProoyQlJTFjxow/fD91wEVERERERMQzeMjjwv6IzWbDYDDwwQcfEBoaCjiGrV977bWkpKQQHR190W09/+hERERERERELoGIiAi8vLxITU11WZ6amnrRjnRMTAxVq1Z1dr4BGjRoAEBCQsIfvp864CIiIiIiIuIR7AbjJfu5EB8fH+Lj41m6dKnL8qVLl9KhQ4cLbtOxY0eSkpJc7vk+dOgQwEVnTf+NOuAiIiIiIiJSaY0aNYr//e9/zJgxg3379jF+/HiSkpK48847ARg+fDjDhw93xl9//fWEh4czatQo9uzZw7p165gwYQJXX311iXvJf0/3gIuIiIiIiIhnuMhs5ZfStddeS0ZGBi+//DLJyck0btyYb775hho1agAlh5UHBQUxd+5cHn30UXr37o3ZbGbgwIEXfGTZ76kDLiIiIiIiIpXasGHDGDZs2AXXLViwoMSy+vXrM2fOnL/9PuqAi4iIiIiIiEe42L3aFUXFPjoRERERERERD6EKuIiIiIiIiHgGN9wDXpYMWVlZdncnUZGc/yw4ERERERGRspCdne3uFP4VxgNrL9m+bfU7XbJ9/1Uagi4iIiIiIiJSBjQE/RLoO2STu1Mol375si0ABbNfd3Mm5ZPfdQ8DcOi2gW7OpHyqO8Mxu+XS+i3dnEn51evAdgAWeDd0cybl00DLPgB+jmnm5kzKp8uSdwKwulUbN2dSPnXZuhmA9Z06uDmT8qnD2vUAbOrh/upaedV2uaPquaVPVzdnUj61XrzK3Sn8a+wVfAi6KuAiIiIiIiIiZUAVcBEREREREfEMegyZiIiIiIiIiJSWKuAiIiIiIiLiEezoHnARERERERERKSVVwEVERERERMQj2C/hPeCeUFtXB1xEREREREQ8gyZhExEREREREZHSUgVcREREREREPILdcOkGinvCEHRVwEVERERERETKgCrgIiIiIiIi4hEu5SRsnqBiH52IiIiIiIiIh1AFXERERERERDzDJbwH3BOoAi4iIiIiIiJSBlQBFxEREREREY+ge8BFREREREREpNRUARcRERERERGPYPeIp3VfOuqAVzCjbq9O+/hQCotsvDT9KAePnikRU792AI+OqIWPj5EN27J557MTANxxQzU6tzVjs0FWjoWX3z1KeqalrA/BbVbvP86L81djs9kZ3K4xd/doVSLmpx0HeXfxZjBAwyoRvHBTXwBeX7iWFfuOY7fb6VgvjvFXdsFQwSeQ+D3/5m2IHHovBqORnOWLyJr/fy7rTRFRRN/zCMbAQDAYyfjmU87s2ERQp56YB1znjPOpXouESQ9SdPxwWR+CW4V360z9J8aDl5FT38zh+Psfu6z3rVaVxlP+i3d4GJbsbPaMfZzCpBTMHdpRb+JYZ1xAndrsfmg8ab8sLetDcKsWH0wmekBPilLSWdHqqgvGNHl9ItH9e2DNL2D73RPI2bobgNhbr6H+YyMBODBlOomfzy2rtD1GRK8uNHxuAgYvLxK/mM3Rtz9yWe8XV5UmbzyLT0Q4lsxsdo6aQOGpZADqP/kIkX27g9FIxoq17Js4xR2H4Hbmzp2oM24sGL1InjuXxE8+dVnvW7UK9Z56Cu+wMIpzstk/8UmKUlIA6LxpA3kHDwJQlJTEnoceKev03S60Y0dqPvQIBi8jKd9/z6nPZ7is96lShToTn8DbbKY4J4dDTz9NUWqKc71XQCAtvvyKjBXLOfbqK2WdvtuFtO9IjfsfAqMXaQu+J+l/n7us94mpQq3xEzGZzVhzcjj8/NNYUlPxialC3edewGAwYDCZSPl2Fqnfz3HPQbhRSLsOxI16EIxG0n+YT/JXM13W+0THUGPcY2fPv1yOTnkGS1oq/nXrUf2hsXgFBILNStIXM8hctsRNR1FxVPQh6OqAVyDt40OJreLH7Q/vpHG9QB68uwb3P7m3RNyDd9XktQ+OsedgHpPH16ddyxA2bs/hm/lJfPp/JwG45vJohl5blTc/Ol7Wh+EWVpuNyd+v4r27riQmJJCbp31Lz0Y1qRsT7ow5lpbFR8u38tmIawjx9yX9dD4A244lse1YErMeuAGAO977jk1HTtKuTqxbjsUtDEaibhvJyZeeoDgjjbj/vk7elnVYTp5whoQNuonTG1aSs+QHvKtVp+qY/3J8zF2cXruM02uXAeATV5MqDz5Z6TrfGI00ePpxtt0xnMKkZNrO/h9pS5Zx5uC5dqg34RGS5s4jac48zB3bU2fMg+wZN5Gs9RvZNOhGAEyhIXT8ZT4Zq9a660jcJuGzbzk6bSbxH794wfVR/bsTWK8Wyxr3w9yhJc2mPs2aLv/BOyyUBk+MZlXH67Db7XRb/y3J85ZQnJVTxkfgRkYjjV54gi3/uYeCk0l0+OlrUn9aSt7+c+dfg6fGcuqb7zn1zfeEdW1PvYkPsWv0Y4S2jcfcvhVre10LQLt5Mwjr3I7MNRvddTTuYTRSZ8IEdo28j6LkZFp+8TkZy5eTf/iIM6TWww+TsmABqfPmE9quHTXvH82BJycBYCssZPtNN7sre/czGqk1Zhx7H7yfopQUmn78KVkrV5J/9Fz71bj/AdIW/kDaDz8Q0qYN1Ufex6Fnnnauj7t3ODnbtpZ97p7AaKTGQ2PYP+ZBLKkpNH7vY7JWr6Tg2FFnSNx995P+00LSf/qB4FZtiLt3JEeefwZLehp777sHu8WC0d+fpp98QdbqlVjS09x3PGXNaKT6A49w4NGHsaSm0HDah2SvXeXSfrEjRpPx849kLPqRoPjWVBs2nGMvPIetsJBjLzxHYWIC3hERNJr+ETkbN2DNO+2+4xGPV+rLC4mJiQwZMoTWrVsTHx/P+PHjKSoqYuXKlZjNZhYuXOiMvfHGG1m5ciUAAwcOZOvWi/+ibN68Oenp6c7X06ZNIyYmhuzsbOeyM2fOcM8999C5c2c6depE//79OX268p7wnduY+Xmlo832HMwjKMBEuNnbJSbc7E2Av5E9B/MA+HllOl3ahgFwJt/mjPP3M4K9jBL3ADsTUqgeEUJceAjeJi/6t6jLsj1HXWK+3biHmzo2I8TfF4CIIH/A8aSEwmIrFquNomIrxTYbEUEBZX0IbuVbtwGWlJMUpyaBtZjT61YQ2LqjS4zdbsfo72gXY0Ag1qyMEvsJ6tiD0+tXlEnOniSkRTPyj52g4EQidksxyQt+JLJPT5eYwHp1yVy7AYCsdRuI7NuzxH6i+l9G+opV2AoKyiBrz5KxahOWjOyLro8Z1IfEmXMByFq/He/QEHyrRBHVryupi1djycymOCuH1MWrib68Wxll7RlCWzfnzJHj5B9LwG4pJmnuQqL693aJCWxQl4xVjvMvc9UGovv3OrvGjtHXB6OPt+O/Jm+KUtOpbIKbNaXgxAkKExOxFxeT+tMiwnv2dIkJqFOb7A2OCxPZGzcS3rOHGzL1TEFNmlCQkEDhyZPYi4vJ+OVnwrp3d4nxr1WbnE2bAMjZvNllfUDDRniHh5O9fn2Z5u0pAhs3oTAxgaJTZ9tvyS+Yu/6u/WrWImeLo/1yt27G3MWx3l5cjN3iGO1o8PYGY+UavQcQ2KixS/tlLv2F0M5dXWL8atYid+sWAE5v24K5s+N7ojDhBIWJCQBY0tOxZGVhMpvLNP8KyWC4dD8eoFQdcLvdzq233srAgQPZsmULmzdvJi8vj2effRaA2NhYXn311X8l0dmzZ9O6dWvmzZvnXPbuu+8SFRXFmjVrWLt2LW+//Tbe3t5/sJc/Z7VaS5uq20SGe5OaXuR8nZpRRGS4d4mYtIxzw8pT011j7vxPLP+b2oLeXSKc1fDKICU7jyqhQc7X0aFBJOfkucQcS8vmWFoWt787h6HTv2X1fsfogJY1qtCuTix9p8yg75TP6Vw/jjrRYWWav7uZwiIoPu9qeXFGGqawCJeYzDlfENS5FzXf+IyqY/5L6ufvlthPUIfunF67/JLn62l8q0RTcCrJ+bowKQXfmBiXmNN79xF1eR8AIvv1wRQUhMkc6hITM7A/KfN/vPQJl0N+1WLITzjXxgWJSfjFxuBXLYaCE+ctT0jGr1rMhXZRYflWiabw5Hnn38lkfKtEu8Tk7t5H9EDHLTfRA/piCg7COyyU7E3byVi9ke47ltJ9x1LSlq0m70AlG8EC+ERHU5Sc7HxdlJyMb1SUS0ze/gNE9HZc2Ajv3cvxGQ51fIaNPj60/OJzWnz2aYmOe2XgExVNUcp57ZeSgvfv2u/MwQOE9XRc+Anr0ROvwEBMISFgMFDzgQc4/vZbZZqzJ/GJjHLezgBQlJqCT+Tv2u/QQcK69wTA3K0HXoGBeIWEAOAdFU2Tjz+nxf99R9L/Zlau6jfgHRnlcjuDJTUV79+1X/6hg5i7OS6ambt2d2m/3wQ0bIzRZKLwZOKlT1rKtVJ1wFesWIGvry9Dhw4FwMvLi8mTJzNz5kzy8/Np1qwZISEhLF1aunsRjxw5Ql5eHhMnTmT27NnO5UlJSVStWtX5un79+vj6+l5wH8eOHaNdu3bcc889tG/fnttuu40zZxz3Rzdv3pynnnqK7t27M3fuXJYsWcJll11G9+7duf322zl9+jS//PILt99+u3N/K1eu5MYbbyzVcXmiT75J5ObRO1iyOp2rL4/+8w0qkWKbjWPp2Xx4zyBeuLEv/52znJz8Qo6nZ3MkNZNF42/l5wm3suHQSbYcOeXudD1OUKce5K78hWMP3c6pV58iZvgYlyuRvnUaYisqpCjxmBuz9FwHX3gNc/u2tP3ua8zt21CQlAzWc6NWfKIiCWxYj4yVa9yYpVRUB55+hbBObenwy/8R1rktBSeTsFtt+NeqTmD9OqyM78PKlr0J79oec4fW7k7XIx19/XVC27Sm5ZdfENqmDYXJydjPXvTfNOBKtt9yK/sen0jtcWPwi4tzc7ae5/jbbxHSqhXNPptBSKvWFKWkYLfZiLnuOrLWrHHpQElJCdPeJji+FU0+/Izg+FaODrvN8R1iSU1h9123svPmG4jsPwBTWOUqIvwVie9NJbhFPI3e/Ziglq0c59t538Gm8AhqPfYkR1+eAvZKNIT0ErFjvGQ/nqBU94Dv2bOH+Ph4l2UhISHExcVx+LDjCviYMWN4/vnn6dWr1wX28NfMnj2ba6+9ls6dOzNixAhSUlKIjo5m6NChXHvttXz//ff06NGDIUOGULdu3Yvu58CBA7z99tt07NiRUaNG8dFHH3H//fcDEB4ezooVK0hPT2fo0KHMnTuXwMBA3njjDd555x3GjBnDQw89RF5eHoGBgcyZM4drr732Hx/Tv2XQZVEM6O24Srf/cB5RET7OdVHhPi7VboC0DItLxTsqomQMwOJVGTw/vj4zZlWOKnh0aCBJ2eduX0jJPk1MSKBLTExoEM2rR+Pt5UVceAg1I8wcT89m0+GTNK8eQ4Cvo127NKjO9hNJtK5dlcqiODMdU0Sk87UpPJLiTNdhqCHd+3HyFcf9joUH92Lw9sErKARrrmPYcFDH7pxeV/mq3+CoePtVreJ87VslmsLzqmkARSmp7BzlmJjJK8CfqMv7Upyb61wfPaAfaYuWYC8uLpuky5mCk8n4x1Uh8+xrv9gqFCQmU3AymfAe7Z1xfnExZCzf4J4k3aQwKQXfauedf9ViKExy7cwUJqey466HAMf5Fz2wL8U5ucQOvZ7szduxnnHMiZG+eBWhbVuStX5LmeXvCYpSUvA5b9SKT0wMhamprjGpaewdOw4Ao78/EX16Yz1721zR2djCxESyN20msFFDChISyih79ytKTcEn+rz2i47G8rv2s6SlceCxCYCj/cJ79cJ6+jRBzZoT3DKemOuuw+gfgNHbG9uZM5yYPq1Mj8GditJS8Yk+VzTxiYqmKO137ZeexqEnHwMc7RfWvZfz/Ds/Jv/IYYJbxJO5vPJM5GlJS8Un6lz7eUdFYSnRfukcfnoiAEY/f8zdejjv8zYGBFBv8kuc/Ph9zuzZVXaJS7l1yS8DdOnSBYC1a//5pECzZ8/muuuuw2g0MmjQIObOnQtAixYt2LZtG/fffz+ZmZn06tWLffv2XXQ/cXFxdOzouC/1P//5j0tOgwcPBmDjxo3s27ePyy+/nK5du/Lll19y4sQJTCYTffr04ccff6S4uJhFixYxYMCAf3xM/5bvf05lxGO7GfHYblZvyuKybo5hv43rBZJ3xkpGlmvnOiPLwpl8G43rOTqXl3WLYM3mLABiq5wbPdC5rZkTJ/PL5iA8QNPYaI6nZZOQkYOl2MqPOw7Ro3Etl5jeTWqx6bDjgkRmXj7H0rOICw+hijmIzUdOUmy1YbFa2XzkFLWjKtfV48LD+/GOicUUGQNeJoI6didvq+u9eMXpqQQ0iQfAu1p1DN7ezs43BgNB7btyel3lu/8bIPfXXfjXqoFfXCwGbxMxA/uTttj1YoR3mNk5YqDG8LtJmjXXZX30lVeQrOHnF5UybwmxQ68BwNyhJcU5uRQmpZK6aBVRfbtiModgMocQ1bcrqYtWuTfZMpazdScBdWrgV8Nx/lW55gpSf3L949s73Ow8/2o9eA8nv3TMklyQeIqwzm0xeHlhMJkwd25bKYeg5+7ajX+N6vhWq4bBZCLq8n5kLHP9DJvMZmcbxt11JynffQ+AV3Cw497bszEh8S05c7hyteHpPXvwq14d36pVMZhMhPe9jMyVrt8HptBQZ/tVu+12UuY7bkk89PRTbBt8NduuHczxt98ideEPlarzDZC3dw9+cdXxqXK2/Xr3JWv1SpeY89uv6i23kbZwPuDobBp8HH//eQUFE9S8BQUnKscEvL/J27sX39hz7RfWqy/Za1a7xHiFnGu/KjffSvqPCwAwmEzU+e9k0hf9SNaKZWWdeoVlNxgu2Y8nKFUFvFGjRnz33Xcuy3JyckhISKBOnTrOoedjx47llVdewWT6+2+3a9cuDh06xDXXXAOAxWKhZs2a3HvvvQAEBQUxaNAgBg0ahNFoZNGiRTRs2PAv7fv8x0QFBjo6pHa7nV69evHRRx+ViL/22mv54IMPCAsLIz4+nuDg4L99PJfS+q3ZtI8PZcYbzSgstPHye0ed696d0oQRjzkeufPWJ8cYN6I2vj4GNmzLYcM2Rydo2E1xxFXzw263k5xaxBsfVZ6hwCYvI48N6srITxZgs9u5pk1D6sWE887PG2kaF0XPxrXoXL86aw4kMPj1rzEaDTzcvxPmAD8ua1aHDYcSuf6tbzBgoHOD6vT8Xee9wrPZSJsxnaqPPovBYCRnxc9YEo8Tdu1QCo8c4MzW9aR9+SFRdz1AaP+rwQ4pH7zu3NyvYTOKM9Ick7hVQnarlf3/nULLj6dj8DJyatZczhw8RO0H7yPn112kL1mOuUNb6ox5AOyQtXEz+/872bm9X2w1/KpUIWvDJjcehXvFf/4qET3a4xMZRu8jyznwzNsYvB3fOcff/4qUhcuJuqIHPff+jDU/nx3DHgfAkpnNgcnT6Lp2FgAHnn8HS+bFJ3OriOxWK/sem0zrr97D4OXFyS/nkLfvEHUfHUXO9l2k/rSMsM7tqD/xIex2O1nrNrNnwnMAJM9bRHjX9nRcNgfsdtKXriJtUSUcyWK1cvjFl2g6bSoYvUj57jvyDx+mxsgRnN69m4zlKwht24aa948Gu52cLVs5NOUFwDE5W92JE8FuA4ORhE8+dZk9vVKwWjn66is0fOMtDEYjqfPnkX/kCLH33Evenj1krVpJSGvHzOd2u53cbVs5+srL7s7ac1itHH/jVRq88obzMVoFR49Q7a57yNu7h+w1qwiOb03svSPBbid3+zaOv+F4VJt/zVrE3feAY9i0wUDS1/8j//Ah9x5PWbNZOfH2a9R78TUMRiPpCxdQcOwIVe+4mzP79pK9djXB8a2odvdwAE7v2MaJt14DIKxnb4JbxGMKCSXickdh7thLz5N/6KDbDkc8nyErK+sf36jwW2d1+PDhDBkyBKvVysMPP0xwcDD9+/dn6tSpfP311wD06dOH5ORkpk+fTrdu3Rg4cCDPPfccrVqVfNYyOO7LXrZsGe+88w5BQUE88si5Z2K2aNGC+fPnc/LkSRo1aoTZbKaoqIjrrruOYcOGcfXVV5fY37Fjx2jZsiWLFi2iffv23H///TRo0ID777/f+V4RERGkpaXRs2dPvv/+e+rUqUNeXh6nTp2iXr16WK1W4uPjad26Nddcc42zan6+0NBQ+g6pvH8El8YvX7YFoGD2638SKRfid93DABy6baCbMymf6s5wXM1eWr+lmzMpv3od2A7AAu+/dhFUXA20OEZw/RzTzM2ZlE+XJe8EYHWrNm7OpHzqsnUzAOs7dXBzJuVTh7WOUV+benRycyblV9vljpGpW/p0/ZNIuZDWi1e5PC2qPMs/delGAflXrXPJ9v1XlWoIusFgYObMmcydO5fWrVvTpk0bfH19mTRpUonYMWPGkPA37meyWq34+Pgwe/ZsrrzySpd1V155Jd9++y1HjhxhwIABdO7cme7du9OqVSsGDRp00X3Wr1+fDz/8kPbt25OVlcXdd99dIiYyMpJ33nmHu+++m86dO3PZZZexf/9+wDHJXP/+/fnll1+4/PLL//KxiIiIiIiIiJRqCDo47qv+rcp9vm7dutGt27lnqQ4YMICsrCzn6wULFlx0n2lpadjtdoKDg9m+fXuJ9ZMnnxt6OWTIkL+cq8lk4v333y+x/Ndff3V53aNHj4vO3P7yyy/z8ssa9iQiIiIiIvJvs+MZ92pfKp4xF/t5fvjhB6644ooLVtFFRERERESk4rIbjJfsxxOUugJeWn369KGwsNBl2aeffkrTpk3/0f4yMjIuOAz9+++/L9VM7CIiIiIiIiKl4fYO+OLFi//V/YWHh7NqVeV6hIyIiIiIiEhF4CmPC7tUPKMOLyIiIiIiIlLBub0CLiIiIiIiIgKahE1ERERERERE/gWqgIuIiIiIiIhH8JTZyi+Vin10IiIiIiIiIh5CFXARERERERHxCBX9HnB1wEVERERERMQjaAi6iIiIiIiIiJSaKuAiIiIiIiLiESr6EHRVwEVERERERETKgCrgIiIiIiIi4hF0D7iIiIiIiIiIlJoq4CIiIiIiIuIRKvo94IasrCy7u5OoSEJDQ92dgoiIiIiIVDLZ2dnuTuFfkZ6Wdsn2HREZecn2/VepAi4iIiIiIiIewW6o2BVwdcAvgZ7Xr3V3CuXSslmdADiz/Cs3Z1I+BfS4CYCUiXe4N5FyKvr5TwHY0qerexMpx1ovXgXAzzHN3JxJ+XRZ8k4AFng3dHMm5dNAyz4Afopo6uZMyqfL03cBsLR+SzdnUj71OrAdgNWt2rg5k/Kry9bNAGzs2tHNmZRP7Vatc3cK8hepAy4iIiIiIiIewW5XBVxERERERETkkrNX8Ad1VeyjExEREREREfEQqoCLiIiIiIiIR6jojyFTBVxERERERESkDKgCLiIiIiIiIh5BFXARERERERERKTVVwEVERERERMQjqAIuIiIiIiIiIqWmCriIiIiIiIh4BFXARURERERERKTUVAEXERERERERj2C3V+wKuDrgIiIiIiIi4hE0BF1ERERERERESk0VcBEREREREfEIqoCLiIiIiIiISKmpAl7B3H9XLTq2CqOgyMoLUw9x4EheiZgGdQKZMKoevj5G1m3N5O2Pj7qs/89VVbnv9lpcfedGsnOLyyhz91u98wAvf70Qm83ONV1bc9cV3UrELNq0k3fnLcMANKhehSnDrgdg1Jufs+NwAq3q1eCt+28p28Q9hE/95gQNvBmMRgo2reDMigUu642h4YRcfw8GvwAMRiOnf/o/ivbvwOAfSOjNozHF1qZg6ypOz5vppiNwr5B2HYgb9SAYjaT/MJ/kr1zbwSc6hhrjHsPbbKY4J5ejU57BkpaKf916VH9oLF4BgWCzkvTFDDKXLXHTUbhPRK8uNHxuAgYvLxK/mM3Rtz9yWe8XV5UmbzyLT0Q4lsxsdo6aQOGpZADqP/kIkX27g9FIxoq17Js4xR2H4FYtPphM9ICeFKWks6LVVReMafL6RKL798CaX8D2uyeQs3U3ALG3XkP9x0YCcGDKdBI/n1tWaXuUyN5daTRlAgajFwkzZ3PkzQ9d1vvFVaXZ28/hExGGJTObHSMnUHjScQ42eGoMUf26g9FA+rK17H2s8p2D4d06U/+J8eBl5NQ3czj+/scu632rVaXxlP/iHR6GJTubPWMfpzApBXOHdtSbONYZF1CnNrsfGk/aL0vL+hDcyty5E3XGjQWjF8lz55L4yacu632rVqHeU0/hHRZGcU42+yc+SVFKCgCdN20g7+BBAIqSktjz0CNlnb7bhXToSI0HH8ZgNJI6/3uSZn7ust4npgq1H5uIyRxGcW4Oh595CktqqnO9MSCA5jO/InPlco6//mpZp1/hVPQKuDrgFUiHVmbiqvpxy/1baVI/iIfvrc19j+0sEffwPXV45d1D7D5wmhcnNqJ9KzMbtmYBEBXhQ9uWZpJSC8s4e/ey2my88L8FTH/4NmLCQrhl8vv0aNmQutWinTHHktP5eOFKPn30bkIC/cnIOe1cd1u/LhQUWZi9YpM70nc/g4Hgq24l85OXseVkEDbyKQr3bMWaetIZEthrEIW/biB/w1K8oqphvv0R0l8Zi73YQt4v3+IVE4cpJtaNB+FGRiPVH3iEA48+jCU1hYbTPiR77SoKjh11hsSOGE3Gzz+SsehHguJbU23YcI698By2wkKOvfAchYkJeEdE0Gj6R+Rs3IA17/TF36+iMRpp9MITbPnPPRScTKLDT1+T+tNS8vYfdoY0eGosp775nlPffE9Y1/bUm/gQu0Y/RmjbeMztW7G217UAtJs3g7DO7chcs9FdR+MWCZ99y9FpM4n/+MULro/q353AerVY1rgf5g4taTb1adZ0+Q/eYaE0eGI0qzpeh91up9v6b0met4TirJwyPgI3Mxpp/NJENl13DwUnk+n0y9ek/LiUvH2HnCENnxnHya+/5+RX3xHerQMNnnyIX0c+hrldPOYOrVjdbTAAHX74nLAu7chcXYnOQaORBk8/zrY7hlOYlEzb2f8jbckyzhw89xmuN+ERkubOI2nOPMwd21NnzIPsGTeRrPUb2TToRgBMoSF0/GU+GavWuutI3MNopM6ECewaeR9Fycm0/OJzMpYvJ//wEWdIrYcfJmXBAlLnzSe0XTtq3j+aA09OAsBWWMj2m252V/buZzRS85Gx7H/4AYpSUmjy4SdkrVpJwdGjzpDqo+8n7ceFpP/4A8Gt2xA3/D6OPPdf5/q4e4aTu32rG5KX8uhvDUFPTExkyJAhtG7dmvj4eMaPH09RURErV67EbDazcOFCZ+yNN97IypUrARg4cCBbt/7xSbljxw7MZjO//PKLy/JXXnmFjh070rlzZ7p27cqmTY4OTlFRERMmTKBVq1a0bt2aIUOGkJiY+HcOp8Lp0i6cn5Y5rsbtPnCaoAAT4WZvl5hwszeBAV7sPuD44/ynZal0bRfuXD/6jlq89/kxsNvLLnEPsPNIItWjw4mLCsfbZOLyds1Ytn2vS8yclZv5T8/2hAT6AxAeEuRc16FxHQL9fMo0Z09iiqtDcUYytsxUsFop3LEe38atXIPsdgy+jrYz+Pljy8l0LLcUYTl2ACyWMs7acwQ2akxhYgJFp05iLy4mc+kvhHbu6hLjV7MWuVu3AHB62xbMnR0jNAoTTlCYmACAJT0dS1YWJrO5TPN3t9DWzTlz5Dj5xxKwW4pJmruQqP69XWICG9QlY9UGADJXbSC6f6+za+wYfX0w+ng7/mvypig1vYyPwP0yVm3CkpF90fUxg/qQOHMuAFnrt+MdGoJvlSii+nUldfFqLJnZFGflkLp4NdGXlxw9VNE5zsETZ89BC6fm/ED0Fb1cYoIa1iVjxXoAMlauJ/oKxzlqt7uegwZvU6U7B0NaNCP/2AkKTiRitxSTvOBHIvv0dIkJrFeXzLWOz3DWug1E9u1ZYj9R/S8jfcUqbAUFZZC15whu1pSCEycoTEzEXlxM6k+LCO/Z0yUmoE5tsjc4Lupkb9xIeM8ebsjUMwU2bkJhQgKFJx3fwRm//ExY1+4uMf61apO7xdEHyd2ymbBu59YHNGyIKSyc7A0byjTvisxuN1yyH0/wlzvgdrudW2+9lYEDB7JlyxY2b95MXl4ezz77LACxsbG8+uo/H3Ixe/ZsOnXqxKxZs5zLNmzYwE8//cTy5ctZs2YN3333HbGxjgrZM888w+nTp9m0aRNbtmxh4MCB3HrrrdhL2XG0Wq2l2t6doiJ8SE0vcr5OzSgiKsLnAjGFF4zp0i6M1IwiDh07UzYJe5CUrBxiwkOdr2PMoaRm5rrEHEtO53hyOne8+CG3TfmA1TsPlHWaHssrJAxbdobztS0nE2NomEtM3pK5+MV3IuLR1zDf/gi58yvnUPML8Y6Moig1xfnakpqKd2SUS0z+oYOYuzn+YDJ37Y5XYCBeISEuMQENG2M0mSg8WbkuRvpWiabwZJLzdeHJZHyrRLvE5O7eR/TAvgBED+iLKTgI77BQsjdtJ2P1RrrvWEr3HUtJW7aavAOHEVd+1WLITzjXxgWJSfjFxuBXLYaCE+ctT0jGr1qMO1J0K7+qMRQknnK+LjiZjF9V13bI3bmP6CvPnoNX/u4cXLWBnruX0XP3MtKWrHYZvVEZ+FaJpuDUeZ/hpBR8Y1zb7/TefURd3geAyH59MAUFYTKHusTEDOxPyvwfL33CHsYnOpqi5GTn6/9n777jm6reB45/srp36YCWVfbuAAodFCjIEqTgV0VBHCgioCAg6ycuhjKcyFAcIKiobFGGrFL2nmXPFpruQelM8vsjGogFQStN0z7v16svSO6T5LnndTPOfc45t1CrxdbL/Dsk98xZPDsaT/p4dOxgbD9XY/spbWxoseRbmi/8pkTHvTKw8fIyDccHKExJRvOX9rt57izuUe0BcG/X/tZ3sEJB9WGvcvWzT8oyZWHl7rsDHhsbi62tLf379wdApVIxdepUFi9eTF5eHk2bNsXFxYUtW/75nBuDwcDKlSuZM2cOW7duJf+PM5dJSUl4eHhga2sLgKenJ1WrVuXmzZssWbKEqVOnolKpAOjfvz+2trbExsbe8TUuX75Mq1ateOGFF2jdujVPP/00N28aO5rNmjXjzTffpF27dqxcuZLNmzfTuXNn2rVrx8CBA7lx4wa///47AwcOND3f9u3befzxx//xvpZXtjZKnurjx9dLr1o6lXJLp9dzJTmNL0Y9y7QXHuXdb1eTczPP0mlZDdvmbcg7uIO06a+RufADXP73IijKx5lIa5A4fzbOzQNpOO8rnFoEGTvsOr1pu9rDk1rj3+DSjGmVbgTL/Tj71kzc27Yk9PefcA9rSf61JAw6Pfa1quNYL4DtgdFsb9ERj4jWuIUGWzpdUQGdfnMGHuEtabvlZzxuOwYdatfAqX4A25pFs61pRzwjQ3FrI8fgX5177wPcWrek5aqluLUOIT9Ja/YZaONVBccGdUnfvtOCWZZflz78ENeQYFp8vwTXkBAKtFoMfxSd9nd/mCNPDeD0hInUHjMKO39/C2db/lyd/SnOgcE0/mohzkFBxg67Xo93TF+ydu00mw8uSk+P4oH9lQf3PQc8Pj6ewMBAs/tcXFzw9/fnwgXjmdpRo0YxZcoUOnTocIdnuLs9e/ZQs2ZNateuTUREBOvXr+eRRx6hY8eOTJ8+nZCQENq3b09MTAwRERFcuHABf39/XP5S/QkMDCQ+Pp6oqDsPqzl79iyffvopbdq0YejQoXz55ZcMHz4cAA8PD2JjY0lLS6N///6sXLkSR0dHPvroIz777DNGjRrFiBEjyM3NxdHRkRUrVtCnT59/tJ8PQu+uPjwcbTxLfOr8DbOKt5eHeUUcICWtEC9P2xIx1XztqOptx5czmxvv97Tl8+nNGTL+GOmZFX9osLebC9rbhl9qM7Pwcnc2j3F3oVltfzRqFX5V3Knp48mV5HSa1Kqk85Zvo8vOQOl6ayqD0sUdfVaGWYx9SDsyFxpHyRRfPY9CrUHh4IQh13ykQWVUlJqCjdetiq3Gy4uiVPMv86K0NC68NREApZ09bpFRpnneSgcH6k6dzrWvPudm/ImyS7ycKEhKxraar+m2bTUfCpKSzWO0KRx9bgQAKgd7vHt0ojg7B7/+j5J14Ai6P06mpW2Kw7VlCzL3HCyz/K1B/jUt9v6+/PmutvPzJT9RS/41LR5RrU1xdv4+pG+rfMMw869rsfOrarptV82H/Otas5iCpBQODxwBgMrRAZ+enSnOzsH/6UfJ3H8UXa6xKJD6exxurQLJ3F15jsGCpGTsqt72Hvb1pkBr3n6FySkcH2pcHEzlYI9Xl04U59z6/vDu/hCpGzZjKK48i8f+qTA5GZvbRgzY+PhQ8JcOYWFKKqdGjwFAaW+PZ3RHdDdu/LHNGFuQmEjW/gM4NmxAfkJCGWVveYUpKdh43/oOtvHyLtGhLkpL5dzEcYCx/dyjOqC7cQOnps1watEC75i+KO3tUWo06PPySJg3p0z3oaKp6Iuw/aeXIQsPDwdg165/tvjFsmXL6Nu3LwB9+vRh2bJlADg5ObFt2zY++ugjPD09ee6551iyZMm/zs/f3582bdoA8Nhjj5nlGRNjXPxk3759nD59mi5duhAREcH333/P1atXUavVREdHs27dOoqLi9mwYQPdu3f/17n8V1au0zJozFEGjTlK3N50urQ3DplpXM+J3Ju6Ep3n9Mwicm/qaFzPOH+5S3svduxL5+KVm8Q8v58nXj7EEy8fIiWtgBdfP1opOt8ATWpV40pyOompGRQVF7N+33Hat2hoFtMhsCH7zxgXNMnIyeWyNg2/Ku53erpKpzjxImpPH5TuVUClwrZ5KAWnzNd90GWlYRPQGACVV1VQa6Tz/YfcU6ew9auOjW9VFGo17h06kbVzh1mMysXVNGLA98kBpK0zrjKvUKsJeHsqaRvWkRm7taxTLxeyDx3HIaAGdjX8UGjU+PbuRsp689FYGg83U/vVevUFrn2/AoD8xOu4h7VEoVKhUKtxC2spQ9DvIHnNZvz69wbALbQFxdk5FCSlkLIhDq9OEajdXFC7ueDVKYKUDXGWTdYC/jwG7Wv4odBoqBrTneTf7n4M1h4xiMQlfxyDCdfxCL91DLqHt6x0Q9Bzjp3AvlYN7PyN72GfHl1J3bTNLEbj7mZqvxqDnyfp55Vm270f7oa2Eg4/B8g5cRL7GtWxrVYNhVqNV5eHSN9q3n5qNzdT+/k/9yzJq1YDoHJ2RqHRmGJcAltw80LlOv5yT8VjW706NlWN38EenTqTsWO7WYza9dZ3cNUBA0lZuwaAC++8ydG+vTn6vxiufvYpqet+lc63uKf7roA3bNiQVatWmd2XnZ1NQkICAQEBpqHno0ePZubMmajV9/fUOp2O1atX8+uvvzJz5kwMBgMZGRnk5OTg7OyMSqUiMjKSyMhImjRpwnfffUfv3r1JSEgwxfzp8OHDdO3a9X53CcVtw18dHR0B43D4Dh068OWXX5aI79OnD1988QXu7u4EBgaavXZ5sPtgJqHB7iyZHURBgZ7355wzbVswozmDxhwF4KMFFxg3tC42Nkr2Hspkzx8roFdmapWKsf268/JH36LX63kkPIg61byZs2ozjWtWo31gQ8Ka1GXXyfP0eXM2KoWCEX0fws3JAYDnpn/JxaRU8goK6fL6LN4c+AhhTepaeK/KkF5PzprFuD0zGoVCSd7B7eiSr+EYHUNR4kUKTx3mxq8/4BzzLPbhDwGQs+zWJXo8R89EYWsHKjW2jYLJ/Hqm2QrqFZ5ex9VPP6Du+x+gUCpJ+20t+ZcvUvWZ57l5+hRZu3bgHBhEtecHA3Dj6GGufvIBAO7tO+LcPBC1iyueXYwnBS9Pn0Le+XN3fbmKxqDTcXr8VIJ/mI9CpeLa9yvIPX2eOq8PJfvICVLWb8U9rBX1Jo7AYDCQufsA8eMmA6BdswGPiNa02boCDAbStsSRumHbPV6x4gn8dhaeUa2xqeJOx4vbOPvOpyg0xu/xK5//QPJv2/DqFkX7UxvR5eVxdNAEAIoysjg7dQ4Ru4zrt5yd8hlFGXdfzK2iMuh0xI+dQshPn6NQKUn8zngM1h03jKzDJ0hZtwWP8NbUe2MEGAxk7NrPydeNx2DS6g14RIYSFrcCDJC6KY6U9Vstuj9lzaDTcebtabT4ai4KlZLrP6/k5rnz1H71ZbKPnSBt8zbcQlsSMOoVMEDmvgOceXuq6fF2ftWw8/Ulc28lvRKJTseF96fTZM5sUKpIXrWKvAsXqDHkJW6cPEn6tlhcW4ZQc/gwMBjIPniI89PeA4yLs9WZOBEMelAoSfj6G7PV0ysFnY4rH8ykwQcfg1JJ6tpfyL94kWrPv8DNU6fI3LEd56Bg/Ae/DBjIOXyYyx/MsHTWFZqlFktbsGABn3zyCVqtloYNGzJt2jTCwsLu+bhdu3bx8MMPU79+/fsqRCsyMzPva7Lgnx3TwYMH069fP3Q6HSNHjsTZ2ZmuXbsye/Zsli5dCkB0dDRarZa5c+cSGRlJjx49mDx5MkFBQSWed/PmzcyePZvly5eb7nvppZeIioqiZcuWKJVK6tSpA8DkyZPJyspixowZTJgwgRs3bvDhhx+iUqn4/vvvmT9/Plu2bDHrWP/p8uXLtGjRgg0bNtC6dWuGDx9O/fr1GT58OM2aNWPr1q14enqSmppK+/btWb16NQEBAeTm5nL9+nXq1q2LTqcjMDCQ4OBgevfubaqa387V1ZX2j1ayy1/8R7b+3BaAm9t+sHAm1skh6gkAkic+Y9lErJT3lG8AOBgd8feB4q6CNxkrnxt9mlo4E+vUWWu8bORaTQMLZ2KdehSdBmC9ZxMLZ2KduqQZp69sqdfCwplYpw5njwCwIyjEwplYr/BDBwDYF9HGwplYp1Zxu8nKqhgnQM9rH9xUkjo+dy4SL1++nBdffJFZs2bRpk0bFixYwHfffcfu3bupXr36XZ8vMzOTqKgo6tSpw/Xr1++rA37fQ9AVCgWLFy9m5cqVBAcHExISgq2tLZMmTSoRO2rUKBLuc+7Izz//zMMPP2x2X69evVi2bBm5ubkMGTKE0NBQwsLCOHXqFOPGGedfvPnmm9ja2hISEkJwcDArV65k8eLFd+x8/6levXosWLCA1q1bk5mZyfPPP18ipkqVKnz22Wc8//zzhIWF0blzZ86cOQMYF57r2rUrv//+O126dLmv/RNCCCGEEEIIcX8MKB7Y39189tlnPPnkkwwcOJAGDRowY8YMfHx8+Oqrr/4212HDhtGvXz9atWp13/t330PQwTiH+s8q9+3+HCL+p+7du5OZmWm6vXbt2rs+55w5JedJdO/e3TS/esOGDXd8nK2tLTNm/LPhH2q1ms8//7zE/ceOHTO7HRUVddfV3GfMmPGPX1cIIYQQQgghRPlTWFjI4cOHTYtz/6ljx47s2bPnro9bsGABKSkpjBkzhunTp9/36/2jDrgQQgghhBBCCPGglPUc8LS0NHQ6HV5/uf67l5cXycnJd3zMiRMneP/999m4caPpstj3q0w74NHR0RQUFJjdN3/+fJo0+e/ma6Wnp9OrV68S969evfofr84uhBBCCCGEEEL8qaCggOeee453332XWrVq/ePHl2kHfNOmTQ/8NTw8PIiLq3yXQBFCCCGEEEIIa1fW1wH39PREpVKR8pfrv6ekpOB92zXi/5SUlMTp06cZOnQoQ4cOBUCv12MwGPD09OSnn36iY8eOd309GYIuhBBCCCGEEKJSsrGxITAwkC1bttC7d2/T/Vu2bLnjyOpq1aqxc+dOs/u+/PJLtmzZwuLFi6lRo8bfvp50wIUQQgghhBBClAuWuA740KFDGTx4MCEhIYSGhvLVV1+RlJTEs88+C8DgwYMB4/RpjUZD48aNzR5fpUoVbG1tS9x/J9IBF0IIIYQQQghRLugt8Jp9+vQhPT2dGTNmoNVqadSoET/++KOpmn2/l9i+H9IBF0IIIYQQQghRqQ0aNIhBgwbdcdvfXVYbYPz48YwfP/6+Xkc64EIIIYQQQgghyoUHOwTd8ACf+/4oLZ2AEEIIIYQQQghRGUgFXAghhBBCCCFEufBgL0MmFXAhhBBCCCGEEKJSkAq4EEIIIYQQQohywRKXIStLUgEXQgghhBBCCCHKgFTAhRBCCCGEEEKUCw92DrjlSQVcCCGEEEIIIYQoA1IBF0IIIYQQQghRLugtv1D5A6XIzMys4LtYtlxdXS2dghBCCCGEEKKSycrKsnQK/4nDCZoH9tyB/kUP7LnvlwxBF0IIIYQQQgghyoAMQX8AOvXbb+kUrNLv37cE4MaeNRbOxDo5hfYEIGPayxbOxDq5j58DwKn/PWThTKxXw582ALAjKMTCmVin8EMHAFjv2cTCmVinLmknAFiraWDhTKxTj6LTAKxzaWThTKxT1+x4AH73b2bhTKxXp4RjAMQ2DbJwJtap3fFDlk7hPyOXIRNCCCGEEEIIIUSpSQVcCCGEEEIIIUS5YKjgK5RJBVwIIYQQQgghhCgDUgEXQgghhBBCCFEu6JE54EIIIYQQQgghhCglqYALIYQQQgghhCgXKvoq6NIBF0IIIYQQQghRLsgibEIIIYQQQgghhCg1qYALIYQQQgghhCgXDLIImxBCCCGEEEIIIUpLKuBCCCGEEEIIIcoFvcwBF0IIIYQQQgghRGlJBVwIIYQQQgghRLlQ0S9DJhVwIYQQQgghhBCiDEgFXAghhBBCCCFEuSDXARdCCCGEEEIIIUSpSQVcCCGEEEIIIUS5oK/g1wGXDngFM3RgdVoHulJQqGf63Eucu3SzREy92g68/lItbGyU7D2cxWcLrwLwzP+qEdbSDb0eMrOLmDHvEmkZRWW9Cxaz8+gpZi5ehU6vp3dUKM/27Gi2ffX2fXz8wy94u7sC8FincGLahwLwydJfiDscD8CgRzrzUJvAMs29PFAHNMah0/9AqaDg8E4Kdm8w224f3Rd1zfoAKDQ2KBycyfpwtHFbhxg0dZqAQknRpXjyNv5U5vlbmmNgS7yfHYJCqSRz0zrSVy41266u4kXVoWNQOTqBUknKki/JPbQP1Gp8X3wVuzr1Qa8n+eu53Dx51EJ7YTluYW0JGDMalCq0K1eS+PU3Ztttq/pS98030bi7U5ydxZmJb1CYnAxA2P695J47B0BhUhLxI14r6/QtrkrHCBpOG4dCqSJh8TIufrzAbLudf1WafjoZG093ijKyODpkHAXXtADUf3MUXg+1A6WCtK27ODV+miV2waKafzEV7+7tKUxOIzao5x1jGn84Ee+uUejy8jny/DiyD50EwG9Ab+qNHwLA2WlzSfx2ZVmlXa5U6RRBo/cngEpJwsKfufjhX47B6tVo9tlkbKp4UJSRxZEXXr91DL49Cq8uUQCcnz6XpOW/lXn+lubZPpz6b49FoVKR+P1yLn/2pdl2O7+qNJ71DhpPD4ozszj+yngKrhvbr+7EkVTp2A6FUkna9l2cmfSeJXbBotzDw6gzbgwKlZKkZSu5+uXXZtttq1al/rtvovFwpzgrm1PjJlKoNX6H2Pr6Uv+dSdj6+mAwwPEhwyi4dt0Su1FhVPQh6NIBr0BaB7ri52vHwJHHaVTXkVefr8HwN06ViHv1uZp88MVl4s/lMnVsPVq1cGHfkWx+/CWJb366BkDvLt7071OVj7+8Uta7YRE6vZ73Fq1gzusv4uPhyoA3PyYquDEBfr5mcQ+FtmDs033M7tt++CSnLiXy3eTXKCou5sWpcwlr0RAne7uy3AXLUihweOhxbvzwCfrsTJyfGUvR2aPo05JMIXmblpn+bxvSHpWPPwAqvwDU/gFkfzkFAOcBo1DXqEfxlbNluw+WpFTi8/wwrr47jqL0VGpN+5Qb+3dRmHDr/Vel71Pk7Iolc8Mv2PjXoPr4yZwf+jRu0d0AuDRqMCoXN6pPnMKlccMq/rfX7ZRKAsaN48SQlynUammx5FvSt20j78JFU0itkSNJXruWlDW/4NqqFTWHD+PsG5MA0BcUcOSJJy2VveUplTSaPpH9fV8g/5qWtr8vJXndFnJPnzeFNHhnDNeWrubaD6vwiAyl/hsjODZkPG6tAnELDWJHZAwAob9+i3t4KzJ27LPU3lhEwsLlXJqzmMCv3r/jdq+u7XCsW4utjR7CLbQFTWe/xc7wx9C4u1L//4YR16YvBoOByD3L0a7ZTHFmdhnvgYUplTSe9Qb7Hnme/EQtbbf+SPKv5sdgw8ljSPxhFde+W4VHu1Dqv/Uax14ci1eXKFxaNGZneAxKWxta/7qQlI2x6HJyLbhDZUyppMHkiRx68kXyryfReu0PpG7YQu7ZC6aQem+M5vrPa7j+82rcw1pTd9yrnHh1Aq4hLXBrGcTuzn0BaLliEe5tW5Kxa7+l9qbsKZXU/b9xHHthCAVJWoKWLiFtyzZuXrjVfgGjR5K8ei3a1Wtwa92K2iOGc3r8GwA0mPYuVz5fQOauPSjt7SvX96/4V+57DnhiYiL9+vUjODiYwMBAxo4dS2FhIdu3b8fNzY3ffrt1tvHxxx9n+/btAPTo0YNDhw7d9Xm//fZbwsLCCAsLo23btqxduxYAg8HAjBkzCA4OJiQkhIcffpj4+HjT45o1a8aAAQNMt1etWsWQIUPuf88roLAQNzZuTwMg/lwuTg5qPNw0ZjEebhoc7JXEnzN+MW3cnkZ4S3cAbubpTXH2dkqoRJ8fJ85fobq3J/7enmjUah5qE8jWgyfu67EXE7UENQhArVJhb2tLverV2Hm05ImPikxVrRb6jBT0mWmg11EUfwCb+i3uGm/TuCWFJ//8cjeASgMqtfFPqUKfm1M2iZcTdnUbUJh0jaLkJCguJnvHNpxahpnFGAwGlPYOACgdHCnKML7Xbf1rcvP4YQB02Znocm8Yq+GViHPTJuRfvUpBYiKG4mJS1m/Ao317sxiHgNpk7TV2CrP27cOjfZQFMi2fXIObcfPiVfIuJ2AoKuL6il/x7tbBLMapQR3SY/cAkL59D97djCOEDAYDSlsblDYalLY2KDRqClPSynwfLC09bj9F6Vl33e7TK5rExSsByNxzBI2rC7a+Xng9FEHKph0UZWRRnJlNyqYdeHeJLKOsyw+3ls25eeEKeZeMx2DSsl/x6WE+Cs2xYV3St/1xDMbuwae7cbtjgzpk7NyPQadDdzOPnONn8OpUudrQNbAZeZeukHclAUNRMdpVv+H1kPl72LFeAOk7jO2XsXPvre0GUNraGt/DNjYo1WoKKtl72LlZU/KuXCU/4Y/vkN/W49mxvVmMQ50AMvfuBSBz7z48Oxi3OwQEoFCpyNxlbFt9Xh76/PwyzL5iMhgUD+yvPLivDrjBYGDAgAH06NGDgwcPcuDAAXJzc3n33XcB8PPzY9asWf/4xRMTE5k1axa//fYbO3fuZOPGjTRp0gSAL774gr179xIXF8eBAwd47bXX6NevH/m3HdSHDx/m1Kn/rqNTXFz8nz2XJVTx0JCSVmi6nZJeSBUPTYmY1PRbw8pT0sxjnn3Mj+9mN6djuKepGl4ZJGdk4ePpZrrt4+FGSkbJH1Ob9h3j8YmzeP3ThSSlZQJQr0Y1dh07TV5BIRk5ueyPP4c2PbNsEi8nlE5u6LMzTLf1ORkonF3vHOvigdLNk+LLpwHQJV6k+MoZXIdPw234exRdiDernFcGGo8qFKelmG4Xp6eg8fQ0i0n98Vtc2kVTZ94Sqo+fjParOQDkX76AU8u2oFSi8fbFLqAeGk+vMs3f0my8vSnUak23C7VabL3M2yD3zFk8Oxp/sHt07IDayQm1q/EYVdrY0GLJtzRf+E2JjntlYFfVh/zEW8Ml869psavqYxaTc/w03g93AsD74U6onZ3QuLuStf8I6XF7aX9yK+1PbiV18w5yz1xAmLOr5kNewq3PtfzEJOz8fLCr5kP+1dvuT9BiV83nTk9RodlW9TZvn2tabKv99Rg8hU+vzgD49OyM2sUJjYcbOcdPUaVTBEp7OzQebnhEtsbuL6PXKjrbqt7kX7+t/ZK02P7lPXwj/gze3Y3vYa9u0cb3sJsrWQePkLFzL5EHNtPu4GbStu3g5rmLVCa23t4UJN36DinQarHx/st3yOkzeHYyfod4dupo+g6xr1WD4pwcGn80k+Cfvqf2qBGglDWuxd+7ryMkNjYWW1tb+vfvD4BKpWLq1KksXryYvLw8mjZtiouLC1u2bPlHL56SkoKTkxNOTk4AODk5UatWLQA+/vhjZsyYgYODseLTsWNHWrduzY8//mh6/LBhw+674z9t2jRefPFFOnfuTHBwMAsXLgRg+/btdOvWjSeeeILQ0FB0Oh1vvPEGHTp0ICwsjK+/Ns4Bee6551i/fr3p+YYMGcKqVav+0f5ag69/TOTJYUfZvCONR7p4WzqdcqVdYGN++WAiS6eMIrRJfd78/HsA2jZrQHiLhjz37mwmzllMs7o1USnkw/duNI1DKDx1yDRES+nuhcrTl6zZE8mcPQFNrfqo/etYOMvyxyWiA9lbNnD+pae4Ou3/qDb8dVAoyNq8juK0VGq9/xnez7xE3umTGPT6ez9hJXPpww9xDQmmxfdLcA0JoUCrxaDTAbC/+8MceWoApydMpPaYUdj5+1s42/Ln9Jsz8AhvSdstP+MR1pL8a0kYdHocatfAqX4A25pFs61pRzwjQ3FrE2zpdEUFdHridNzDWxG2fRnuES3JT0zCoNORtnknKRtiabPxO1p8NYvMfYflM/AOzrw7E/c2LQld9yPubVqSf12LQa/HvlZ1HOsFENeqE9tbRuMeHopba3kP/9WFmR/i1jKE4J++x61lCAVJWgx6HQqVGtfgIC7M/JCDT/THzt8f3969LJ2u1dMbHtxfeXBfc8Dj4+MJDAw0u8/FxQV/f38u/DE/YtSoUUyZMoUOHTrc4RnurFmzZnh7e9OiRQvatWtHz5496datG9nZ2eTm5po6438KCgoyq3jHxMTw5ZdfmnK4lxMnTvD7779z8+ZN2rVrx0MPPQTAkSNH2LlzJ7Vq1eKbb74xnUwoKCigS5cudOjQgZiYGFasWEGXLl0oLCwkNjaWDz744L739UHp1dmL7h2NZ+nOXMjFy9PGtM3Lw8as2g2Qml5kVvH28iwZA7ApLp0pY+ux6OfKUQX3dndF+0dFG0CbnomXu3kF183Z0fT/3u1D+XjpWtPt53t14vlexjPLE+YsoUbVylWB1N/IROnibrqtdHbHkHPn4Zg2jVpyc8OtBcY09VtQfO0iFBUAUHT+BCq/AIoTzt/x8RVRUXoq6tuq1moPL4rSzIcAunXswtUpEwHIPxOPQmODytkVXXYmyQvnmeJqTP6QwusJZZN4OVGYnIyNz61qj42PDwUpKeYxKamcGj0GAKW9PZ7RHdHduPHHNmNsQWIiWfsP4NiwAfkJlacN869rsfOrarptV82H/Otas5iCpBQODxwBgMrRAZ+enSnOzsH/6UfJ3H8UXa5xwc/U3+NwaxVI5u6DZZa/Nci/psXe35c/xwnZ+fmSn6gl/5oWj6jWpjg7fx/St+21TJIWVHA9GXv/W1Vru2o+pgXWTDFJKRzu/wpgPAZ9ez1EcZZxutKFmfO5MHM+AM2/nEHuuUtlk3g5UXA9Gbuqt7Wfr49pgbU/FWpTOPrCSABUDvZ4dze+h/2e7EvWwaPobuYBkLYlDteQFmTurTzv4YLkZGx9b32H2Pr4UJj81++QFE6OMC4cq7S3p0qnaHQ5NyjQarlx6gz5CYkApG3egkvzZmWXvLBK/1mZLjw8HIBdu3bd92NUKhXLli1j4cKF1K1blwkTJjBt2v2vnqpSqRg+fPh9d4S7d++Ovb09np6eREREcODAAQCCg4NNnf3Nmzfzww8/EBERQXR0NOnp6Vy4cIHOnTsTFxdHQUEBGzduJCwsDHt7+/vO9UFZvTGFl8af5KXxJ9mxP5POkcZhq43qOpJ7U0d6pnnnOj2ziJt5ehrVNXYmO0d6svNAJgB+vramuLCWbly9llc2O1EONA6ozlVtKokpaRQVF7Nh92GigpqYxaTctijOtoMnqF3NOEJAp9eT+cdiL2evXOPc1Wu0aVq55uDqrl1G6e6N0tUTlCo0jUIoPFtyJW6lhw8KOwd0ibdOmumzM1BXrwcKJSiVqGvUq3RD0PPPncamqh8ab19Qq3EJj+LGfvPP0qLUFBybBQJg41cdhcYGXXYmChtbFLbGBf8cmgeDTm+2eFtlkHPiJPY1qmNbrRoKtRqvLg+RvnWbWYzazQ0Uxrlf/s89S/Kq1QConJ1RaDSmGJfAFmYL71QG2YeO4xBQA/safig0GqrGdCf5N/MRbRoPN1P71R4xiMQlKwDIT7iOR3hLFCoVCrUa9/CWMgT9DpLXbMavf28A3EJbUJydQ0FSCikb4vDqFIHazQW1mwtenSJI2RBn2WQtIOvAMRwCamJf03gM+vbtTvKvdz8GA157gYTFy40blErjNsCpSX2cmzQgbdOOMsze8rKPHMe+dk3sqvuh0KjxeaQbKRu3msVo3N1M7Vdr2CCuLf3jPZx4Hbc2t72H24SYLd5WGeQcP4F9jRrY+f3xHdKtC2lbtprF3P4dUuOF50hascr0WLWLMxp3YxHCrXUrcs9XrvZ7EAyGB/dXHtxXBbxhw4YlhltnZ2eTkJBAQECAaej56NGjmTlzJmr1/S+urlAoCAkJISQkhA4dOjB06FDGjx+Po6Mjly5dMquCHz582NTR/9MTTzzBhx9+SKNGje7rte5029HxVmXTYDAwffp0oqOjSzw+PDycTZs2sWLFCvr06VNiu6XtOZRF60BXFn3UlIICPTPmXzJtmzetMS+NN17y5JOvLzPmpdrY2ijYezibvYeNlcpBT/jjX80Og8GANqWQj768bIndsAi1SsXrT8cwbPoX6AwGHmnXijr+vsxdto7GtasTFdyEHzbEEXvoBCqlEhcnB9564QkAiot1DJryGQCO9na8+9KTqFUqS+5O2TPoublxKU5PDAOFksKju9CnXscu8mF01y9TdO4YYFx8rSjefGXVolMH0dSsj8ug/wMMFF04aYqvNPR6tF/OpvrEqaBUkrVlPYUJl6ny+NPknz/Djf27SV40H9/BI3HvYfzsuf7ZTADUrm74/99U0BsoTk/l2qd3XoW5QtPpuPD+dJrMmQ1KFcmrVpF34QI1hrzEjZMnSd8Wi2vLEGoON64On33wEOenGS+z4xBQmzoTJ4JBDwolCV9/Y7Z6emVg0OmIHzuFkJ8+R6FSkvjdCnJPn6fuuGFkHT5ByroteIS3pt4bI8BgIGPXfk6+PhmApNUb8IgMJSxuBRggdVMcKeu3WnR/LCHw21l4RrXGpoo7HS9u4+w7n6LQGH8LXfn8B5J/24ZXtyjan9qILi+Po4MmAFCUkcXZqXOI2PUzAGenfEbRHdYfqegMOh0nx0ym5YoFKFRKEr5dzo1T56g7cThZB4+T8tsWPCJbU/+t18BgIH3Hfk6OegcApUZN6LpvASjOyeXoC6+bppdUFgadjtNvTCVoyTwUShXXlq4g98x5AkYPJfvICVI3bsU9rBV1x72KwWAgc88BTk00XnlEu3Yj7uGhtPl9OQaDgbStO0j9fds9XrGC0ek4N/V9ms6fY7wM2YpV3Dx/gZpDh5Bz4iTpW7fh1qoltUcMx2AwkHXgIOcm/1Ew1Ou5MPMDmn05DwUKck7Gk/Tzcsvujyj3FJmZmfc8F2AwGOjQoQODBw+mX79+6HQ6Ro4cibOzM127dmX27NksXWocUhodHY1Wq2Xu3LlERkbSo0cPJk+eTFBQUInnvX79Olqt1jS8fdGiRaxdu5alS5cyb948tmzZwjfffIO9vT1bt27l1VdfZffu3djb29OsWTO2bt2Kp6cnCxYs4KOPPiIyMpK5c+fecR+mTZvG2rVrzYagb9y4kXPnzpnl/80337BhwwYWLlyIRqPh3LlzVK1aFUdHR9avX8+iRYs4fPgwhw4dwsbGpsTruLq60qlfJbp0w3/o9+9bAnBjzxoLZ2KdnEKN157NmPayhTOxTu7jjYuanfrfQxbOxHo1/Ml47fcdQSEWzsQ6hR8yjspa79nkHpHiTrqkGa9csVbTwMKZWKceRcaFMde53LugIUrqmm28Us/v/jL8+N/qlGA8+R7btGSfQdxbu+OHyMqqGCfwNp12fmDPHd3A8lfaua9StUKhYPHixYwaNYoZM2ag1+vp3LkzkyZNYu9e87lKo0aN4skn7+96qkVFRbzxxhskJSVha2tLlSpV+PDDDwEYPHgwmZmZhIWFoVKp8Pb25rvvvrvjsO8BAwYwc+bMe75ekyZN6NmzJ2lpaYwZM4aqVaty7tw5s5inn36aK1euEBUVhcFgwNPTkyVLlgDGheAGDx5M9+7d79j5FkIIIYQQQgjx75WXxdIelPseK+7v72+qEt8uMjKSyMhb11vs3r07mZmZptt/Xtf7TmrUqMGaNXeudioUCsaNG8e4cePuuP3YsVtDVG1tbe/rcmRNmzZl/vz5f5u/Uqlk0qRJTJo0qcTjNRoNly5duufrCCGEEEIIIYQQf3X/k7WFEEIIIYQQQogHqLwslvaglFkHPDo6moKCArP75s+fT5Mm/+1ct8WLFzNv3jyz+9q0aXNfQ9SFEEIIIYQQQogHpcw64Js2bSqT1+nfvz/9+/cvk9cSQgghhBBCCPHfqegV8P/sOuBCCCGEEEIIIYS4O5kDLoQQQgghhBCiXNAbFJZO4YGSCrgQQgghhBBCCFEGpAIuhBBCCCGEEKJckDngQgghhBBCCCGEKDWpgAshhBBCCCGEKBcqegVcOuBCCCGEEEIIIcoFfQXvgMsQdCGEEEIIIYQQogxIBVwIIYQQQgghRLlgkMuQCSGEEEIIIYQQorSkAi6EEEIIIYQQolyo6IuwSQVcCCGEEEIIIYQoA1IBF0IIIYQQQghRLlT0VdAVmZmZFXwXy5arq6ulUxBCCCGEEEJUMllZWZZO4T+x4tCD60/FBFm+jaQCLoQQQgghhBCiXKjoc8ClA/4AdBl42NIpWKX1CwMByNm71rKJWCnn1j0AyHx/mIUzsU5uY2cDcKZfVwtnYr3qf78OgD1tQy2ciXUK3bUHgC31Wlg4E+vU4ewRANa5NLJwJtapa3Y8AGs1DSyciXXqUXQakOOvNP48BjfXam7hTKxTx0tHLZ2CuE/SARdCCCGEEEIIUS5IBVwIIYQQQgghhCgDFX0RNrkMmRBCCCGEEEIIUQakAi6EEEIIIYQQolyo6EPQpQIuhBBCCCGEEEKUAamACyGEEEIIIYQoF/R6S2fwYEkFXAghhBBCCCGEKANSARdCCCGEEEIIUS7IHHAhhBBCCCGEEEKUmlTAhRBCCCGEEEKUCxW9Ai4dcCGEEEIIIYQQ5YK+gnfAZQi6EEIIIYQQQghRBqQCLoQQQgghhBCiXDBU8DHoUgEXQgghhBBCCCHKgFTAhRBCCCGEEEKUCxW8AC4VcCGEEEIIIYQQoixIBVwIIYQQQgghRLmg11s6gwdLOuAVzJCn/GjdwoX8Qj2zvrjCuct5JWLq1rJn9KAa2Noo2Xskm7lLEgEY9Hg12gS6UKQzcD25gFkLrpJ7U1fWu2AxO4/GM/Pblej1enq3b8MzPaPNtq+J3cvHP6zB290VgMc6R9C7fRsAPv5+DTuOnERvMBDapD6jB8SgUCjKfB8sSV27EfbRj4JSSeGRnRTs2Wi23a5jHzQ16htvaGxQOjiR9fHrxm3tH0FTpykoFBRfPEXepp/LOn2Lc2gRgvfTQ0CpJGvLOjJW/2i2Xe3phe+Q0SgdHVEoVaR+/xW5h/eBSoXPiyOwq1UXVCqyt28iY9VSC+2F5bi2aUPNEa+hUClJXr2a698uMttu4+tLwMT/Q+PmRnF2NuffeovClGTTdpWDI82//4H02G1cnjWzrNO3OI/IMOr931hQKbn+4wqufP6V2XbbalVpNO1tNB7uFGVlET96AgVJybiFtqLuxNGmOIeA2pwcMZbU37eU9S5YXJVOETR6fwKolCQs/JmLHy4w225XvRrNPpuMTRUPijKyOPLC6xRc0wJQ/+1ReHWJAuD89LkkLf+tzPO3pOZfTMW7e3sKk9OIDep5x5jGH07Eu2sUurx8jjw/juxDJwHwG9CbeuOHAHB22lwSv11ZVmmXK3L8lY5HVDj1Jo1FoVJyfelyLs81/wy086tKw+nvYPPHZ+DJERMoSNLi1rYV9d4YY4pzqFObE8NfJ3VD5fsMFPdPhqBXIK2aO+Pna8uzr8fz8ddXGT7Q/45xrwz056Ovr/Ls6/H4+drSsrkzAAdP5PDixFMM+b/TJCYV8MTD3mWZvkXp9HreX7icT8a8yE/vj2X9roNcSEwqEdc5NJDvpozmuymjTZ3vI2cucuTsRb6fOoal017n5MWrHDh1vqx3wbIUCuw7P0buT3PIWTAZm8YhKD19zULyNy8n55v3yPnmPQoObKPwzBEAVH61UfsFkPPVVHK+nIKqak3U1etZYi8sR6HE+9mhJL7/f1wa/SIuYe2x8athFuIR04+c3bFcGT+M659Mw/u5YQA4h0aiUGu4PHYIVyYMxy26O+oqPpbYC8tRKqk1agynXxvB0X5P4Nn5Iexr1TYLqTH8FVJ/+5VjA/qT+NWXVB/ystl2/xcHk334UFlmXX4oldR/awJHBr3M3m4x+DzcFYe6AWYhdce9RtLKNezr+T8uzf6cgFGvApC5Zx/7ez3O/l6Pc3jAC+jz8kmP22WJvbAspZLGs95gf98XiWvVk6qP9sCxQR2zkIaTx5D4wyp2hPXm3PtzqP/WawB4dYnCpUVjdobHsLvj49R+5VlUzo6W2AuLSVi4nL0PD7rrdq+u7XCsW4utjR7i2JA3aDr7LQA07q7U/79h7Ah/jLiw/1H//4ahdnMpo6zLETn+SkeppME7EzjyzBD2dO6Nd69uJT8DJ4wiafka9nZ7lEsfz6fO668AkLlrH/u6P8a+7o9xqN8g42dgbCX8DPyPGQwP7u/vLFiwgObNm+Pj40NUVBQ7d+68a+zq1auJiYmhTp06+Pv7Ex0dza+//npf+3dfHfDExET69etHcHAwgYGBjB07lsLCQrZv346bmxu//XbrTNnjjz/O9u3bAejRoweHDt39B01WVhaDBw8mKCiIwMBABg8eTFZWFgCXL1/Gzc2N+fPnm+LHjBnDkiVLABgyZAjNmzcnPDyckJAQBg8eTGJi4n3tdEXVNtiV33ekA3Dq/E0cHVR4uJoPcvBwVeNgp+LU+ZsA/L4jnbBgY0X34PEc05CP+PM3qeKuKbvkLezE+StU96mCv7cnGrWah9oEse3A8ft6rEKhoLComKLiYoqKiinW6fB0cX7AGZcvqqq10Gemos9KA72OwviDaOo1v2u8TeMQiuIPGG8YALUGVGrjn1KF/mZ22SReTtjVbUBR0nWKkpNAV0z2rm04tmxrHmQApb0DAEoHR4oz0kyblLZ2oFSisLHBUFyEPi+3LNO3OKfGjclPSKDg2jUMxcWk/74R93btzGLsa9Ume/9+ALIPHDDb7tCgIRoPD7L27CnTvMsLl+ZNybt8lfyriRiKitGuXUeV6PZmMY5165Cxay8Ambv3UqVT+xLP49W1M2mxcejz88sg6/LFrWVzbl64Qt6lBAxFRSQt+xWfHh3NYhwb1iV9m/EYS4/dg09343bHBnXI2Lkfg06H7mYeOcfP4NUpssz3wZLS4/ZTlJ511+0+vaJJXLwSgMw9R9C4umDr64XXQxGkbNpBUUYWxZnZpGzagXeXytV2IMdfabkENuXm5Sumz8DkNevweqiDWYxDvQAydhrbL2PXXqp07lDieby7dyZta+X8DKwIli9fzrhx4xg1ahSxsbG0bt2a//3vf1y9evWO8Tt27KBdu3b8+OOPxMbG0rlzZ/r37/+3nfY/3bMDbjAYGDBgAD169ODgwYMcOHCA3Nxc3n33XQD8/PyYNWvWP9xFo+HDh1OrVi0OHTrE4cOHqVmzJq+88oppu5eXF/PmzaOwsPCOj3/33XfZsWMH+/fvp3nz5vTq1euusferuLi4VI+3pCruGlLSiky3U9OL8PxLJ9rTXUNqhnnMnTraXSI92Hcs58ElW84kZ2Th4+Fmuu3t4UZyRskfA5v3HeWJCTN4/ZNvSErLAKB5vVq0bFSXrsPfosvwt2jTrCG1/SpXBVLp7Io+O8N0W5+TgdLJ9Y6xChd3lK6eFF8+DYDu2kWKr5zFdegUXIdNpfhiPPo0bZnkXV6o3T0pTksx3S5OS0Xj7mkWk7ZsMS4RHak9+1v8Xn+H5G/mAJCzZzv6gnwC5n5HwKffkvHLMvS5N8o0f0uz8fKmMPnWMVOYnIzGy8ss5ua5s7i3N/5gco9qj8rREbWLCygU1HzlFa58+kmZ5lye2Pp6k3/91oifgqRkbH3MP8NunDqNVxfjtJwqD0WjdnJC7Wb+Hvfp0ZXkX9Y9+ITLIduq3uQl3GrD/GtabKuZt2HO8VP49OoMgE/PzqhdnNB4uJFz/BRVOkWgtLdD4+GGR2Rr7PzMRxBVdnbVfMzbNzEJOz8f7Kr5kH/1tvsTtNhVq1zfvyDHX2nZ+viYhuMDFFzXYutjPgr0RvwZvLp2AsCrSzRq5zt8BvbshnZ15Ru+/yDoDQ/u724+++wznnzySQYOHEiDBg2YMWMGPj4+fPXVV3eMf//99xk5ciQhISEEBAQwbtw4AgMDWbt27T33754d8NjYWGxtbenfvz8AKpWKqVOnsnjxYvLy8mjatCkuLi5s2fLP5jpcuHCBw4cP8/rrr5vuGzt2LIcOHeLixYsAVKlShaioKL7//vu/fS6FQsHQoUPx9vZm48aNd43z8/Nj/PjxtGnThl69epGamgoYK/Xjxo2jffv2zJ07l8OHD9O9e3eioqLo06cPSUlJnDlzho4db51NvHz5MmFhYf9on61Fv54+6PQGNu/MuHdwJRIZ1IQ1H77BD1PHENq0Pm/NNx6XV7UpXLym5deP3+S3T95k/8mzHDp9wcLZll82jUIoOn3YNA5I6VYFlacPWXP+j6zPJqKuWR+Vf52/f5JKyDmsPdmxG7k4bACJ0yfh+/IYUCiwq9MA9HouvPwUF18diHuPvmi8K9ePp/tx5dNPcAkKounCRbgEBVOYnIxBr8enb18yd+40mw8uSjr33ge4tW5Jy1VLcWsdQn6SFnS3Vsmx8aqCY4O6pG+/95n/yur0xOm4h7cibPsy3CNakp+YhEGnI23zTlI2xNJm43e0+GoWmfsOY6joKxCJMifHX+mcmzILt9AQWq1dilubluRf15qtFGb6DIyVz8D/QlkPQS8sLOTw4cNmfT2Ajh07sucfjI67ceMGbm5u94y75yJs8fHxBAYGmt3n4uKCv78/Fy4YOxmjRo1iypQpdOhQcjjG3Zw6dYpmzZqhUqlM96lUKpo1a0Z8fDxNmjQBYMSIETz66KOmEwB/p0WLFpw9e/au23NzcwkKCmLatGm8//77vP/++8yYMQOAoqIitm7dSlFRET169OC7776jSpUqLF++nHfffZfPPvuMwsJCLl26RK1atVixYgUxMTH3vb8PSs/oKnSLMlbKzly8iZenBv5ogioeGtJuq3YDpGWYV7yreJhXxDtHeNA60IVx75978MmXI97urmjTM023k9MzTYut/cnttjlRvdu34ZMffgFgy/5jNKtbEwc7WwDCmjfk6NlLBDUwnz9UkelzslC6uJtuK53d0d+483BCTaMQ8jbeWmBMU78FxdcuQZFx9ErRhROoq9VGl1B55tEXZ6Sh9rxVsVV7VqHotiHmAK4dupA4bSIA+WfjUWhsUDm74BLegdwjB0CnQ5edRd6ZE9gG1DMOZ68kClOSsfG+Ve2x8famKCXFLKYoNZWz48cBoLS3x6NDB3Q3buDUtBnOLQLx6dsXpb0DSo0G/c2bXJ07p0z3wZIKkpKxq3rrpI2trzcFWvNRKIXJKRwfapwzqnKwx6tLJ4pzbo2S8u7+EKkbNmOw4lFkpVFwPRl7/1ttaFfNvKIGUJCUwuH+xlF+KkcHfHs9RHGWsQ0vzJzPhZnGKXfNv5xB7rlLZZO4lci/psXe35c/ywJ2fr7kJ2rJv6bFI6q1Kc7O34f0bXstk6QFyfFXOgVa8xEDtlV9KNCan5QtTE7h+Eu3fQZ27URx9m2fgQ93IWV95f0MtHZpaWnodDq8/jJ6zsvLi+Tk+ztB/8UXX3Dt2jUef/zxe8b+J4uwhYeHA7Br13+/6ECtWrUICQnhp59+umes4R4z65VKJX369AGMc9Vvz/fPzvTZs2eJj4+nd+/eREREMHPmTK5du2aKWbFiBWCcJ/Dnc1nSmk2pvDzpNC9POs3Og1l0CvcAoGEdB27m6UjPMv8gSM8q5ma+joZ1jHNJO4V7sOugsaPUspkz/+vuzVsfXaCg8B6rFFQwjQOqczUphcTkNIqKi9mw+xDtgpuaxaRm3pqXHHvwOLWrGYcn+Xq6c/DUeYp1OoqLdRw8dYHalWwInO76ZZTuXihdPUGpwqZRMEXnjpaIU3r4oLRzQJd40XSfPjsDdfW6oFCCUom6ej10aZWn8wiQf/40Gt9qqL18QKXGpW0UuQd2m8UUpybj0DQIAJtq1VHa2KDLzqIoNRmHJi0AUNjaYle3IYXXEsp8HyzpRnw8dtWrY1u1Kgq1Go9OncnYHmsWo3Z1hT+uTFDt6YEk/7IGgPNvvcnhmEc43CeGK59+Qspvv1aqzjdAzrET2NeqgZ2/HwqNGp8eXUndtM0sRuPuZmq/GoOfJ+nnlWbbvR/uhraSDj8HyDpwDIeAmtjX9EOh0eDbtzvJv5qPDNR4uJnaMOC1F0hYvNy4Qak0bgOcmtTHuUkD0jbtKMPsy7/kNZvx698bALfQFhRn51CQlELKhji8OkWgdnNB7eaCV6cIUjbEWTZZC5Djr3RyjpzAoVZN02egd8+upG7cahZz+2dgzZcHcf3HFWbbfXp1Q7tGhp//Vwx6wwP7exBWrVrFpEmT+OKLL6hRo8Y94+9ZAW/YsCGrVq0yuy87O5uEhAQCAgJMQ89Hjx7NzJkzUavv78pmDRs25NixY+j1epRK43kAvV7PsWPHaNiwoVnsqFGjGDhwoKmjfzdHjx4lKirqvl4fMLtMlKOjsbppMBho2LDhHYey9+nTh4EDB9KzZ08UCgV16pSvYbJ7j2TTqrkzX89oREGBnlkLrpi2zXmnAS9PMs65/XRhAqNfqIGNjZL9R7PZd9R4Bm/oAH80agXTxtQF4NT5XD5ZWDl+yKtVKsY83YfhMz5Hp9fTq11r6vj7Mm/ZbzSqXZ2o4Kb8sD6W2EMnUCmVuDg58NaL/QCIbt2CfSfP8sSEGShQ0LZ5Q9oFN7HwHpUxg568jT/i+NhQUCgoPLYbfWoSdhE9KE66QvG5Y4Bx+Hnhn4uv/aHo9CHUNevj/PwEMBgouhhP8fn7WwCvwtDrSflmDv7jp4BSSfbWDRQmXMbz0QHkXzxL7oHdpCz+Ap8XXsW9ewwGg4Gkuca1NzI3rMH3pVHUnGGsXmRv20jhlYt/92oVj07HpVkzafDRJyiUSlJ+WUPexYv4vfAiufHxZMZtxyU4hOpDXsZgMJBz+BCXZs6wdNblhkGn48zb02jx1VzjJXh+XsnNc+ep/erLZB87QdrmbbiFtiRg1CtggMx9Bzjz9lTT4+38qmHn60vm3v0W3AvLMuh0nBwzmZYrFqBQKUn4djk3Tp2j7sThZB08TspvW/CIbG1cedpgIH3Hfk6OegcApUZN6LpvASjOyeXoC69j0FWeS4ACBH47C8+o1thUcafjxW2cfedTFBrj78krn/9A8m/b8OoWRftTG9Hl5XF00AQAijKyODt1DhG7jJeuPDvlM4rusH5LRSfHX+kYdDrOTJpK4KK5KFQqrv24ktyz56k98mVyjp0k9fetuLVpZVz53GAgc+9BTk+aYnq8nX817Kr6kLm78n4GWjtPT09UKhUpfxk9l5KSgrf3318VatWqVbz00kvMmzePbt263dfrKTIzM//2VIDBYKBDhw4MHjyYfv36odPpGDlyJM7OznTt2pXZs2ezdKnxmrPR0dFotVrmzp1LZGQkPXr0YPLkyQQFBd3xufv370+zZs0YO3YsYJzMfvz4cb799lsuX77ME088YapSP/PMM+zfv5/x48fz1FNPMWTIELp27cojjzyCwWBg/vz5fP755+zevRsbG5s7vp6bmxtffvklffv2ZcaMGSQnJzNjxgyzPAsLCwkNDWX+/Pm0bt2aoqIizp07R6NGjQDo0KED9erVo0mTJrz66qslXsPV1ZUuAw/fV+MLc+sXBgKQs/feixeIkpxb9wAg8/1hFs7EOrmNnQ3AmX5dLZyJ9ar/vbECuqdtqIUzsU6hu4zzzLbUa2HhTKxTh7PGSxuuc2lk4UysU9fseADWahpYOBPr1KPIWOSQ4+/f+/MY3Fzr7ldREXfX8dJR09WkrN383x/c1YQGd7rzItPR0dE0bdqUjz/+2HRfSEgIvXr14s0337zjY1asWMGQIUOYO3fuP5qafM8h6AqFgsWLF7Ny5UqCg4MJCQnB1taWSZMmlYgdNWoUCQn3XzGdPXs258+fJzAwkMDAQM6fP8+nn356x9hRo0aVuMzYG2+8YboM2cGDB1mzZs1dO99grHIfOHCAtm3bEhsba+r4387GxoaFCxfy5ptvEh4eTmRkJHv33ppP1KdPH3788Ud69+593/sphBBCCCGEEKJ8Gjp0KN999x2LFi3i9OnTjB07lqSkJJ599lkABg8ezODBg03xy5Yt44UXXuDNN98kLCwMrVaLVqslI+Pei1jfswJekfj5+T3wa4VLBfzfkwp46UgFvHSkAl56UgEvHamAl45UwEtHKuClIxXw0pMKeOlUpAr4vI0PrgL+Uue7X2Z5wYIFfPzxx2i1Who1asTUqVNNU6B79DD+zv7zMmM9evRgx46S6yWEh4ff81Jk9zdhWwghhBBCCCGEqKAGDRrEoEGD7rjtr53q+7ne992USQc8OjqagoICs/vmz59vutRYWb3eg65+CyGEEEIIIYT49/QPaLXy8qJMOuCbNm0qi5ex2OsJIYQQQgghhBD3IkPQhRBCCCGEEEKUC4aKXQCXDrgQQgghhBBCiPKhonfA73kZMiGEEEIIIYQQQpSeVMCFEEIIIYQQQpQL+gpeApcKuBBCCCGEEEIIUQakAi6EEEIIIYQQolww6C2dwYMlFXAhhBBCCCGEEKIMSAVcCCGEEEIIIUS5YJA54EIIIYQQQgghhCgtqYALIYQQQgghhCgX9BV8Drh0wIUQQgghhBBClAsyBF0IIYQQQgghhBClJhVwIYQQQgghhBDlgr5iF8BRZGZmVvBdLFuurq6WTkEIIYQQQghRyWRlZVk6hf/EjBX2D+y5x8TkPbDnvl9SARdCCCGEEEIIUS4YKngJXDrgD0C7mDhLp2CVYldEAHBjzxoLZ2KdnEJ7ApA1Y7iFM7FOrmM+BeBMv64WzsR61f9+HQD7o9paOBPr1HLbLgB2BIVYOBPrFH7oAAC/+zezcCbWqVPCMQDWuTSycCbWqWt2PABrNQ0snIn16lF0GoBfHRpaOBPr1P3mKUunIO6TdMCFEEIIIYQQQpQLFXwRdFkFXQghhBBCCCGEKAtSARdCCCGEEEIIUS7oK/gccKmACyGEEEIIIYQQZUAq4EIIIYQQQgghygVDBZ8ELh1wIYQQQgghhBDlgkFv6QweLBmCLoQQQgghhBBClAGpgAshhBBCCCGEKBf0FXwIulTAhRBCCCGEEEKIMiAVcCGEEEIIIYQQ5UJFX4RNKuBCCCGEEEIIIUQZkAq4EEIIIYQQQohyQa+XCrgQQgghhBBCCCFKSSrgQgghhBBCCCHKhQo+BVwq4EIIIYQQQgghRFmQCrgQQgghhBBCiHLBUMHngEsHvIJ55fkA2oS4U1CgZ9qnZzhzIbdETP0ARya8Uh8bGyW7D2TwyZcXTNv6dK9KTLeq6PUGdh3IYN6iS2WYvWXtPHqKmYtXodPr6R0VyrM9O5ptX719Hx//8Ave7q4APNYpnJj2oQB8svQX4g7HAzDokc481CawTHMvD9S1GmEX3RcUSoqO7qJg70az7XYd+qCuUe+PYBuUDk5kfzoWVfV62HfsY4pTevhwc803FJ87WpbpW5xDixC8nx4CSiVZW9aRsfpHs+1qTy98h4xG6eiIQqki9fuvyD28D1QqfF4cgV2tuqBSkb19ExmrllpoLyzHpXUbagwfAUoVqWtXk/Tdt2bbbXx8qTV2Imo3N3TZ2VyY8hZFKSnY+PhSZ/J7KBQKFGo1yct/JmX1CsvshAW5hbUlYMxoUKrQrlxJ4tffmG23repL3TffROPuTnF2FmcmvkFhcjIAYfv3knvuHACFSUnEj3itrNMvFzzbh1P/7bEoVCoSv1/O5c++NNtu51eVxrPeQePpQXFmFsdfGU/BdS0AdSeOpErHdiiUStK27+LMpPcssQsWVaVTBI3enwAqJQkLf+bihwvMtttVr0azzyZjU8WDoowsjrzwOgXXjO1X/+1ReHWJAuD89LkkLf+tzPO3tOZfTMW7e3sKk9OIDep5x5jGH07Eu2sUurx8jjw/juxDJwHwG9CbeuOHAHB22lwSv11ZVmmXG1U6R9B4xkQUKiVXv/mZC7O+MNtuV70azedNuXX8PT+G/ETj8dfg3VF4dzUef+fem8v1ZZXv+Puv6Sv4GHTpgFcgbYLd8a9mx5MvH6BxfWdeG1yXl8YeKRE36qW6TJ9zjpNncpj+RmNCg93ZczCDoKauRLT25LmRhygqNuDmqrHAXliGTq/nvUUrmPP6i/h4uDLgzY+JCm5MgJ+vWdxDoS0Y+3Qfs/u2Hz7JqUuJfDf5NYqKi3lx6lzCWjTEyd6uLHfBshQK7Dr/j9wfP8OQk4nTgDEUnT+GPi3JFJK/Zbnp/zZB7VD5+AOgu3qWGwvfNz6NnQNOgyZRfCm+bPO3NIUS72eHkjh1AkVpqdSc8gm5B3ZTmHjFFOIR04+c3bFk/b4WG78a+I19l4uvDMQ5NBKFWsPlsUNQ2NhSa+bn5OzYSnGq1oI7VMaUSmqMGMWZUa9SlJJMo/lfkbljO/mXL5lC/F8eTtr630hb/yvOQSH4vziEi1PeoSgtlVMvv4ChqAilvT1Nvl5C5o7tFKWlWm5/yppSScC4cZwY8jKFWi0tlnxL+rZt5F24aAqpNXIkyWvXkrLmF1xbtaLm8GGcfWMSAPqCAo488aSlsi8flEoaTJ7IoSdfJP96Eq3X/kDqhi3knr11grveG6O5/vMarv+8Gvew1tQd9yonXp2Aa0gL3FoGsbtzXwBarliEe9uWZOzab6m9KXtKJY1nvcG+R54nP1FL260/kvzrFnJPnzeFNJw8hsQfVnHtu1V4tAul/luvcezFsXh1icKlRWN2hsegtLWh9a8LSdkYiy6nZAGiIktYuJxLcxYT+NX7d9zu1bUdjnVrsbXRQ7iFtqDp7LfYGf4YGndX6v/fMOLa9MVgMBC5ZznaNZspzswu4z2wIKWSJh9OYu/Dz5GfqCV8+08kr93MjVO3jr9G014n8btVJC5ZiWdUKA3efo0jg8bi1TUK18DGxLUxHn+h6xeRsiGW4kp2/Il/5l/PAU9MTKRfv34EBwcTGBjI2LFjKSwsZPv27bi5ufHbb7fO/jz++ONs374dgB49enDo0KG7Pm+zZs0YMGCA6faqVasYMsR4Vm7JkiXUqVOHyMhIgoOD6dOnD3v27DHFDhkyhFWrVv3bXbJ6Ea09WL/FWJE4eSYHJ0cVnu7mnWhPdw0O9ipOnskBYP2WZCJbewDwSFdfliy/SlGx8axTZlZRGWZvWSfOX6G6tyf+3p5o1GoeahPI1oMn7uuxFxO1BDUIQK1SYW9rS73q1dh59NQDzrh8UVWtiT4jFUNWGuh1FJ06gKZus7vGaxqFUBR/oMT96vqBFF88CcWV59gDsKvbgKKk6xQlJ4GumOxd23Bs2dY8yABKewcAlA6OFGekmTYpbe1AqURhY4OhuAh9XuX64nds1JiCxAQKr1/DUFxM+ubfcYtoZxZjX7MW2QeNHZqcQwdwCzduNxQXYygyHm8KjQaUirJNvhxwbtqE/KtXKUhMxFBcTMr6DXi0b28W4xBQm6y9+wDI2rcPj/ZRFsi0/HINbEbepSvkXUnAUFSMdtVveD3UwSzGsV4A6TuMv1kydu69td0ASltblDYalDY2KNVqClLS/voSFZpby+bcvHCFvEsJGIqKSFr2Kz49zEehOTasS/o2Y/ulx+7Bp7txu2ODOmTs3I9Bp0N3M4+c42fw6hRZ5vtgaelx+ylKz7rrdp9e0SQuXglA5p4jaFxdsPX1wuuhCFI27aAoI4vizGxSNu3Au0vlaj+3ls25ef7W8Xf951/xeTjaLMapYR3Stu4GIG3bHrz/2O7UsA7pO24//k5TpXPlar8HwaA3PLC/8uBfdcANBgMDBgygR48eHDx4kAMHDpCbm8u7774LgJ+fH7NmzfrXSR0+fJhTp+7cgenTpw/bt2/n4MGDjBgxggEDBnD69Ol//Vp/VVxc/J89V1mr4mlLclqh6XZKWiFVPGzNYzxsSflrjKcxpno1e5o3dmXe+y34ZHIzGtZ1KpvEy4HkjCx8PN1Mt3083EjJKPlFtmnfMR6fOIvXP11IUlomAPVqVGPXsdPkFRSSkZPL/vhzaNMzyybxckLh5IYhJ8N0W5+TicLJ7c6xLu4oXT0pvnKmxDabhnfumFd0andPitNSTLeL01LRuHuaxaQtW4xLREdqz/4Wv9ffIfmbOQDk7NmOviCfgLnfEfDpt2T8sgx97o0yzd/SbKp4mYZDAxSmJGNTxcss5ub5c7i3aw+AW2QUKkdHVC4uAGi8vGn81bc0/2kVSd8trlzVb8DG25tC7a0RE4VaLbZe5u2Xe+Ysnh2NHR6Pjh1QOzmhdjVOx1Ha2NBiybc0X/hNiY57ZWFb1Zv867eN+EnSYlvVxyzmRvwZvLt3AsCrWzRqZyc0bq5kHTxCxs69RB7YTLuDm0nbtoOb5y5SmdhW9SYv4bb2u6bFtpp5++UcP4VPr84A+PTsjNrFCY2HGznHT1GlUwRKezs0Hm54RLbG7i+j1wTYVfMxb+PEJOz8fLCr5kP+1dvuT9Bi95e2r+jsqvmQn3jddDsvMank8XfsNL6P/HH8PdIZzZ/H3zFjh1tpb4fG0w3PdqHY+1ct0/yF9flXHfDY2FhsbW3p378/ACqViqlTp7J48WLy8vJo2rQpLi4ubNmy5V8lNWzYsPvqwLdr146BAwfyzTff3NfzNmvWjEmTJhEWFkbHjh25cME4NGzIkCGMHDmS6OhoJk2axMWLF+nbty9RUVF069aNM2fOkJWVRdOmTdHr9QDk5ubSpEkTiooqTqVOpVLg4qTmpbFHmLvwIm+PbmjplMqVdoGN+eWDiSydMorQJvV58/PvAWjbrAHhLRry3LuzmThnMc3q1kSlkAsM3I2mYQhFZw6XuMaEwtEFpVfVyjf8/D45h7UnO3YjF4cNIHH6JHxfHmMc+l+nAej1XHj5KS6+OhD3Hn3ReMuPz79KmPMpzoFBNF6wEOfAIGOH/Y/P86KUZE4+N4DjT/6PKl27o3Z3t3C25c+lDz/ENSSYFt8vwTUkhAKtFoNOB8D+7g9z5KkBnJ4wkdpjRmHn72/hbMunM+/OxL1NS0LX/Yh7m5bkX9di0Ouxr1Udx3oBxLXqxPaW0biHh+LWOtjS6ZY7pydOxz28FWHbl+Ee0ZL8xCQMOh1pm3eSsiGWNhu/o8VXs8jcdxjDH+9tIf4r8ROm4xHZivBdy/GIaEXeH8df6qYdpKzfRtiW7wn6ZhYZew6bPhvFv1fRK+D/ag54fHw8gYGBZve5uLjg7+9v6tSOGjWKKVOm0KFDhzs8w9+LiYnhyy+/ND3X32nRosV9d8D/zHPnzp18//33jB8/nqVLjYsVXbt2jQ0bNqBSqejVqxcffvghderUYf/+/YwaNYo1a9bQrFkz4uLiaNeuHevXr6djx45oNJadJx3TrSoPdzaepTt17gbenjambV6eNqSmF5jFp6YX4PXXmDRjTEpqIbG7jcPe4s/eQG8w4OqiJivbekcF3C9vd1e0f1S0AbTpmXj9sdjan9ycHU3/790+lI+XrjXdfr5XJ57vZaxsTJizhBpVzatHFZ3hRiYK51udFqWzG4YbmXeMtWkYTN7vP5W4X9MgiOKzR02dosqkOCMNteetY0btWYWiDPMhqK4dupA4bSIA+WfjUWhsUDm74BLegdwjB0CnQ5edRd6ZE9gG1DMOZ68kClNTsPH2Nt228fKmMDXFLKYoLZXzb4wHQGlvj3u7Duhu3CgRk3fxAs7NA8nY9u9OIFujwuRkbHxuVXtsfHwoSDFvv8KUVE6NHgMY288zuqOp/Qr/iC1ITCRr/wEcGzYgPyGhjLIvHwquJ2NX9daJLztfH9MCa38q1KZw9IWRAKgc7PHu3pni7Bz8nuxL1sGj6G7mAZC2JQ7XkBZk7j1YdjtgYQXXk7H3v639qvmYFlgzxSSlcLj/KwCoHB3w7fUQxVnG6XQXZs7nwsz5ADT/cga55y6VTeJWJP+aFnt/X/4cq2bn50t+opb8a1o8olqb4uz8fUjfttcySVpI/jUtdn63qtb2fr4lj7/ryRzsd9vx1/vW8Xd++nzOTzcef4Ffz5TjT9zTAyvThYeHA7Br165//FiVSsXw4cP54IMP7hlr+Ier5D366KOmf/fuvfUB88gjj6BSqbhx4wZ79+5l4MCBREREMGLECLR/DM3r06cPK1YYV8ddtmwZffr0KfkCZWzFb9d5/rXDPP/aYbbvSaNLB+OP0Mb1ncm9qSMtw7xCn5ZRxM08HY3rOwPQpYM3cXvTAdi+N42gZsZOp381OzRqZaXofAM0DqjOVW0qiSlpFBUXs2H3YaKCmpjFpNy2IMm2gyeoXc3Y1jq9nsw/Fts4e+Ua565eo03T+mWXfDmgu34FlbsXCldPUKqMVe5zx0rEKT18UNg5oLtWcnilplEIhZVw+DlA/vnTaHyrofbyAZUal7ZR5B7YbRZTnJqMQ9MgAGyqVUdpY4MuO4ui1GQcmrQAQGFri13dhhReq1ydn9xT8dj5V8fGtyoKtRqPjp3I3LHdLEbt6goK4/zuqk89TepvvwCg8fJCYWOchqNycsapWXPyr16hMsk5cRL7GtWxrVYNhVqNV5eHSN+6zSxG7eZmaj//554ledVqAFTOzsa583/EuAS24OZ9nDyvaLKPHMe+dk3sqvuh0KjxeaQbKRu3msVo3N1MbVhr2CCuLTX+nshPvI5bm5YoVCoUajXubULMFm+rDLIOHMMhoCb2Nf1QaDT49u1O8q/mJ8E0Hm6m9gt47QUSFv+xsKdSadwGODWpj3OTBqRt2lGG2VuH5DWb8evfGwC30BYUZ+dQkJRCyoY4vDpFoHZzQe3mglenCFI2xFk22TKWdeAYjnVvHX9VH+2Odu1msxiNp5vp+Ksz5kUSFi0zbrjt+HNuWh/npvVJ/V2Ov9LSGx7cX3nwryrgDRs2LLHYWXZ2NgkJCQQEBJiGno8ePZqZM2eiVv/zl3niiSf48MMPadSo0d/GHT16lPr1/11nR6G4tdiOo6OxuqnX63F1dSUuruSHT7du3XjnnXfIyMjgyJEjtGvXrkSMJe0+kEHbEHe+nxvyx2XIzpq2fflBIM+/dhiAD+afZ/wr9bC1UbLnYAa7DxrPh/66Scu4YfX45uMgiosMTP2k5BzdikqtUvH60zEMm/4FOoOBR9q1oo6/L3OXraNx7epEBTfhhw1xxB46gUqpxMXJgbdeeAKA4mIdg6Z8BoCjvR3vvvQkapXKkrtT9gx68n7/CcdHXwalgqJju9GnJWEb3h1d0hWKzx8HQNMwmMJTJas6ChcPlM7u6K6eK+vMywe9npRv5uA/fgoolWRv3UBhwmU8Hx1A/sWz5B7YTcriL/B54VXcu8dgMBhImmucppO5YQ2+L42i5gzj2ffsbRspvFK55o+i03Hlo1nUn/kRKJWk/foL+ZcuUu25F8g9FU/WzjicA4Pxe3EIGAzkHDnMlY9mAsbF2fxffsU4JUKhIGnpd+RdOP/3r1fR6HRceH86TebMBqWK5FWryLtwgRpDXuLGyZOkb4vFtWUINYcPA4OB7IOHOD/NeJksh4Da1Jk4EQx6UChJ+Pobs9XTKwuDTsfpN6YStGQeCqWKa0tXkHvmPAGjh5J95ASpG7fiHtaKuuNexWAwkLnnAKcmTgFAu3Yj7uGhtPl9OQaDgbStO0j9fds9XrFiMeh0nBwzmZYrFqBQKUn4djk3Tp2j7sThZB08TspvW/CIbE39t14Dg4H0Hfs5OeodAJQaNaHrjJcdLM7J5egLr1fKIcCB387CM6o1NlXc6XhxG2ff+RSFxvj7+8rnP5D82za8ukXR/tRGdHl5HB00AYCijCzOTp1DxK6fATg75TOK7rAGTkVm0Ok48dq7tF79pfEyeIuWcSP+HPXeMB5/yWu34BkZSoN3RoIB0nfs48SIW8dfm42LASjOucHh5yvn8Sf+GUVmZuY/PhdgMBjo0KEDgwcPpl+/fuh0OkaOHImzszNdu3Zl9uzZpqHd0dHRaLVa5s6dS2RkJD169GDy5MkEBQXd8bmbNWvG1q1b8fT0ZMGCBXz00UdERkYyd+5clixZwuHDh5kxYwYAcXFxPPfcc6xZs4YGDRowZMgQunbtyiOPPHLX537uuecYOXIkS5cuZfny5SxdurTE4x566CFefvllevfujcFg4Pjx4zRrZlzReeDAgdja2uLs7HzHeequrq60i6lcZw7/K7ErIgC4sWeNhTOxTk6hxut+Zs0YbuFMrJPrmE8BONOvq4UzsV71v18HwP6otveIFHfScptxxNiOoBALZ2Kdwg8ZR9D87n/3KzCIu+uUYBy1tM7l7wsf4s66ZhvXL1mraWDhTKxXjyLjosq/OsgaRP9G95unyMqqGCdPxs57cNMR33/J8us0/asMFAoFixcvZuXKlQQHBxMSEoKtrS2TJk0qETtq1CgS/uVcsAEDBpRYlXz58uVEREQQEhLCBx98wKJFi2jQwPhhp9PpsLGxudNTmWRmZhIWFsa8efOYNm3aHWM+//xzvv32W8LDw2nTpg2//vqraVufPn348ccfiYmJ+Vf7JIQQQgghhBDizgwGwwP7Kw/+1RB0AH9/f1OV+3aRkZFERt66/l337t3JzMw03V67dm2Jx9zu2LFb80ZtbW3NLkf21FNP8dRTT93xcXq9ntOnT1O7du2/ff5XXnmFt99+2+y+uXPnmt2uVasWy5Ytu+PjH3nkEbP9EUIIIYQQQggh7se/7oCXJ9evX6d3795ERkbSsKEMWxFCCCGEEEIIa6QvL6ulPSAW64BHR0dTUGB+iaz58+fTpEmTuzzi7qpWrcqePXtMt5966ikuX75sFvP222+bVdeFEEIIIYQQQoiyZLEO+KZNmx7Ycy9ZsuSBPbcQQgghhBBCiAejvMzVflAsvwycEEIIIYQQQghRCVSIOeBCCCGEEEIIIayfoYLPAZcKuBBCCCGEEEIIUQakAi6EEEIIIYQQolyQCrgQQgghhBBCCCFKTSrgQgghhBBCCCHKBX0FXwVdOuBCCCGEEEIIIcoFGYIuhBBCCCGEEEKIUpMKuBBCCCGEEEKIcsFQwYegSwVcCCGEEEIIIYQoA1IBF0IIIYQQQghRLuhlDrgQQgghhBBCCCFKSyrgQgghhBBCCCHKhYq+CroiMzOzYu9hGXN1dbV0CkIIIYQQQohKJisry9Ip/Cdefu/GA3vuOeOcHthz3y+pgAshhBBCCCGEKBcq+iro0gF/ACJ6brN0ClYpbk0UALk7l1s4E+vkGNYHgKwZwy2ciXVyHfMpAGf6dbVwJtar/vfrADgYHWHhTKxT8KY4APZFtLFwJtapVdxuAGKbBlk4E+vU7vghADbXam7hTKxTx0tHAfjVoaGFM7Fe3W+eAmCtpoGFM7FOPYpOWzqF/4xBr7d0Cg+ULMImhBBCCCGEEEKUAamACyGEEEIIIYQoF+QyZEIIIYQQQgghhCg1qYALIYQQQgghhCgXKvoibFIBF0IIIYQQQgghyoBUwIUQQgghhBBClAsGmQMuhBBCCCGEEEKI0pIKuBBCCCGEEEKIckEq4EIIIYQQQgghhCg1qYALIYQQQgghhCgX9Aa9pVN4oKQDLoQQQgghhBCiXJAh6EIIIYQQQgghhCg1qYALIYQQQgghhCgXpAIuhBBCCCGEEEJUYAsWLKB58+b4+PgQFRXFzp07/zY+Li6OqKgofHx8aNGiBV999dV9vY50wIUQQgghhBBClAsGg+GB/d3N8uXLGTduHKNGjSI2NpbWrVvzv//9j6tXr94x/tKlSzz22GO0bt2a2NhYXnvtNV5//XVWrVp1z/2TDrgQQgghhBBCiErrs88+48knn2TgwIE0aNCAGTNm4OPjc9eq9tdff42vry8zZsygQYMGDBw4kH79+jF79ux7vpZ0wIUQQgghhBBClAt6vf6B/d1JYWEhhw8fpmPHjmb3d+zYkT179tzxMXv37i0RHx0dzaFDhygqKvrb/ZNF2CqYV1+sQ9sQT/ILdEz9+DRnzt8oEdOgjhMTRjTA1kbFrgNpfPz5edO2vg9Xo08PP/R6Azv3pTP3mwtlmb5F7Th2mpnf/YJOryemXSue7dG+RMyGvUeZv2oTCqB+9apMfekJANbEHWDBmi0ADOrZgZ4RIWWYefmgrtUIu+i+oFBSdHQXBXs3mm2369AHdY16fwTboHRwIvvTsaiq18O+Yx9TnNLDh5trvqH43NGyTN/iHFqE4P30EFAqydqyjozVP5ptV3t64TtkNEpHRxRKFanff0Xu4X2gUuHz4gjsatUFlYrs7ZvIWLXUQnthOS6tQvEf+ioolaT9+gvaHxabbbfx9qHGmPFo3Nwozs7h0rR3KEpNwb5OXaqPGI3KwRH0OpKWLCJj62YL7YXluIS2ocarI1EolaT8spqkxd+abbfx8aX2+Imo3dwpzsnmwjtvUpSSYtqudHCg2eIfyNi+jSsfzirr9MsF9/Aw6owbg0KlJGnZSq5++bXZdtuqVan/7ptoPNwpzsrm1LiJFGqTjdt8fan/ziRsfX0wGOD4kGEUXLtuid2wGI+ocOpNGotCpeT60uVcnmtedbLzq0rD6e9g4+FOUVYWJ0dMoCBJi1vbVtR7Y4wpzqFObU4Mf53UDVvKehcsqkrnCBrPmIhCpeTqNz9zYdYXZtvtqlej+bwp2FTxoCgjiyPPjyE/UQtAg3dH4d01CoBz783l+rLfyjx/S2v+xVS8u7enMDmN2KCed4xp/OFEvLtGocvL58jz48g+dBIAvwG9qTd+CABnp80l8duVZZW2+I+kpaWh0+nw8vIyu9/Ly4vk5OQ7PiY5OZn27duXiC8uLiYtLQ1fX9+7vp50wCuQNiEeVK/mwBOD99KkgTOjh9TjxdGHSsSNerke02ef4cTpHGa+1Yw2IR7sPpBOUDM3IkOr8Mzw/RQVG3Bz1VhgLyxDp9fz/rermTP6eXw8XOj/zmdEBTYiwM/HFHMlKZWv127l6wkv4eJoT3q28eRG1o2bfL56E4snDUOhUPDU258SFdQYF0d7S+1O2VMosOv8P3J//AxDTiZOA8ZQdP4Y+rQkU0j+luWm/9sEtUPl4w+A7upZbix83/g0dg44DZpE8aX4ss3f0hRKvJ8dSuLUCRSlpVJzyifkHthNYeIVU4hHTD9ydseS9ftabPxq4Df2XS6+MhDn0EgUag2Xxw5BYWNLrZmfk7NjK8WpWgvuUBlTKqn+ymucfX0kRSnJNJizgKxdceRfvmQK8XtpGOkb15G+YR1OgcFUGzSYy+9NRl9QwOX3JlOQmIDG05OGc78ke99edLklT15WWEolNV8bzZmRr1CYnEzjBV+TGbed/EuXTCHVhw0ndd1vpK37FefgEPwHv8zFyW+btvu/MJicIyW/byoNpZK6/zeOYy8MoSBJS9DSJaRt2cbNC7dOYgeMHkny6rVoV6/BrXUrao8YzunxbwDQYNq7XPl8AZm79qC0t4e/madYISmVNHhnAof6v0hBkpaWq78nZeNWbp671X51J4wiafkakpatxr1ta+q8/gonX5tI5q597Ov+GABqVxfabltLeuwuS+2JZSiVNPlwEnsffo78RC3h238iee1mbpy6VWBpNO11Er9bReKSlXhGhdLg7dc4MmgsXl2jcA1sTFybGJS2NoSuX0TKhliKc3ItuENlL2Hhci7NWUzgV+/fcbtX13Y41q3F1kYP4Rbagqaz32Jn+GNo3F2p/3/DiGvTF4PBQOSe5WjXbKY4M7uM96BikVXQy4nExET69etHcHAwgYGBjB07lsLCQrZv346bmxu//XbrbN3jjz/O9u3bAejRoweHDt39R0GzZs0ICwsjLCyM0NBQJk+eTH5+PgCXL1+mbdu2AGzfvp0aNWoQERFBREQEjzzyyAPc238nso0n6zYbOzwnTufg5KjG093GLMbT3QZHBzUnTucAsG5zEpFtPAGI6V6VxT9foajYeNBnZv398ImK5PiFq/h7e+Lv7YFGraZL6xZsPWTeCVweu4/HOrY1daw9XJwA2HX8DKGN6+Hq5ICLoz2hjeux89jpMt8HS1JVrYk+IxVDVhrodRSdOoCmbrO7xmsahVAUf6DE/er6gRRfPAnFlefYA7Cr24CipOsUJSeBrpjsXdtwbNnWPMgASnsHAJQOjhRnpJk2KW3tQKlEYWODobgIfV7l+uHk2LARBYkJFF6/hqG4mIwtv+MaFmEWY1ezFjmHDgJw4/BB3MIiAShIuEpBYgIARWlpFGVmonZzK9P8Lc2xUWMKEhIouGZsv/TfN+Ie0c4sxr5WbXIO7gcg5+AB3CNvbXdo0AC1uwdZe/eWad7liXOzpuRduUp+QiKG4mJSfluPZ8f2ZjEOdQLI/KONMvfuw7ODcbtDQAAKlYrMXcZhjvq8PPR//A6pLFwCm3Lz8hXyryZiKComec06vB7qYBbjUC+AjJ3GNsrYtZcqnTuUeB7v7p1J2xpX6drPrWVzbp6/Qt6lBAxFRVz/+Vd8Ho42i3FqWIe0rbsBSNu2B+8/tjs1rEP6jv0YdDp0N/PIOX6aKp0jy3wfLC09bj9F6Vl33e7TK5rExSsByNxzBI2rC7a+Xng9FEHKph0UZWRRnJlNyqYdeHepfO1n7Tw9PVGpVKTcNrILICUlBW9v7zs+xtvb+47xarUaT0/Pv309q+iAGwwGBgwYQI8ePTh48CAHDhwgNzeXd999FwA/Pz9mzfr3Q97WrFnDzp072bRpE5cuXWLEiBF3jGvbti1xcXHExcXd1wp3Za2Kpy3JqQWm28lpBVTxtPlLjA0pt8ekFlLF0xaA6tUcaN7Elc9nBvHptBY0rOdcNomXAykZ2fh6uJpue3u4kJxh/kF8JSmVy9pUnp0yj6ffncOOPzrZyX95rI+HC8kZlevMp8LJDUNOhum2PicThZPbnWNd3FG6elJ85UyJbTYN79wxr+jU7p4Up936EC9OS0Xjbv7hnbZsMS4RHak9+1v8Xn+H5G/mAJCzZzv6gnwC5n5HwKffkvHLMvSVqXoLaKp4UZhya4hYUUoKmirmw8jyzp/DLdI4xNItoh0qR0dULi5mMQ4NGqFUqym4lvjgky5HbLy8KLxtiF1hSjKavwzDu3nuLO5R7QFwb9f+VvspFFQf9ipXP/ukLFMud2y9vSlIujXqpECrxcbbvA1zT5/Bs5NxvqBnp46onZxQu7piX6sGxTk5NP5oJsE/fU/tUSNAaRU/z/4ztj4+FFy7rf2ua7H1Mf/ReyP+DF5dOwHg1SUatbMTajdXsxifnt3Qrq58w6ftqvmQn3hrykJeYhK21XzMYnKOncb3kc4A+DzSGY2LExoPN3KOGTvcSns7NJ5ueLYLxd6/apnmbw3sqvmQl3DbqL7EJOz8fIxtf/W2+xO02P2l7cU/ZzDoH9jfndjY2BAYGMiWLeZTV7Zs2UJoaOgdH9O6des7xgcFBaHR/P0oYqv4hI+NjcXW1pb+/fsDoFKpmDp1KosXLyYvL4+mTZvi4uJSohH+KScnJz744AN+/fVXMjIy7v2ACkalUuDipOHF0YeY89UF3hnbyNIplSvFeh1Xtal8PvYFpr30BJO/XkHOzTxLp2V1NA1DKDpzuMQQS4WjC0qvqpVv+Pl9cg5rT3bsRi4OG0Di9En4vjzGOPS/TgPQ67nw8lNcfHUg7j36ovG++7yjyipx/mycmwfScN5XOLUIMnbYdbe+iNUentQa/waXZkyrfMN/78PV2Z/iHBhM468W4hwUZOyw6/V4x/Qla9dOs/ng4s4uzPwQt5YhBP/0PW4tQyhI0mLQ61Co1LgGB3Fh5occfKI/dv7++PbuZel0y51zU2bhFhpCq7VLcWvTkvzrWrhtQSUbryo4NqhLeuzfX7e3soqfMB2PyFaE71qOR0Qr8hKTMOh0pG7aQcr6bYRt+Z6gb2aRsecwBp3O0umKSs6gNzywv7sZOnQo3333HYsWLeL06dOMHTuWpKQknn32WQAGDx7M4MGDTfHPPvss169fZ9y4cZw+fZpFixbx3XffMWzYsHvun1XMAY+PjycwMNDsPhcXF/z9/bnwx/yqUaNGMWXKFDp0KDkk6Z9wcXGhRo0anD9/vsRE/F27dhERYRzW2Lt3b0aPHl2q1/ov9OlejZ5djGcq48/m4F3F1rTN29OW1LRCs/jUtEK8bo+pYkNqmrEinpJawLZdqabnMujBzUVDZnbFHw7s5e5C0m1Dj5LTs/F2/8uZdXdXmgZUR6NW4eflQQ3fKlxJSsXb3YX9py6a4rTp2bRsWLvMci8PDDcyUTi7m24rnd0w3Mi8Y6xNw2Dyfv+pxP2aBkEUnz1q9oOqsijOSEPteevzRu1ZhaLbhpgDuHboQuK0iQDkn41HobFB5eyCS3gHco8cAJ0OXXYWeWdOYBtQzzicvZIoSk3BxutWtUzj5UVRqnmHsCgtjQtvGdtPaWePW2SUaZ630sGBulOnc+2rz7kZf6LsEi8nClNSsLltiJ2Nl3eJDnVRWirnJo4DQGlvj3tUB3Q3buDUtBlOLVrgHdMXpb09So0GfV4eCfPmlOk+WFpBcjK2vreqXrY+PhQmm7dhYUoKJ0cYfzco7e2p0ikaXc4NCrRabpw6Q36CceRF2uYtuDS/+xSeiqhAqzWr2NpW9aFAa77wUWFyCsdfeg0AlYM9Xl07UZydY9ru/XAXUtZvxlBcXDZJlyP517TY+d2qWtv7+ZqNKAAouJ7MwX6vAKBydMC390MUZxnb7/z0+ZyfPh+AwK9nknvuUtkkbkXyr2mx9/flz/KcnZ8v+Yla8q9p8YhqbYqz8/chfVvlnY5jzfr06UN6ejozZsxAq9XSqFEjfvzxR2rUqAFAQkKCWXytWrX48ccfmTBhAl999RW+vr68//779zVN2Soq4PcjPDwcMHaSS+tuF2m/fQh6eeh8Ayz/9RrPvnqAZ189wPbdqXTtaKx8NWngzI2bxaRlmHfA0zIKyb1ZTJMGxuHlXTv6sn238Yd+7O5Ugpu7AVC9mj1qtaJSdL4BmtT252pyKokp6RQVF7N+7xGigsxHALQPbsyBU8YTPhk5uVxJSsXP24O2Teuz+8RZsnPzyM7NY/eJs7RtWt8Su2ExuutXULl7oXD1BKXKWOU+d6xEnNLDB4WdA7prF0ts0zQKobASDj8HyD9/Go1vNdRePqBS49I2itwDu81iilOTcWgaBIBNteoobWzQZWdRlJqMQ5MWAChsbbGr25DCawklXqMiyz11Clu/6tj4VkWhVuPeoRNZO3eYxahcXEGhAMD3yQGkrVsLgEKtJuDtqaRtWEdm7NayTr1cyD0Vj2316thUNbafR6fOZOzYbhajdr3VflUHDCRl7RoALrzzJkf79ubo/2K4+tmnpK77tdJ1vgFyjp/AvkYN7PyqoVCr8erWhbQtW81i1G5upjas8cJzJK1YZXqs2sUZjbvxJKZb61bknq88VyAByDlyAodaNbHz90OhUePdsyupG7eaxWjc3UztV/PlQVz/cYXZdp9e3dCuqXzDzwGyDhzDsW5N7Gv6odBoqPpod7Rrza/moPF0M7VfnTEvkrBomXGDUonGww0A56b1cW5an9TfzT8/BSSv2Yxf/94AuIW2oDg7h4KkFFI2xOHVKQK1mwtqNxe8OkWQsiHOsslWAJaogAMMGjSIY8eOkZyczLZt20z9S4C1a9eydu1as/iIiAhiY2NJTk7m6NGjPPfcc/e1f1ZRAW/YsGGJOdfZ2dkkJCQQEBBgGno+evRoZs6ciVr973crJyeHq1evUrduXbKy7r4YQ3m0a386bVt6sPTz1qbLkP3p649DePZVY+dm1tyzTBzREFsbJbsPpLP7QDoAa39PYvwrDVg0uyVFxXqmfFR5FhJTq1SMfaoXQ2d9hV5voFdkS+r4+TB3xUYa1/IjKqgxYU3rs/v4WfpO/BCVQsGIx7vh5uQIwKCeHen/zmwAXujVEVcnB0vuTtkz6Mn7/SccH30ZlAqKju1Gn5aEbXh3dElXKD5/HABNw2AKTx0s8XCFiwdKZ3d0V8+Vdeblg15Pyjdz8B8/BZRKsrduoDDhMp6PDiD/4llyD+wmZfEX+LzwKu7dYzAYDCTNNa57kblhDb4vjaLmDGP1InvbRgqvlDzBUaHpdVz99APqvv8BCqWStN/Wkn/5IlWfeZ6bp0+RtWsHzoFBVHveOHTsxtHDXP3kAwDc23fEuXkgahdXPLt0B+Dy9Cnkna9Ex6JOx5UPZtLgg49BqSR17S/kX7xItedf4OapU2Tu2I5zUDD+g18GDOQcPszlD2ZYOuvyRafj3NT3aTp/jvEyZCtWcfP8BWoOHULOiZOkb92GW6uW1B4xHIPBQNaBg5ybPM34WL2eCzM/oNmX81CgIOdkPEk/L//716tgDDodZyZNJXDRXBQqFdd+XEnu2fPUHvkyOcdOkvr7VtzatKLO66+AwUDm3oOcnjTF9Hg7/2rYVfUhc/d+C+6F5Rh0Ok689i6tV38JKiUJi5ZxI/4c9d4YTtbB4ySv3YJnZCgN3hkJBkjfsY8TI94BQKlR02aj8bKNxTk3OPz865VyCHrgt7PwjGqNTRV3Ol7cxtl3PkWhMfYnrnz+A8m/bcOrWxTtT21El5fH0UETACjKyOLs1DlE7PoZgLNTPqMow7r6D6LsKTIzM8v9ZDeDwUCHDh0YPHgw/fr1Q6fTMXLkSJydnenatSuzZ89m6VLjdW+jo6PRarXMnTuXyMhIevToweTJkwkKCrrjczdr1oytW7fi6enJjRs3eO2111AqlcybN4/Lly/zxBNPsGvXLrZv3272Onfj6upKRM9t/3kbVAZxa4wLJOXurFw/PP4rjmHGa2lnzRhu4Uysk+uYTwE406+rhTOxXvW/XwfAweiIe0SKOwneZKya7ItoY+FMrFOrOOOokdimd/6+F3+v3XHjFWM212pu4UysU8dLRwH41aGhhTOxXt1vngJgraaBhTOxTj2KTltd8fBuHnvlwRUSfvzE8tNErWIIukKhYPHixaxcuZLg4GBCQkKwtbVl0qRJJWJHjRpVYoz+vfTs2ZO2bdsSHR1N9erV+eijjwDQ6XTY2Nj8/YOFEEIIIYQQQoj7YBVD0AH8/f3vWH2OjIwkMvLW9fa6d+9OZmam6fZfx+r/1bFjJeep/ik+Pp7atWvf8XWEEEIIIYQQQvy37jVX29pZTQe8rE2ZMoVff/2VOXMq32IyQgghhBBCCCH+e5WmAx4dHU1BQYHZffPnz6dJkyZ3jJ84cSITJ04si9SEEEIIIYQQQgCGCn5J2krTAd+0aZOlUxBCCCGEEEII8Tcq+hB0q1iETQghhBBCCCGEsHaVpgIuhBBCCCGEEKJ8Mxgq9hB0qYALIYQQQgghhBBlQCrgQgghhBBCCCHKBb3MARdCCCGEEEIIIURpSQVcCCGEEEIIIUS5UNEvQyYVcCGEEEIIIYQQogxIBVwIIYQQQgghRLkg1wEXQgghhBBCCCFEqUkFXAghhBBCCCFEuVDRrwMuHXAhhBBCCCGEEOWCDEEXQgghhBBCCCFEqUkFXAghhBBCCCFEuVDRL0OmyMzMrNg1/jLm6upq6RSEEEIIIYQQlUxWVpalU/hP9Oh/+IE999rFgQ/sue+XdMCFEEIIIYQQQogyIHPAhRBCCCGEEEKIMiAdcCGEEEIIIYQQogxIB1wIIYQQQgghhCgD0gEXQgghhBBCCCHKgHTAKzC9Xs+ePXssnYbVO3z4sKVTsGrSfkIIIYRl6HQ6S6cghPgL6YBXYEqlktGjR1s6Dav3f//3f7Ru3ZrJkydz8uRJS6djdaT9Sm/16tUUFBRYOg2r9fjjj/PTTz+Rm5tr6VSskrRf6cj7t3TCwsKYNWsWFy9etHQqVqlFixa8+uqrbNu2DYNBLnz0T8TExJj+/8EHH1gwE1HRSAe8gouKimLVqlXyoVsKv/zyC2vWrKFKlSqMHDmSsLAwZsyYYem0rIa0X+mtW7eOkJAQXnzxRdatW0dxcbGlU7Iqw4cPZ/fu3YSGhvL000+zatUq8vPzLZ2W1ZD2Kx15/5bODz/8gFqt5plnnqFDhw58+umnXL161dJpWY29e/fSvn17vvjiC5o3b86YMWPYtWuXpdOyCqmpqab/r1y50nKJiApHrgNewfn7+5Obm4tarcbOzg6DwYBCoZAvr3/pxIkTfPzxx6xYsYKUlBRLp2N1pP3+vaKiIjZu3MiKFSvYtWuX6YeouH86nY7Y2FgWLlzIpk2b5HPwH5L2+/fk/fvfOH/+PNOnT+enn34iPT3d0ulYnczMTMaOHSvtd5/atWtHbGxsif8LUVpqSycgHqyEhARLp2D1Tp8+zfLly1m9ejUeHh706dOHKVOmWDotqyHt99/QaDR07twZhUJBXl4ea9eulR/w/0BeXh7r1q1j+fLlHDlyhCeeeMLSKVkVab/Skfdv6Vy5coUVK1awfPlyVCoVb7/9tqVTsipxcXGsWLGC33//naCgIL7++mtLp2QVLl26xBNPPIHBYDD9/3Y//PCDhTIT1k4q4JVAZmYm58+fNxsyGB4ebsGMrEvnzp3p06cPvXv3pmrVqpZOx+pI+5Xexo0bWb58OXFxcURERBATE0PHjh1Rq+Uc6v145plnOHDgAJ06dSImJoaIiAiUSpmBdb+k/UpH3r+lEx0dTVFREb1796ZPnz7UqlXL0ilZlWbNmtG8eXNiYmLo1q0bjo6Olk7JasTFxf3t9oiIiDLKRFQ00gGv4BYtWsS8efNITEykWbNm7N+/n1atWrFmzRpLp2ZV8vLySEhIoF69epZOxSpJ+5XO888/T0xMDJ07d8bW1tbS6VidTZs20b59e1QqlaVTsUrSfqUj79/SOXv2rHx3lEJ2djYuLi6WTkMIcRs5hV3BzZs3j82bN1O9enV++eUXYmNjcXV1tXRaVuW3334jMjKSvn37AnD06FEZfvkPSPuV3pdffknz5s1NC+fk5eWRk5Nj4aysR9u2bfnggw949dVXAeM80nXr1lk4K+sh7Vc68v4tHVdXV4YNG8ajjz4KwKlTp1i0aJGFs7IeycnJ9OrVi7Zt2wJw/PhxWQj1PoWFhd31r0OHDjz33HMcO3bM0mkKKyQd8ArO1tYWOzs7AAoKCqhfvz7nzp2zcFbW5b333mPTpk2mExfNmzfnypUrFs7Kekj7ld7ChQsZOHAgI0aMAODatWs89dRTlk3KigwdOhQbGxv27t0LQNWqVZk8ebKFs7Ie0n6lI+/f0nn55ZeJjo7m+vXrANStW5d58+ZZOCvr8corr/Dmm2+apjw0bdqU5cuXWzgr6/DDDz/c9e+rr76ib9++vPzyy5ZOU1gh6YBXcNWqVSMzM5MePXrQu3dv+vXrR/Xq1S2dllXRaDQyaqAUpP1K74svvmD9+vU4OzsDUKdOHbPLo4i/d/HiRV599VXTD1AHBwe5NOM/IO1XOvL+LZ20tDRiYmJM6w6o1WpZg+AfyMvLIyQkxOw+mU5yf2rUqEGNGjVwcXEhNTWV1NRUXF1dqVGjBrVr16ZHjx5069bN0mkKKyQrgFRwS5YsAWD8+PFERkaSnZ1Np06dLJyVdWnYsCE//fQTOp2O8+fPM2/ePEJDQy2dltWQ9is9W1tbbGxsTLflOsL/jI2NDXl5eSgUCsDYoZS5uPdP2q905P1bOg4ODqSnp5uOv3379smc5n/A09OTixcvmtpv1apV+Pr6Wjgr61BQUMCIESNYu3YtNWvWxGAwcPXqVR5++GE+/PBDbGxsmDBhgqXTFFZITiFWArt27WLx4sVERETQunVrrl27ZumUrMr06dM5deoUtra2DBo0CFdXV6ZNm2bptKyGtF/phYeHM2vWLPLz89myZQsDBw6Us+7/wPjx4+nbty+JiYm88MIL9OrVSy5j9A9I+5WOvH9LZ8qUKfTr149Lly7RpUsXXnrpJaZPn27ptKzGzJkzGTFiBGfPnqVRo0bMnTuXDz74wNJpWYUZM2ZQXFzMiRMn2L59O3FxcRw/fpzi4mI5BkWpyCroFdx7773HoUOHOHfuHAcOHOD69es888wzrF+/3tKpWQWdTscjjzzCL7/8YulUrJK033/DYDCwaNEiNm/ejMFgIDo6mqefftpU0RB3p9frWbVqFVFRUezbtw+DwUCrVq3w9PS0dGpWQdqv9OT9++/pdDrmzZvH4MGDOXv2LAaDgXr16qHRaCydmlXQ6XS8+eabTJ48mdzcXPR6vWkqhLi3tm3bsmnTJhwcHMzuv3HjBp07dzYtrCjEPyVD0Cu4X375he3bt9OuXTvAuHiOrL56/1QqFUqlkqysLJnH/C9I+5WeTqejTZs27Nu3j4EDB1o6HaujVCr5+OOPiYmJoUuXLpZOx+pI+5WOvH9LR6VSsWzZMoYOHUqjRo0snY7VUalU7N69G0Cu//0vKBSKEp1vACcnJzmBJkpFOuAVnI2NDQqFwvRBkZuba+GMrI+joyPh4eG0b9/e7INYhh/dH2m/0lGpVNStW5erV6/KAor/Uvv27fn000+JiYkx+xHq7u5uwaysh7Tfvyfv39ILDQ1lzJgxxMTEmH2HBAYGWi4pK9K8eXOeeOIJevfubdZ+vXr1smBW1kGhUJCZmXnHRSelAy5KQzrgFVxMTAwjRowgKyuLhQsXsnjxYjkL/w/17NmTnj17WjoNqyXtV3qZmZm0bduW4OBgsx9QP/zwgwWzsh5/XnLniy++MN2nUCg4cuSIpVKyKtJ+pSPv39L58zrL8fHxpvsUCgVr1qyxVEpWJT8/Hw8PD2JjY033KRQK6YDfh+zsbKKioqQDLv5zMge8gps3bx6+vr4cOHDANPesQ4cOlk7L6hQWFnLmzBkUCgX16tUzW9FW3Ju0X+nExcXd8f6IiIgyzkQI8U/J+1eIii0+Pl6mSIh/RDrgFdzkyZNZtmwZLVq0oH///kRHR8tZu39ow4YNjBw5klq1amEwGLhy5QoffvghnTt3tnRqVkHa77+h1Wo5cOAACoWC4OBgfHx8LJ2S1cjPz2fBggXs3r0bhUJB27Ztee6557Czs7N0alZB2q/05P3776Wnp/Pee++Zjr82bdowduxYPDw8LJ2aVbh06RJjx45l//79KBQKWrVqxbRp06hVq5alU6sw2rVrZzbCQIh7kQ54JWAwGNi8eTNLlizh0KFDxMTEMGDAAGrXrm3p1KxCq1atWLp0KQEBAYDxGriPPfYY+/bts3Bm1kHar/QWLVrE9OnTiYyMxGAwsGPHDl5//XUGDBhg6dSswjPPPIOTkxOPPfYYAD///LNpWo64N2m/0pH3b+n07t2bsLAw0/H3008/ERcXx6pVqyycmXXo1KkTgwYN4tFHHwVg2bJlfP7552zatMnCmVUckZGRbN++3dJpCCsic8ArAYVCgbe3N97e3qjVajIzM3n66afp0KED77zzjqXTK/ecnJxMnUeAWv/f3r0GRVX+cQD/HgnFCxRWgyH4V8uwEFAMDfKSjGkSOqISaZFdHBkZsZKUSMEyLUBMEyW7TTcCsV28YBdSMxRN8oY4omLeBe2mjgmhAvt/4bDTDnuWxYf2OQe/nzfNnqcX3zmzi+f3nN/zPN27o1OnThIT6Qvvn7hly5Zh69at5jc+Fy5cwIgRI/gAb6dDhw6huLjY/HnIkCEYOHCgxET6wvsnhr9fMb/99htmz55t/jxr1iysWbNGYiJ9qa6uxlNPPWX+HBUVhWXLlklM1Pqws5SaiwV4K/f+++9j1apVuPPOO/Hss8/irbfegrOzM+rr6xEYGMgC3A79+vVDZGQkxo4dC0VRsG7dOgQGBmL9+vUAuJNoU3j/xHXu3Nli0qJTp05sv2yGgIAA7Nq1C0FBQQCA3bt3cwflZuD9E8Pfr5hhw4bBaDQiIiICALBu3TqEhoZKTqUfjz32GJYsWYJx48ZBURSsWbMGI0aMwMWLFwHwNAMiGdiC3sq9/fbbeOaZZ9CtW7dGY0eOHIGPj4+EVPoSGxurOqYoClasWOHANPrD+ycuJiYGZWVlCAsLg6Io+Pbbb+Hr6wtfX18AwPTp0yUn1LYBAwbg6NGj8PLyAgCcPXsWvXr1wm233ZiD3rFjh8x4msf7J4a/XzFeXl6oqqqCk5MTgBtnqzcch6coCs6cOSMznub5+/urjvE0g5YxfPhwbNq0SXYM0hEW4ESC3n33XcycOVN2DN3i/WtaSkqKzfHXXnvNQUn06fTp0zbH3dzccMcddzgmjA7x/onh7/e/xR2oxWzZsoWn46goKSmxOc5OILpZLMCJBHH3SzG8f+JmzZqFRYsWAbo18QAAEvNJREFUyY6hW/wOiuH9E8Pfrxh+/8Tw/qkLDw9XHeNZ9CSCa8CJBJlMnMMSwfsn7t8bZFHz8TsohvdPDH+/Yvj9E8P7p27Dhg2yI1ArxQKcSBB3vxTD+0ey8TsohvePZOL3Twzvn7rt27erjimKgpCQEAemodaEBTiRIM4ei+H9IyIiIq2xdlyboig4ePAgKioqcOHCBQmpqDVgAU4kaOzYsbIj6BrvnzhOYojh/RPD+yeG909M27ZtZUfQNWun5NANubm5Fp937tyJ9PR0eHh4IC0tTVIqag24CRuRilmzZqm2ZrVr1w49evRAZGQkXF1dHZxMH3j//js1NTX4/vvvzZMXX331FZ5++mm5oTSouroazs7OcHZ2BgAcPXoUP/zwA7y9vS3On7948SLPwrVh69atOHz4MACgd+/eGDJkiMU4758Y/n7V1dbWYuPGjTh69CgA4P7778fw4cPNR+CRuvXr16uONfwbfP/99zswkX4VFhYiLS0NiqIgPj6eu8aTMBbgRCqys7NVx2pra3H48GGUlZVh7dq1jgulI7x/Lauurg6bN2+GwWDAli1bEBwcjC+++EJ2LE0bNWoUli9fjnvvvRfHjx9HaGgoIiMjceTIEfTv3x/z5s2THVHTKisrER0djXbt2pmP2ykpKUFNTQ2ysrLg6ekpN6DGxcbGqk5CKoqC5cuXOziRvlRWVmLMmDHw8PCAv78/TCYTSktL8fvvvyM/Px/33HOP7IiaFhsbqzpWW1uL8vJyDBgwgG9ybSgoKMDixYvh5uaG+Ph4BAcHy45ErQQLcCIBkZGR+Prrr2XH0C3ev6YVFRXBYDBg48aNCAwMRHFxMUpKStChQwfZ0TQvJCQEO3bsAAAsWLAAly5dQnp6Oq5du4ZHH33UPEbWPf300wgLC2v0djYnJwfr169HTk6OpGT6sG7dukbXKioqkJmZifr6epSVlUlIpR/Tpk2Dn59fo0Jy5cqVKCkpwcqVKyUlax3q6+sREhKCnTt3yo6iWe7u7ujatSt8fX0tJtNMJhMURcGqVaskpiM9YwFOpOKpp56yOc4/vLZFRUU12YI+ZcoUeHl5OTiZfjz44IPw8vLCCy+8gCeeeAKurq7w9/dHaWmp7Gi68O8CfOTIkYiLizOf6/rII4/Y3OGWgIceegi7d+9u9hg1dvLkSSxevBg7duxAbGwsoqOjuXa5CUFBQdi1a5fVMX7/7HP06FF89tlnFi38zz33HO677z4AwPnz59GlSxeZETWtqKgIwI1lX8eOHYOiKOjZsydcXFwAAIMGDZIZj3SMi2iIVOzatQtdu3bFhAkT0L9/f26U00xxcXGqY3V1dTh06BCef/55bNy40YGp9GXMmDH45ptvsGbNGjg5OSEsLIxHxjRDnz59MHfuXNxzzz3mFnQAuHTpktxgOlFfX696va6uzsFp9Km8vBzp6ekoLS1FXFwclixZwvXLdmoocqxp3769A5Po0y+//ILo6GhMnjwZkydPNrfwh4eH48svv0RQUBCL7yY8/PDDmD9/PrKysswvCyoqKjBp0iQkJydLTkd6xjfgRCrq6uqwZcsWGAwGHDx4ECNHjsT48ePxwAMPyI7WasTFxSEjI0N2DE0zmUzYtm0bjEYjNm7ciMuXLyMjIwOPPfYYOnXqJDuepv3zzz9YuXIlzp8/j2eeeQZ+fn4AgOLiYpw4caLJLpdbXWJiIqqqqvDOO++gY8eOAICqqiq8/vrraNeuHdeONmHy5MkoKSnB9OnTERERAScnJ4txblxnW0BAAN56661G100mE+bNm4eSkhLHh9KRCRMm4KWXXsLgwYMtrhcVFWHp0qUwGAySkulHw9/AhQsXmjeMvXz5MpKSktC+fXukpKRITkh6xQKcyA5Xr16FwWBAcnIyEhISMHXqVNmRNC8kJMTmONffNt/169exadMm5OXlYfPmzTh+/LjsSLp09uxZ5OXlYcaMGbKjaNr169fx5ptvIjs7G97e3jCZTKioqMDEiRORnJzMFuom+Pn5mTtWFEWx6KJSFAX79++XFU0XbG0iBgCZmZkOSqJP/fv3x549e6yOsYXfPoGBgdizZ0+jzrO6ujoEBQVh7969kpKR3rEPisiGq1evoqCgAEajEadPn0ZMTIx5DSnZ1qZNGyiKgsjISDz++OM22wnJPs7Ozhg1ahRGjRqFf/75R3YcXfnzzz+xdu1aGI1GnDt3jr9jOzg7O2PBggWYM2eOebKnR48e3ADQTgcOHJAdQddYYIux1SHF37B9FEWxuuzLycmJy8FICAtwIhUxMTE4dOgQRowYgYSEBDz44IOyI+lKUVERysvLYTAYMGXKFPTu3RsTJkxAaGgo10DaycvLy+rOqwDQtm1b9OjRA0lJSRg6dKisiJr2999/Iz8/HwaDAb/++itGjx6NU6dOcfdpO+3duxddu3aFh4cHfH19kZOTgwULFsDb2xuJiYlsobbDtWvXsHr1aotz1CMjI9GuXTvJybTP1i77iqJwCUkTKioqMHv27EbXTSYTzp07JyGR/vj4+CAnJwcTJ060uJ6bm4tevXpJSkWtAVvQiVS4u7ub1z1aK4LOnDkjK5ou5eXl4dVXX8XLL7/M1t8WUFdXh7KyMkydOhU///yz7Dia1KVLFwQGBmLu3LkIDg6GoigICAhg66+dhgwZgnXr1sHd3R3bt2/Hiy++iNTUVBw4cADl5eU8h74Jhw8fxsSJEzFw4ECLc9SLi4uRnZ3N/USaMGvWLKvXv/vuO5w7dw5//fWXgxPpS3Z2ts3xSZMmOSiJflVWViI6OhouLi7m3/C+fftQU1ODrKwseHp6yg1IusUCnIj+M5WVlTAajfjmm29w++23IyIiAuHh4dw8zE4XL15UHWvbti06duyITz/9FM8//7wDU+lHZmYm8vLyUF1djfHjx2PcuHEYO3YsC3A7/fuotldffRV33nknEhMTAdw4fqfhiB6ybsyYMXjllVcwbNgwi+s//fQT0tPTsWHDBknJ9MdkMmH16tV477334OPjg/j4ePTp00d2LLpFFBYWWnSxsOuMRLEAJ2qGqqoqbNiwAUajEatXr5YdR9PCwsJw5coVREREYMyYMejcubPFONtXm+bv799o86YGDcdAJScnIyoqytHRdOXkyZMwGo0wGo04duwYEhMTER4ebj4Ll6wLDg7Gtm3bcNtttyEoKAhLly7FI488Yh5j54Vtts6xHjBgAH755RcHJ9Kf2tpaZGdnIyMjAw899BBmzpzJ1l87xcbGqq5TVhQFy5cvd3AiImrAhZhETbh27RoKCgpgMBjw448/YvTo0XzjaIczZ85AURR8+umn+Oyzz8zXG1r4+RayaaWlpTbH//zzT4SFhSEgIAC9e/d2UCr96d69O+Lj4xEfH4+ysjIYjUZERkZi3759sqNp2vjx4/HEE0+gc+fOcHFxMZ9scPz4cbi5uUlOp3319fW4evVqo/XeNTU1qK2tlZRKPz766COsXLkSQ4cOhcFgwP/+9z/ZkXRl5MiRja5VVFQgMzMT9fX1EhIRUQO+ASdS8eOPP8JgMGDLli0YPHgwIiIiMHv2bO5s28IOHTrEtZACvv32W6SkpGDr1q2yo2iOPS38ZNuuXbtw/vx5hIaGmu/Xr7/+iqqqKgQEBEhOp22LFi3C7t27sWjRInTr1g0AcOrUKSQkJKBfv35ISEiQnFDb3N3dcffdd+Ouu+6yOs6jLO138uRJLF68GDt27EBsbCyio6N5jCCRRCzAiVS4u7sjODgYmZmZ6N69OwBwA6f/wJAhQ1g8Cho8eDC2bdsmO4bmqLXwK4qCuro6mEwmzJs3D08++aSkhPpTVVWF/Px85OXlcRmOHT788EMsW7YM1dXVMJlM6NixI+Li4hATEyM7muadPn3a5njDpAapKy8vR3p6OkpLSxEXF4eoqCieQkKkAfwVEqkoLCxEXl4exo4di+7du2PcuHHmdbfUcqytb6bm4Xmk1tnbwu/v788Wfhu4DOfmTZ06FVOnTsXff/8NAHB1dZWcSD8aCuyTJ09abIDVMCFOtk2ePBklJSWYPn063n77bTg5OZm/hwD3YSGSiW/AiexQXFwMg8GA/Px89OnTB+Hh4Xjuuedkx2oV+AZcHO/hzWMLvzouwxHz3XffwdfX11xIpqamYv369fD29kZKSgoLySZcvnwZM2bMwL59++Dn5wcAOHDgAPr27YuMjAzuQ9AEPz8/8+Rsw38bJry5DwuRXCzAiZqhvr4eP/30E4xGI1asWAGAa5hFsXgUN3z4cGzatEl2DN1iC791XIYjJiQkBJs2bUKHDh3w/fffY86cOfjkk09QWlqKtWvXIi8vT3ZETZs2bRq6deuGhIQEtGnTBsCNAjItLQ3Hjx/HBx98IDlh68BnGCLHYws6UTO0adMGoaGhCA0NNV+LiYlhASmAG8GoKykpsTnet29fAGDxLYgt/NZxGY4YRVHQoUMHAEB+fj6io6PRt29f9O3bFx9//LHkdNpXXFyM999/3+KaoihISEhAYGCgpFStD59hiByPBTiRIK5hto7Fo7i5c+eqjimKgvz8fAemoVuNv78//P398cYbb5iX4dTW1mLChAlchmMHk8mEK1euoEOHDigsLMSUKVPMY1evXpWYTP/4727L4b0kcjwW4ESC+PbMOhaP4jZs2CA7wi2BXRhNGzhwIAYOHIjU1FTzMpyGApwtrNZNmzYNgwcPhqurK3x8fNCvXz8AwP79++Hh4SE5nfYNGDAAqampmD17tsW/s2lpaQgKCpKYrHXhMwyR43ENOJEgrmGm/8r27dtVxxRFQUhIiAPT6I+9XRgkhn8D1VVWVuKPP/6An5+feR3z+fPncf36dXh7ewPgBIaay5cvIy4uDvv377fYhM3f3x8ZGRm4/fbbJSdsHfj7JXI8vgEnEsS3Z9axeBS3bNmyRtcURcHBgwdRUVGBCxcuSEilH+zCcAy2sKrz9PSEp6enxbUuXbpYfOYaXOvc3Nzw+eef48SJExbHkPXo0cPi/+MEhhg+wxA5Ht+AE6ng2zMxUVFRja6xeBSzc+dOpKen49KlS4iPj8eoUaNkRyLiGzRB3IVfDL9/1vEZhki7+AacSAXfnonJzc21+NxQPHp4eCAtLU1SKn0qLCxEWloaFEVBfHw8hg0bJjuSLrALg/SAa3DFsAPDOj7DEGkXC3AiFdwAq2WweLx5BQUFWLx4Mdzc3DB37lwEBwfLjqQrbOF3DLawkkycwLCOzzBE2sUWdCIVfHsm5t/FY3x8PIvHm+Du7o6uXbvC19fX4iHTZDJBURSsWrVKYjr9YQt/87CF1TGGDx/O4xgFsAXdOj7DEGkXC3AiFVzDLIbFo7iioiIAQE1NDY4dOwZFUdCzZ0+4uLgAAAYNGiQznm6wC+PmhIeHq46xhbVpnMBwDE5gWMdnGCLtYgFOZCe+PWseFo/iamtrMX/+fGRlZcHLywsAUFFRgUmTJiE5ORnOzs6SE2obuzBIJk5giOEERsviMwyRdrAAJ2oC357dHBaP4hITE1FVVYWFCxfC1dUVwI2zcZOSktC+fXukpKRITqht7MIQwxZWkokTGC2DzzBE2sMCnEgF356JYfEoLjAwEHv27Gm0yVBdXR2CgoKwd+9eScn0gV0YYtjCKoYTGCQTn2GItIsFOJEKvj0Tw+JRXP/+/bFnz55mj9EN7MJoWWxhbR5OYIjhBIYYPsMQaRePISNS0dDepvb2jGxTFMXq8TBOTk48NsZOPj4+yMnJwcSJEy2u5+bmolevXpJS6UdSUhKqqqqwf//+Rl0YSUlJ7MKwE1tYb05ubq7F54YJDA8PD6SlpUlKpR88RlAMn2GItItvwIlU8O2ZmEmTJmH06NFWi8c1a9Zw9t0OlZWViI6OhouLi3nDoX379qGmpgZZWVnw9PSUG1Dj2IUhhi2sLYMTGC2DHRjNw2cYIu1iAU6kgmuYxbB4bDmFhYU4fPgwAKB3794YOnSo5ET6wBZ+MWxhFcMJjJbBCYybw2cYIu1iAU6kgm/PWgaLR5KFXRhiuImdGE5giOEEhhg+wxBpFwtwIhV8e0akb+zCEMMWVjGcwBDDCQwxfIYh0i5uwkakghtgEembp6cnNm/ebNGFMWLECHZh2Imb2Il5+OGHbU5gkG3cREwMn2GItItvwIlU8O0ZEd3K2MIqhmtwxbADQwyfYYi0iwU4URO4hpmIbkVsYRXDCQwxnMBoGXyGIdIeFuBERETUCDexE8MJDDGcwCCi1oprwImIiKiR9PR0REdHIysry2oLK9nGNbhiFEVpVHwDgJOTk9XrRER6wTfgREREpIotrDeHa3DFsAODiForFuBERERE/xFOYNwcTmAQUWvFApyIiIiINIkTGETU2rAAJyIiIiIiInKANrIDEBEREREREd0KWIATEREREREROQALcCIiIiIiIiIHYAFORERERERE5AAswImIiIiIiIgc4P9eH1WauQWG/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = df_feature_ONI.corr(method='spearman')\n",
    "f, ax = plt.subplots(figsize=(16,8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', linewidth=0.4,\n",
    "            annot_kws={\"size\": 10}, cmap='coolwarm', ax=ax)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71998a3-cb4b-426c-8c4a-904e1f46d060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "df_feature_ONI.plot(subplots=True,\n",
    "                  layout=(6, 3),\n",
    "                  figsize=(24,24),\n",
    "                  fontsize=10, \n",
    "                  linewidth=2, \n",
    "                  title='Visualization of the transformed Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd20828-bb66-4d02-8c6f-2b151972d163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de532f-38b0-4447-a66a-9bb098828a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "761d2a7b-352f-4e0f-8d59-1d68252413b1",
   "metadata": {},
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cc36a1-0098-4fe7-860f-4187e56954f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  ONI_AMJ_prev  ONI_MJJ_prev  ONI_JJA_prev  ONI_JAS_prev  ONI_ASO_prev  \\\n",
      "0  1953           0.2           0.0          -0.1           0.0           0.2   \n",
      "1  1954           0.8           0.8           0.7           0.7           0.8   \n",
      "2  1955          -0.5          -0.5          -0.6          -0.8          -0.9   \n",
      "3  1956          -0.8          -0.7          -0.7          -0.7          -1.1   \n",
      "4  1959           0.7           0.6           0.6           0.4           0.4   \n",
      "\n",
      "   ONI_SON_prev  ONI_OND_prev  ONI_NDJ_prev  ONI_DJF  \n",
      "0           0.1           0.0           0.1      0.4  \n",
      "1           0.8           0.8           0.8      0.8  \n",
      "2          -0.8          -0.7          -0.7     -0.7  \n",
      "3          -1.4          -1.7          -1.5     -1.1  \n",
      "4           0.4           0.5           0.6      0.6  \n",
      "0    146\n",
      "1    139\n",
      "2    140\n",
      "3    134\n",
      "4    127\n",
      "Name: doy_cherry_peak_bloom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "input_features = df_feature_ONI# .drop(columns=[\"year\"])\n",
    "doy_label = df_label[\"doy_cherry_peak_bloom\"]\n",
    "\n",
    "print(input_features.head())\n",
    "print(doy_label.head())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "# input_features_train, input_features_test, doy_label_train, doy_label_test = train_test_split(input_features, doy_label, test_size=0.2, random_state=42)\n",
    "\n",
    "input_features_train, input_features_test = input_features[:-5], input_features[-5:]\n",
    "doy_label_train, doy_label_test = doy_label[:-5], doy_label[-5:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310cf55a-7ae4-4371-9d4b-73a9c61d4073",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3a38c-4076-4dd3-9776-a6da765c8b88",
   "metadata": {},
   "source": [
    "## RF - model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "229e4b40-c8ae-476e-90df-961074890873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(input_features_train, doy_label_train)\n",
    "\n",
    "\n",
    "doy_pred_training = rf.predict(input_features_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "doy_pred = rf.predict(input_features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d2eb9ea-8707-4401-87d2-89dcd09431a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 29.665940000000013\n",
      "R2 Score: -15.122793478260878\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(doy_label_test, doy_pred)\n",
    "r2 = r2_score(doy_label_test, doy_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d19918-4e88-40e5-9815-97be6b3ed048",
   "metadata": {},
   "source": [
    "## RF - plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57e31d-ce5c-455d-b545-119bed62a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example data\n",
    "real_values = doy_label_test\n",
    "predicted_values = doy_pred\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=real_values, y=predicted_values, label=\"Testset: Pred vs Real\", color=\"blue\")\n",
    "\n",
    "# sns.scatterplot(x=doy_label_train, y=doy_pred_training, label=\"Trainset: Pred vs Real\", color=\"green\")\n",
    "\n",
    "\n",
    "# Plot y=x line for reference\n",
    "plt.plot(real_values, real_values, color=\"red\", linestyle=\"--\", label=\"Ideal Fit: test\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Real Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"DAY OF YEAR (DOY) - Predicted vs Real Data\")\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295fa90-9685-47c2-8095-60b5513dc279",
   "metadata": {},
   "source": [
    "## RF - importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73af7b-592d-40fe-9866-43d87fd89174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': input_features_train.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614296c1-6d8b-494e-a789-42a5b8012524",
   "metadata": {},
   "source": [
    "# LSTM try 1, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d1ca9-0de3-42bd-8969-5efc2f497a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8cbd69-4b01-47f4-8ea7-ab8d2245d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f4756b16-7c9c-4b14-91d1-fe691232862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(input_features.values, dtype=torch.float32)\n",
    "import torchvision.transforms as transforms\n",
    "to_tensor_transform = transforms.Lambda(lambda x: torch.tensor(x.values, dtype=torch.float32))\n",
    "\n",
    "# Apply the transform\n",
    "tensor = to_tensor_transform(input_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea1f55-3e1e-4cf7-b043-e7e2a6a8b714",
   "metadata": {},
   "source": [
    "# LSTM try 2, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b188b370-c39f-4466-ae46-99d37f553d1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13632\\1714907623.py\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# by passing it as an argument  to the lstm at a later time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Add the extra 2nd dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# clean out hidden state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(10, 1)  # Input dim is 3, output dim is 3\n",
    "inputs = tensor # torch.tensor(input_features.values, dtype=torch.float32) # input_features # [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "# doy_labels\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 1),\n",
    "          torch.randn(1, 1, 1))\n",
    "\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 1), torch.randn(1, 1, 1))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1c42b-bee6-4d74-a8a5-a01f26970492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "df = pd.read_csv('airline-passengers.csv')\n",
    "timeseries = df[[\"Passengers\"]].values.astype('float32')\n",
    "\n",
    "# train-test split for time series\n",
    "train_size = int(len(timeseries) * 0.67)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]\n",
    "\n",
    "train = \n",
    "test = \n",
    "\n",
    "def create_dataset(dataset, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        \n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        \n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "lookback = 4\n",
    "X_train, y_train = create_dataset(train, lookback=lookback)\n",
    "X_test, y_test = create_dataset(test, lookback=lookback)\n",
    "\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = AirModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n",
    "\n",
    "n_epochs = 2000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    if epoch % 100 != 0:\n",
    "        continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # shift train predictions for plotting\n",
    "    train_plot = np.ones_like(timeseries) * np.nan\n",
    "    y_pred = model(X_train)\n",
    "    y_pred = y_pred[:, -1, :]\n",
    "    train_plot[lookback:train_size] = model(X_train)[:, -1, :]\n",
    "    # shift test predictions for plotting\n",
    "    test_plot = np.ones_like(timeseries) * np.nan\n",
    "    test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, :]\n",
    "# plot\n",
    "plt.plot(timeseries)\n",
    "plt.plot(train_plot, c='r')\n",
    "plt.plot(test_plot, c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f68b7a-3ce5-4aaf-a69e-ca8f13f28868",
   "metadata": {},
   "source": [
    "# LSTM try 3\n",
    "* https://www.kaggle.com/code/purplejester/a-simple-lstm-based-time-series-classifier/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "88d845a4-6786-4fef-91c2-f11ec51df606",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS = [\"month\", \"year\", \"year_month\"] #  [\"id\"]\n",
    "x_trn = input_features_train\n",
    "y_trn = (doy_label_train-110)/(150-110) # normalise\n",
    "\n",
    "x_tst = input_features_test\n",
    "y_tst = (doy_label_test-110)/(150-110) # normalise\n",
    "\n",
    "# tensor = torch.tensor(df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a0ecb888-463e-40fa-9d6b-2ddbd6143da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 148)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doy_label_train.min(), doy_label_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "283b04aa-99ba-41ed-aeb2-a4a5e82d57b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ONI_AMJ_prev</th>\n",
       "      <th>ONI_MJJ_prev</th>\n",
       "      <th>ONI_JJA_prev</th>\n",
       "      <th>ONI_JAS_prev</th>\n",
       "      <th>ONI_ASO_prev</th>\n",
       "      <th>ONI_SON_prev</th>\n",
       "      <th>ONI_OND_prev</th>\n",
       "      <th>ONI_NDJ_prev</th>\n",
       "      <th>ONI_DJF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1953</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  ONI_AMJ_prev  ONI_MJJ_prev  ONI_JJA_prev  ONI_JAS_prev  ONI_ASO_prev  \\\n",
       "0  1953           0.2           0.0          -0.1           0.0           0.2   \n",
       "1  1954           0.8           0.8           0.7           0.7           0.8   \n",
       "2  1955          -0.5          -0.5          -0.6          -0.8          -0.9   \n",
       "3  1956          -0.8          -0.7          -0.7          -0.7          -1.1   \n",
       "4  1959           0.7           0.6           0.6           0.4           0.4   \n",
       "\n",
       "   ONI_SON_prev  ONI_OND_prev  ONI_NDJ_prev  ONI_DJF  \n",
       "0           0.1           0.0           0.1      0.4  \n",
       "1           0.8           0.8           0.8      0.8  \n",
       "2          -0.8          -0.7          -0.7     -0.7  \n",
       "3          -1.4          -1.7          -1.5     -1.1  \n",
       "4           0.4           0.5           0.6      0.6  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6b921591-89d2-424d-b897-209f788eb4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>ONI</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1953</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1953_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1953</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1953_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1953</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1953_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1953</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1953_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1953</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1953_9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  ONI year_month\n",
       "0    1953      5  0.2     1953_5\n",
       "55   1953      6  0.0     1953_6\n",
       "110  1953      7 -0.1     1953_7\n",
       "165  1953      8  0.0     1953_8\n",
       "220  1953      9  0.2     1953_9"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping of seasons to actual month numbers\n",
    "season_to_month = {\n",
    "    \"AMJ_prev\": 5, \"MJJ_prev\": 6, \"JJA_prev\": 7, \"JAS_prev\": 8, \"ASO_prev\": 9, \n",
    "    \"SON_prev\": 10, \"OND_prev\": 11, \"NDJ_prev\": 12, \"DJF\": 13\n",
    "}\n",
    "\n",
    "\n",
    "# Convert to long format\n",
    "x_trn = x_trn.melt(id_vars=[\"year\"], var_name=\"season\", value_name=\"ONI\")\n",
    "\n",
    "# Extract season key (e.g., AMJ_prev, MJJ_prev, DJF)\n",
    "x_trn[\"season_key\"] = x_trn[\"season\"].str.replace(\"ONI_\", \"\")\n",
    "\n",
    "# Map to actual months\n",
    "x_trn[\"month\"] = x_trn[\"season_key\"].map(season_to_month)\n",
    "\n",
    "# Create year-month column\n",
    "x_trn[\"year_month\"] = x_trn[\"year\"].astype(str) + \"_\" + x_trn[\"month\"].astype(str)\n",
    "\n",
    "# Keep only required columns\n",
    "x_trn = x_trn[[\"year\", \"month\", \"ONI\", \"year_month\"]]\n",
    "\n",
    "x_trn = x_trn.sort_values([\"year\", \"month\"])\n",
    "\n",
    "x_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2dcbb869-7d4b-4fe7-aeca-cd46b2b1fc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>ONI</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2017_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>2017_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2017_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2017_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2017_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>2017_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>2017_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2017_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2017_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2018_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2018_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2018_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>2018_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2018_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>2018_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>2018_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>2018_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2019_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2019_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2019_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2019_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2019_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2019_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2019_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2019_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2020_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2020_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2020_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2020_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2020_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2020_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2020_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2020_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020</td>\n",
       "      <td>13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2020_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>2021_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2021_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2021_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2021_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>2021_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>2021_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>2021_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>2021_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2021</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2021_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  ONI year_month\n",
       "0   2017      5  0.4     2017_5\n",
       "5   2017      6 -0.1     2017_6\n",
       "10  2017      7 -0.4     2017_7\n",
       "15  2017      8 -0.5     2017_8\n",
       "20  2017      9 -0.6     2017_9\n",
       "25  2017     10 -0.7    2017_10\n",
       "30  2017     11 -0.7    2017_11\n",
       "35  2017     12 -0.6    2017_12\n",
       "40  2017     13 -0.3    2017_13\n",
       "1   2018      5  0.3     2018_5\n",
       "6   2018      6  0.3     2018_6\n",
       "11  2018      7  0.1     2018_7\n",
       "16  2018      8 -0.1     2018_8\n",
       "21  2018      9 -0.4     2018_9\n",
       "26  2018     10 -0.7    2018_10\n",
       "31  2018     11 -0.8    2018_11\n",
       "36  2018     12 -1.0    2018_12\n",
       "41  2018     13 -0.9    2018_13\n",
       "2   2019      5 -0.2     2019_5\n",
       "7   2019      6  0.0     2019_6\n",
       "12  2019      7  0.1     2019_7\n",
       "17  2019      8  0.2     2019_8\n",
       "22  2019      9  0.5     2019_9\n",
       "27  2019     10  0.8    2019_10\n",
       "32  2019     11  0.9    2019_11\n",
       "37  2019     12  0.8    2019_12\n",
       "42  2019     13  0.7    2019_13\n",
       "3   2020      5  0.5     2020_5\n",
       "8   2020      6  0.5     2020_6\n",
       "13  2020      7  0.3     2020_7\n",
       "18  2020      8  0.1     2020_8\n",
       "23  2020      9  0.2     2020_9\n",
       "28  2020     10  0.3    2020_10\n",
       "33  2020     11  0.5    2020_11\n",
       "38  2020     12  0.5    2020_12\n",
       "43  2020     13  0.5    2020_13\n",
       "4   2021      5 -0.1     2021_5\n",
       "9   2021      6 -0.3     2021_6\n",
       "14  2021      7 -0.4     2021_7\n",
       "19  2021      8 -0.6     2021_8\n",
       "24  2021      9 -0.9     2021_9\n",
       "29  2021     10 -1.2    2021_10\n",
       "34  2021     11 -1.3    2021_11\n",
       "39  2021     12 -1.2    2021_12\n",
       "44  2021     13 -1.0    2021_13"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping of seasons to actual month numbers\n",
    "season_to_month = {\n",
    "    \"AMJ_prev\": 5, \"MJJ_prev\": 6, \"JJA_prev\": 7, \"JAS_prev\": 8, \"ASO_prev\": 9, \n",
    "    \"SON_prev\": 10, \"OND_prev\": 11, \"NDJ_prev\": 12, \"DJF\": 13\n",
    "}\n",
    "\n",
    "\n",
    "# Convert to long format\n",
    "x_tst = x_tst.melt(id_vars=[\"year\"], var_name=\"season\", value_name=\"ONI\")\n",
    "\n",
    "# Extract season key (e.g., AMJ_prev, MJJ_prev, DJF)\n",
    "x_tst[\"season_key\"] = x_tst[\"season\"].str.replace(\"ONI_\", \"\")\n",
    "\n",
    "# Map to actual months\n",
    "x_tst[\"month\"] = x_tst[\"season_key\"].map(season_to_month)\n",
    "\n",
    "# Create year-month column\n",
    "x_tst[\"year_month\"] = x_tst[\"year\"].astype(str) + \"_\" + x_tst[\"month\"].astype(str)\n",
    "\n",
    "# Keep only required columns\n",
    "x_tst = x_tst[[\"year\", \"month\", \"ONI\", \"year_month\"]]\n",
    "\n",
    "x_tst = x_tst.sort_values([\"year\", \"month\"])\n",
    "\n",
    "x_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cf32a457-efc3-43fc-bffb-65d8fdae5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  month  ONI year_month\n",
      "0   1953      5  0.2     1953_5\n",
      "2   1953      6  0.0     1953_6\n",
      "4   1953      7 -0.1     1953_7\n",
      "6   1953      8  0.0     1953_8\n",
      "8   1953      9  0.2     1953_9\n",
      "10  1953     10  0.1    1953_10\n",
      "12  1953     11  0.0    1953_11\n",
      "14  1953     12  0.1    1953_12\n",
      "16  1953     13  0.4    1953_13\n",
      "1   1954      5  0.8     1954_5\n",
      "3   1954      6  0.8     1954_6\n",
      "5   1954      7  0.7     1954_7\n",
      "7   1954      8  0.7     1954_8\n",
      "9   1954      9  0.8     1954_9\n",
      "11  1954     10  0.8    1954_10\n",
      "13  1954     11  0.8    1954_11\n",
      "15  1954     12  0.8    1954_12\n",
      "17  1954     13  0.8    1954_13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataframe\n",
    "data = {\n",
    "    \"year\": [1953, 1954],\n",
    "    \"ONI_AMJ_prev\": [0.2, 0.8], \"ONI_MJJ_prev\": [0.0, 0.8], \"ONI_JJA_prev\": [-0.1, 0.7], \n",
    "    \"ONI_JAS_prev\": [0.0, 0.7], \"ONI_ASO_prev\": [0.2, 0.8], \"ONI_SON_prev\": [0.1, 0.8], \n",
    "    \"ONI_OND_prev\": [0.0, 0.8], \"ONI_NDJ_prev\": [0.1, 0.8], \"ONI_DJF\": [0.4, 0.8]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a mapping of seasons to actual month numbers\n",
    "season_to_month = {\n",
    "    \"AMJ_prev\": 5, \"MJJ_prev\": 6, \"JJA_prev\": 7, \"JAS_prev\": 8, \"ASO_prev\": 9, \n",
    "    \"SON_prev\": 10, \"OND_prev\": 11, \"NDJ_prev\": 12, \"DJF\": 13\n",
    "}\n",
    "\n",
    "# Convert to long format\n",
    "df_long = df.melt(id_vars=[\"year\"], var_name=\"season\", value_name=\"ONI\")\n",
    "\n",
    "# Extract season key (e.g., AMJ_prev, MJJ_prev, DJF)\n",
    "df_long[\"season_key\"] = df_long[\"season\"].str.replace(\"ONI_\", \"\")\n",
    "\n",
    "# Map to actual months\n",
    "df_long[\"month\"] = df_long[\"season_key\"].map(season_to_month)\n",
    "\n",
    "# Create year-month column\n",
    "df_long[\"year_month\"] = df_long[\"year\"].astype(str) + \"_\" + df_long[\"month\"].astype(str)\n",
    "\n",
    "# Keep only required columns\n",
    "df_long = df_long[[\"year\", \"month\", \"ONI\", \"year_month\"]]\n",
    "\n",
    "df_long = df_long.sort_values([\"year\", \"month\"])\n",
    "\n",
    "print(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3fd183c8-e6b0-4cae-887e-2b1bf781537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    pass\n",
    "    doy_label_train == (y_trn * (150 - 110) + 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1add3329-7ea3-4d11-bd13-b9e5f3ed39d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doy_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1cef9184-aa97-41a8-8d6c-b22011d14412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 495 entries, 0 to 494\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   year        495 non-null    int64  \n",
      " 1   month       495 non-null    int64  \n",
      " 2   ONI         495 non-null    float64\n",
      " 3   year_month  495 non-null    object \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 19.3+ KB\n"
     ]
    }
   ],
   "source": [
    "x_trn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28a1ef8a-a9cf-4e37-8662-f645902e0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for arr in x_trn.iterrows():\n",
    "    # print(arr)\n",
    "    #arr = torch.tensor(x_trn.values, dtype=torch.float32)\n",
    "    #print(torch.tensor(arr, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6117465b-2528-44b3-b425-929b1c5cb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_trn.values\n",
    "#[torch.tensor(arr, dtype=torch.float32) for arr in (x_trn.values, x_trn.values)][0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "24ff1f4d-ea59-4644-921d-1d8b3b584db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train, X_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (x_trn, x_trn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace00c0d-8e57-4a7e-b2a2-25f5603ab44f",
   "metadata": {},
   "source": [
    "## helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2e12e4e9-9f9f-4e56-b82a-92a5d5483098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets_old(X, y, test_size=0.2, drop_cols=ID_COLS, time_dim_first=False):\n",
    "    #enc = LabelEncoder()\n",
    "    #y_enc = enc.fit_transform(y)\n",
    "    \n",
    "    # ONI data (batch_size=any, seq_length=9, input_dim=1)\n",
    "\n",
    "    #enc = None\n",
    "    \n",
    "    X = create_grouped_array(X)\n",
    "    \n",
    "    #X_grouped = create_grouped_array(X)\n",
    "    #if time_dim_first:\n",
    "    #    X_grouped = X_grouped.transpose(0, 2, 1)\n",
    "        \n",
    "    #X = X.transpose(0, 2, 1) # this is not working with df i imagine, plus idk what order i need ...\n",
    "    \n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y.to_list(), test_size=0.1)\n",
    "    \n",
    "    # valid = last 5 years\n",
    "    X_train, X_valid = X[:-5], X[-5:]\n",
    "    y_train, y_valid = y[:-5], y[-5:] \n",
    "    \n",
    "    print(X_train)\n",
    "\n",
    "    # torch.tensor(x_trn.values, dtype=torch.float32)\n",
    "    \n",
    "    X_train, X_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train.values, X_valid.values)]\n",
    "    y_train, y_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (y_train.values, y_valid.values)] # changed to float\n",
    "    \n",
    "    # get back to other code ...\n",
    "    # TODO TODO TODO\n",
    "    # the grouped thing should be done - i am currently taking 9 features of length one instead of 1 feature (ONI) with length 9 (aka 9 months)\n",
    "    \n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    valid_ds = TensorDataset(X_valid, y_valid)\n",
    "    return train_ds, valid_ds, None\n",
    "\n",
    "\n",
    "def create_datasets(X, y, test_size=0.2, drop_cols=ID_COLS, time_dim_first=False):\n",
    "    #enc = LabelEncoder()\n",
    "    #y_enc = enc.fit_transform(y)\n",
    "    X_grouped = create_grouped_array(X)\n",
    "    if time_dim_first:\n",
    "        X_grouped = X_grouped.transpose(0, 2, 1)\n",
    "        \n",
    "    #X_train, X_valid, y_train, y_valid = train_test_split(X_grouped, y, test_size=0.1)\n",
    "    #X_train, X_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train, X_valid)]\n",
    "    #y_train, y_valid = [torch.tensor(arr, dtype=torch.long) for arr in (y_train, y_valid)]\n",
    "    \n",
    "    X_train, X_valid = X_grouped[:-5], X_grouped[-5:]\n",
    "    y_train, y_valid = y[:-5], y[-5:] \n",
    "    \n",
    "    #print(X)\n",
    "    #print(X_train)\n",
    "    \n",
    "    # print(y_train)\n",
    "    \n",
    "    #X_train, X_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train.values, X_valid.values)]\n",
    "    y_train, y_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (y_train.values, y_valid.values)]\n",
    "    \n",
    "    X_train, X_valid = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train, X_valid)]\n",
    "    # y_train, y_valid = [torch.tensor(arr, dtype=torch.long) for arr in (y_train, y_valid)]\n",
    "    \n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    valid_ds = TensorDataset(X_valid, y_valid)\n",
    "    return train_ds, valid_ds, None\n",
    "\n",
    "\n",
    "def create_grouped_array(data, group_col='year', drop_cols=ID_COLS):\n",
    "    X_grouped = np.row_stack([\n",
    "        group.drop(columns=drop_cols).values[None]\n",
    "        for _, group in data.groupby(group_col)])\n",
    "    return X_grouped\n",
    "\n",
    "\n",
    "def create_test_dataset(X, drop_cols=ID_COLS):\n",
    "    X_grouped = np.row_stack([\n",
    "        group.drop(columns=drop_cols).values[None]\n",
    "        for _, group in X.groupby('year')])\n",
    "    X_grouped = torch.tensor(X_grouped.transpose(0, 2, 1)).float()\n",
    "    y_fake = torch.tensor([0] * len(X_grouped)).long()\n",
    "    return TensorDataset(X_grouped, y_fake)\n",
    "\n",
    "\n",
    "def create_loaders(train_ds, valid_ds, bs=512, jobs=0):\n",
    "    train_dl = DataLoader(train_ds, bs, shuffle=True, num_workers=jobs)\n",
    "    valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=jobs)\n",
    "    return train_dl, valid_dl\n",
    "\n",
    "\n",
    "def accuracy(output, target):\n",
    "    return (output.argmax(dim=1) == target).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cc4eae1e-e6ac-4820-a92f-079f0fe44f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "112775a7-ad94-4e6d-929f-ad00d7f2c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "12fc0671-e063-446f-abc1-6aaff4296ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1780ca31c40>]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 100\n",
    "sched = cosine(n)\n",
    "lrs = [sched(t, 1) for t in range(n * 4)]\n",
    "plt.plot(lrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c9c8f667-97e5-44b1-9cb5-41e608636356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # (batch_size, seq_length, input_size) # 4, 1, 10\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True) # why is it 1???\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        \n",
    "        print(\"x\", x.shape)\n",
    "        \n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        \n",
    "        print(\"out.shape\", out.shape)\n",
    "        print(\"out[:, -1, :].shape\", out[:, -1, :].shape)\n",
    "        print(\"out[0:2, 0, 0:4]\", out[0:2, 0, 0:4])\n",
    "        \n",
    "        out = self.fc(out[:, -1, :]) # out[:, -1, :])\n",
    "        \n",
    "        print(\"after fc out\", out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.cuda() for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f32ab35e-4b8c-4382-ad9b-dddace19efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets\n"
     ]
    }
   ],
   "source": [
    "print('Preparing datasets')\n",
    "trn_ds, val_ds, enc = create_datasets(x_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9927f57c-c24c-4b3a-a88a-6872509f466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data loaders with batch size: 8\n"
     ]
    }
   ],
   "source": [
    "bs = 8 # must be less than 70, cause we only have 70 years ...\n",
    "print(f'Creating data loaders with batch size: {bs}')\n",
    "trn_dl, val_dl = create_loaders(trn_ds, val_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "577eb455-20b7-4480-a95f-3f6591268e23",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0204, -0.0168, -0.0195,  0.0130],\n",
      "        [-0.0205, -0.0167, -0.0194,  0.0131]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[-0.0403],\n",
      "        [-0.0402],\n",
      "        [-0.0404],\n",
      "        [-0.0403],\n",
      "        [-0.0404],\n",
      "        [-0.0403],\n",
      "        [-0.0404],\n",
      "        [-0.0404]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[-0.0403],\n",
      "        [-0.0402],\n",
      "        [-0.0404],\n",
      "        [-0.0403],\n",
      "        [-0.0404],\n",
      "        [-0.0403],\n",
      "        [-0.0404],\n",
      "        [-0.0404]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.5750, 0.6000, 0.7000, 0.4750, 0.6000, 0.6500, 0.6000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0265, -0.0243, -0.0130,  0.0070],\n",
      "        [-0.0265, -0.0242, -0.0130,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.3436],\n",
      "        [0.3519],\n",
      "        [0.3446],\n",
      "        [0.3398],\n",
      "        [0.3579],\n",
      "        [0.3236],\n",
      "        [0.3536],\n",
      "        [0.3470]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0351, -0.0315, -0.0107,  0.0037],\n",
      "        [-0.0352, -0.0316, -0.0107,  0.0037]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[3.8813],\n",
      "        [3.9309],\n",
      "        [3.8482],\n",
      "        [3.9241],\n",
      "        [3.9379],\n",
      "        [3.8665],\n",
      "        [3.9326],\n",
      "        [3.7842]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0248, -0.0218, -0.0079,  0.0098],\n",
      "        [-0.0250, -0.0219, -0.0077,  0.0097]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.2712],\n",
      "        [0.2825],\n",
      "        [0.2640],\n",
      "        [0.2774],\n",
      "        [0.2685],\n",
      "        [0.2719],\n",
      "        [0.2677],\n",
      "        [0.2695]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0253, -0.0229, -0.0089,  0.0094],\n",
      "        [-0.0253, -0.0229, -0.0089,  0.0094]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.3152],\n",
      "        [0.3299],\n",
      "        [0.3256],\n",
      "        [0.3706],\n",
      "        [0.3594],\n",
      "        [0.3707],\n",
      "        [0.3211],\n",
      "        [0.3174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0262, -0.0238, -0.0090,  0.0089],\n",
      "        [-0.0262, -0.0238, -0.0090,  0.0089]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.3983],\n",
      "        [0.3761],\n",
      "        [0.3908],\n",
      "        [0.3926],\n",
      "        [0.3709],\n",
      "        [0.4080],\n",
      "        [0.4114],\n",
      "        [0.3679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0268, -0.0245, -0.0094,  0.0086],\n",
      "        [-0.0262, -0.0242, -0.0098,  0.0089]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.4426],\n",
      "        [0.4093]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0266, -0.0247, -0.0102,  0.0088],\n",
      "        [-0.0267, -0.0247, -0.0101,  0.0087]], device='cuda:0')\n",
      "after fc out tensor([[0.4430],\n",
      "        [0.4662],\n",
      "        [0.4548],\n",
      "        [0.4712],\n",
      "        [0.5170]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0268, -0.0248, -0.0100,  0.0087],\n",
      "        [-0.0265, -0.0246, -0.0102,  0.0088]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.4751],\n",
      "        [0.4280],\n",
      "        [0.4575],\n",
      "        [0.4771],\n",
      "        [0.4764],\n",
      "        [0.4506],\n",
      "        [0.4696],\n",
      "        [0.4884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.4751],\n",
      "        [0.4280],\n",
      "        [0.4575],\n",
      "        [0.4771],\n",
      "        [0.4764],\n",
      "        [0.4506],\n",
      "        [0.4696],\n",
      "        [0.4884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.7250, 0.2750, 0.5750, 0.4250, 0.4250, 0.6750, 0.5500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0268, -0.0249, -0.0102,  0.0087],\n",
      "        [-0.0268, -0.0248, -0.0102,  0.0087]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.4886],\n",
      "        [0.4619],\n",
      "        [0.4797],\n",
      "        [0.4497],\n",
      "        [0.4660],\n",
      "        [0.4600],\n",
      "        [0.4542],\n",
      "        [0.4636]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0268, -0.0250, -0.0105,  0.0087],\n",
      "        [-0.0272, -0.0252, -0.0103,  0.0085]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.4740],\n",
      "        [0.4951],\n",
      "        [0.4687],\n",
      "        [0.4939],\n",
      "        [0.5179],\n",
      "        [0.4947],\n",
      "        [0.4832],\n",
      "        [0.5381]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0274, -0.0255, -0.0104,  0.0084],\n",
      "        [-0.0271, -0.0253, -0.0106,  0.0086]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5617],\n",
      "        [0.4877],\n",
      "        [0.5264],\n",
      "        [0.5372],\n",
      "        [0.5041],\n",
      "        [0.5383],\n",
      "        [0.5310],\n",
      "        [0.5066]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0276, -0.0256, -0.0104,  0.0084],\n",
      "        [-0.0272, -0.0254, -0.0107,  0.0086]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5709],\n",
      "        [0.5067],\n",
      "        [0.5008],\n",
      "        [0.5525],\n",
      "        [0.5010],\n",
      "        [0.5269],\n",
      "        [0.5460],\n",
      "        [0.5539]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0274, -0.0255, -0.0106,  0.0084],\n",
      "        [-0.0273, -0.0254, -0.0107,  0.0085]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5409],\n",
      "        [0.5337],\n",
      "        [0.5321],\n",
      "        [0.5902],\n",
      "        [0.5599],\n",
      "        [0.5467],\n",
      "        [0.5791],\n",
      "        [0.5539]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0276, -0.0256, -0.0105,  0.0084],\n",
      "        [-0.0272, -0.0254, -0.0108,  0.0086]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5454],\n",
      "        [0.5263]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0272, -0.0254, -0.0108,  0.0086],\n",
      "        [-0.0273, -0.0255, -0.0107,  0.0085]], device='cuda:0')\n",
      "after fc out tensor([[0.5237],\n",
      "        [0.5465],\n",
      "        [0.5349],\n",
      "        [0.5512],\n",
      "        [0.5972]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0272, -0.0254, -0.0108,  0.0085],\n",
      "        [-0.0271, -0.0254, -0.0108,  0.0086]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5250],\n",
      "        [0.5160],\n",
      "        [0.5382],\n",
      "        [0.5549],\n",
      "        [0.5571],\n",
      "        [0.5374],\n",
      "        [0.5600],\n",
      "        [0.5600]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5250],\n",
      "        [0.5160],\n",
      "        [0.5382],\n",
      "        [0.5549],\n",
      "        [0.5571],\n",
      "        [0.5374],\n",
      "        [0.5600],\n",
      "        [0.5600]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7500, 0.6000, 0.9250, 0.6500, 0.5750, 0.6750, 0.5000, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0259, -0.0111,  0.0084],\n",
      "        [-0.0276, -0.0259, -0.0112,  0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5705],\n",
      "        [0.5890],\n",
      "        [0.5928],\n",
      "        [0.6187],\n",
      "        [0.5689],\n",
      "        [0.5876],\n",
      "        [0.6082],\n",
      "        [0.6048]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0266, -0.0115,  0.0081],\n",
      "        [-0.0283, -0.0266, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7210],\n",
      "        [0.7241],\n",
      "        [0.7104],\n",
      "        [0.6978],\n",
      "        [0.7142],\n",
      "        [0.6767],\n",
      "        [0.6915],\n",
      "        [0.7355]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0258, -0.0106,  0.0083],\n",
      "        [-0.0274, -0.0257, -0.0108,  0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5813],\n",
      "        [0.5518],\n",
      "        [0.5485],\n",
      "        [0.5460],\n",
      "        [0.5426],\n",
      "        [0.5508],\n",
      "        [0.5561],\n",
      "        [0.5739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0259, -0.0107,  0.0083],\n",
      "        [-0.0276, -0.0258, -0.0108,  0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5852],\n",
      "        [0.5692],\n",
      "        [0.5625],\n",
      "        [0.5756],\n",
      "        [0.5587],\n",
      "        [0.5728],\n",
      "        [0.5513],\n",
      "        [0.5629]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0261, -0.0113,  0.0083],\n",
      "        [-0.0280, -0.0262, -0.0111,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6181],\n",
      "        [0.6228],\n",
      "        [0.6030],\n",
      "        [0.6096],\n",
      "        [0.6069],\n",
      "        [0.6356],\n",
      "        [0.6257],\n",
      "        [0.6215]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0261, -0.0114,  0.0084],\n",
      "        [-0.0280, -0.0262, -0.0111,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6118],\n",
      "        [0.6232]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0276, -0.0260, -0.0112,  0.0084],\n",
      "        [-0.0277, -0.0260, -0.0111,  0.0084]], device='cuda:0')\n",
      "after fc out tensor([[0.5835],\n",
      "        [0.5936],\n",
      "        [0.5881],\n",
      "        [0.5957],\n",
      "        [0.6190]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0261, -0.0110,  0.0083],\n",
      "        [-0.0277, -0.0260, -0.0111,  0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5817],\n",
      "        [0.5892],\n",
      "        [0.5987],\n",
      "        [0.6112],\n",
      "        [0.5905],\n",
      "        [0.5876],\n",
      "        [0.5940],\n",
      "        [0.5775]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5817],\n",
      "        [0.5892],\n",
      "        [0.5987],\n",
      "        [0.6112],\n",
      "        [0.5905],\n",
      "        [0.5876],\n",
      "        [0.5940],\n",
      "        [0.5775]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.5250, 0.4250, 0.3750, 0.9250, 0.6250, 0.6000, 0.7250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0275, -0.0259, -0.0112,  0.0084],\n",
      "        [-0.0277, -0.0260, -0.0111,  0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5883],\n",
      "        [0.5904],\n",
      "        [0.5876],\n",
      "        [0.6039],\n",
      "        [0.5869],\n",
      "        [0.6120],\n",
      "        [0.5881],\n",
      "        [0.6188]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0261, -0.0111,  0.0083],\n",
      "        [-0.0277, -0.0261, -0.0112,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6096],\n",
      "        [0.5908],\n",
      "        [0.6220],\n",
      "        [0.5957],\n",
      "        [0.6046],\n",
      "        [0.6092],\n",
      "        [0.5929],\n",
      "        [0.6122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0261, -0.0114,  0.0084],\n",
      "        [-0.0279, -0.0262, -0.0112,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6077],\n",
      "        [0.6212],\n",
      "        [0.6366],\n",
      "        [0.6205],\n",
      "        [0.6230],\n",
      "        [0.6228],\n",
      "        [0.6294],\n",
      "        [0.6245]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0263, -0.0111,  0.0082],\n",
      "        [-0.0278, -0.0262, -0.0114,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6251],\n",
      "        [0.6143],\n",
      "        [0.6193],\n",
      "        [0.6196],\n",
      "        [0.6225],\n",
      "        [0.6277],\n",
      "        [0.6132],\n",
      "        [0.6096]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0262, -0.0114,  0.0083],\n",
      "        [-0.0280, -0.0263, -0.0112,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6139],\n",
      "        [0.6332],\n",
      "        [0.6354],\n",
      "        [0.6143],\n",
      "        [0.6240],\n",
      "        [0.6198],\n",
      "        [0.6334],\n",
      "        [0.6231]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0262, -0.0112,  0.0082],\n",
      "        [-0.0277, -0.0262, -0.0114,  0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6277],\n",
      "        [0.6186]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0262, -0.0114,  0.0083],\n",
      "        [-0.0278, -0.0262, -0.0113,  0.0083]], device='cuda:0')\n",
      "after fc out tensor([[0.6136],\n",
      "        [0.6226],\n",
      "        [0.6176],\n",
      "        [0.6244],\n",
      "        [0.6462]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0263, -0.0111,  0.0082],\n",
      "        [-0.0281, -0.0263, -0.0111,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6305],\n",
      "        [0.6452],\n",
      "        [0.6395],\n",
      "        [0.6285],\n",
      "        [0.6252],\n",
      "        [0.6186],\n",
      "        [0.6228],\n",
      "        [0.6123]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6305],\n",
      "        [0.6452],\n",
      "        [0.6395],\n",
      "        [0.6285],\n",
      "        [0.6252],\n",
      "        [0.6186],\n",
      "        [0.6228],\n",
      "        [0.6123]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7250, 0.2750, 0.5750, 0.5000, 0.5000, 0.5250, 0.6000, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0258, -0.0107,  0.0083],\n",
      "        [-0.0276, -0.0258, -0.0108,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5631],\n",
      "        [0.5658],\n",
      "        [0.5600],\n",
      "        [0.5651],\n",
      "        [0.5580],\n",
      "        [0.5651],\n",
      "        [0.5608],\n",
      "        [0.5589]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0274, -0.0258, -0.0109,  0.0084],\n",
      "        [-0.0276, -0.0258, -0.0108,  0.0084]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5570],\n",
      "        [0.5653],\n",
      "        [0.5669],\n",
      "        [0.5595],\n",
      "        [0.5647],\n",
      "        [0.5571],\n",
      "        [0.5570],\n",
      "        [0.5655]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0265, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0265, -0.0116,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6633],\n",
      "        [0.6596],\n",
      "        [0.6606],\n",
      "        [0.6630],\n",
      "        [0.6594],\n",
      "        [0.6690],\n",
      "        [0.6596],\n",
      "        [0.6621]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0265, -0.0115,  0.0082],\n",
      "        [-0.0280, -0.0265, -0.0116,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6556],\n",
      "        [0.6577],\n",
      "        [0.6584],\n",
      "        [0.6621],\n",
      "        [0.6598],\n",
      "        [0.6635],\n",
      "        [0.6558],\n",
      "        [0.6585]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0264, -0.0113,  0.0081],\n",
      "        [-0.0280, -0.0264, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6481],\n",
      "        [0.6506],\n",
      "        [0.6486],\n",
      "        [0.6475],\n",
      "        [0.6490],\n",
      "        [0.6476],\n",
      "        [0.6478],\n",
      "        [0.6467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0262, -0.0112,  0.0083],\n",
      "        [-0.0279, -0.0262, -0.0111,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6122],\n",
      "        [0.6123]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0118,  0.0082],\n",
      "        [-0.0282, -0.0267, -0.0117,  0.0082]], device='cuda:0')\n",
      "after fc out tensor([[0.6874],\n",
      "        [0.6852],\n",
      "        [0.6858],\n",
      "        [0.6848],\n",
      "        [0.6876]], device='cuda:0')\n",
      "Epoch:   5. Loss: 0.0434. mean_squared_error.: 0.06437720358371735\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0118,  0.0082],\n",
      "        [-0.0282, -0.0267, -0.0117,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6861],\n",
      "        [0.6849],\n",
      "        [0.6857],\n",
      "        [0.6887],\n",
      "        [0.6849],\n",
      "        [0.6849],\n",
      "        [0.6857],\n",
      "        [0.6863]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6861],\n",
      "        [0.6849],\n",
      "        [0.6857],\n",
      "        [0.6887],\n",
      "        [0.6849],\n",
      "        [0.6849],\n",
      "        [0.6857],\n",
      "        [0.6863]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5000, 0.5750, 0.9000, 0.4000, 0.6000, 0.8500, 0.8000, 0.7750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0116,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0117,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6804],\n",
      "        [0.6800],\n",
      "        [0.6809],\n",
      "        [0.6848],\n",
      "        [0.6806],\n",
      "        [0.6818],\n",
      "        [0.6803],\n",
      "        [0.6811]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0265, -0.0115,  0.0082],\n",
      "        [-0.0281, -0.0265, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6533],\n",
      "        [0.6532],\n",
      "        [0.6535],\n",
      "        [0.6571],\n",
      "        [0.6544],\n",
      "        [0.6543],\n",
      "        [0.6537],\n",
      "        [0.6551]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0266, -0.0116,  0.0082],\n",
      "        [-0.0280, -0.0266, -0.0117,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6604],\n",
      "        [0.6620],\n",
      "        [0.6644],\n",
      "        [0.6607],\n",
      "        [0.6608],\n",
      "        [0.6606],\n",
      "        [0.6641],\n",
      "        [0.6619]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0265, -0.0116,  0.0082],\n",
      "        [-0.0280, -0.0265, -0.0116,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6541],\n",
      "        [0.6543],\n",
      "        [0.6568],\n",
      "        [0.6544],\n",
      "        [0.6559],\n",
      "        [0.6547],\n",
      "        [0.6586],\n",
      "        [0.6538]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0265, -0.0114,  0.0082],\n",
      "        [-0.0279, -0.0265, -0.0116,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6496],\n",
      "        [0.6485],\n",
      "        [0.6487],\n",
      "        [0.6486],\n",
      "        [0.6498],\n",
      "        [0.6485],\n",
      "        [0.6505],\n",
      "        [0.6514]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0265, -0.0116,  0.0083],\n",
      "        [-0.0280, -0.0265, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6468],\n",
      "        [0.6469]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0265, -0.0115,  0.0083],\n",
      "        [-0.0280, -0.0265, -0.0115,  0.0082]], device='cuda:0')\n",
      "after fc out tensor([[0.6456],\n",
      "        [0.6450],\n",
      "        [0.6448],\n",
      "        [0.6450],\n",
      "        [0.6501]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0265, -0.0115,  0.0083],\n",
      "        [-0.0279, -0.0265, -0.0116,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6448],\n",
      "        [0.6450],\n",
      "        [0.6456],\n",
      "        [0.6476],\n",
      "        [0.6482],\n",
      "        [0.6468],\n",
      "        [0.6452],\n",
      "        [0.6473]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6448],\n",
      "        [0.6450],\n",
      "        [0.6456],\n",
      "        [0.6476],\n",
      "        [0.6482],\n",
      "        [0.6468],\n",
      "        [0.6452],\n",
      "        [0.6473]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.4750, 0.4250, 0.4250, 0.7000, 0.7750, 0.8000, 0.6500, 0.7250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0263, -0.0114,  0.0083],\n",
      "        [-0.0279, -0.0263, -0.0114,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6266],\n",
      "        [0.6267],\n",
      "        [0.6281],\n",
      "        [0.6268],\n",
      "        [0.6273],\n",
      "        [0.6277],\n",
      "        [0.6271],\n",
      "        [0.6263]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0266, -0.0115,  0.0081],\n",
      "        [-0.0282, -0.0266, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6744],\n",
      "        [0.6754],\n",
      "        [0.6788],\n",
      "        [0.6752],\n",
      "        [0.6737],\n",
      "        [0.6760],\n",
      "        [0.6763],\n",
      "        [0.6739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0266, -0.0116,  0.0081],\n",
      "        [-0.0281, -0.0266, -0.0117,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6735],\n",
      "        [0.6746],\n",
      "        [0.6780],\n",
      "        [0.6745],\n",
      "        [0.6737],\n",
      "        [0.6794],\n",
      "        [0.6740],\n",
      "        [0.6750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0261, -0.0111,  0.0083],\n",
      "        [-0.0277, -0.0261, -0.0111,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5872],\n",
      "        [0.5870],\n",
      "        [0.5873],\n",
      "        [0.5871],\n",
      "        [0.5870],\n",
      "        [0.5871],\n",
      "        [0.5878],\n",
      "        [0.5878]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0264, -0.0115,  0.0083],\n",
      "        [-0.0280, -0.0264, -0.0114,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6323],\n",
      "        [0.6338],\n",
      "        [0.6320],\n",
      "        [0.6315],\n",
      "        [0.6318],\n",
      "        [0.6348],\n",
      "        [0.6332],\n",
      "        [0.6317]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0276, -0.0261, -0.0112,  0.0083],\n",
      "        [-0.0279, -0.0261, -0.0109,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5905],\n",
      "        [0.5892]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0263, -0.0113,  0.0083],\n",
      "        [-0.0278, -0.0263, -0.0113,  0.0083]], device='cuda:0')\n",
      "after fc out tensor([[0.6142],\n",
      "        [0.6104],\n",
      "        [0.6119],\n",
      "        [0.6097],\n",
      "        [0.6076]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0262, -0.0111,  0.0082],\n",
      "        [-0.0279, -0.0263, -0.0112,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6076],\n",
      "        [0.6093],\n",
      "        [0.6127],\n",
      "        [0.6115],\n",
      "        [0.6105],\n",
      "        [0.6138],\n",
      "        [0.6171],\n",
      "        [0.6097]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6076],\n",
      "        [0.6093],\n",
      "        [0.6127],\n",
      "        [0.6115],\n",
      "        [0.6105],\n",
      "        [0.6138],\n",
      "        [0.6171],\n",
      "        [0.6097]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.2750, 0.6500, 0.4250, 0.2750, 0.8000, 0.7500, 0.8000, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0261, -0.0111,  0.0083],\n",
      "        [-0.0277, -0.0262, -0.0112,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5935],\n",
      "        [0.5990],\n",
      "        [0.5927],\n",
      "        [0.5936],\n",
      "        [0.5944],\n",
      "        [0.5930],\n",
      "        [0.5932],\n",
      "        [0.6002]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0262, -0.0111,  0.0082],\n",
      "        [-0.0278, -0.0263, -0.0113,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6054],\n",
      "        [0.6083],\n",
      "        [0.6059],\n",
      "        [0.6048],\n",
      "        [0.6125],\n",
      "        [0.6073],\n",
      "        [0.6077],\n",
      "        [0.6074]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0263, -0.0113,  0.0083],\n",
      "        [-0.0279, -0.0263, -0.0113,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6164],\n",
      "        [0.6163],\n",
      "        [0.6222],\n",
      "        [0.6246],\n",
      "        [0.6174],\n",
      "        [0.6210],\n",
      "        [0.6171],\n",
      "        [0.6199]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0263, -0.0112,  0.0082],\n",
      "        [-0.0279, -0.0263, -0.0113,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.6183],\n",
      "        [0.6184],\n",
      "        [0.6224],\n",
      "        [0.6194],\n",
      "        [0.6262],\n",
      "        [0.6229],\n",
      "        [0.6179],\n",
      "        [0.6174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0263, -0.0112,  0.0082],\n",
      "        [-0.0278, -0.0263, -0.0114,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6169],\n",
      "        [0.6198],\n",
      "        [0.6168],\n",
      "        [0.6196],\n",
      "        [0.6202],\n",
      "        [0.6174],\n",
      "        [0.6235],\n",
      "        [0.6198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0264, -0.0114,  0.0083],\n",
      "        [-0.0279, -0.0263, -0.0113,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6206],\n",
      "        [0.6214]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0264, -0.0114,  0.0083],\n",
      "        [-0.0279, -0.0264, -0.0113,  0.0083]], device='cuda:0')\n",
      "after fc out tensor([[0.6238],\n",
      "        [0.6201],\n",
      "        [0.6216],\n",
      "        [0.6194],\n",
      "        [0.6175]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0264, -0.0114,  0.0083],\n",
      "        [-0.0278, -0.0264, -0.0114,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6229],\n",
      "        [0.6275],\n",
      "        [0.6214],\n",
      "        [0.6191],\n",
      "        [0.6202],\n",
      "        [0.6175],\n",
      "        [0.6269],\n",
      "        [0.6231]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6229],\n",
      "        [0.6275],\n",
      "        [0.6214],\n",
      "        [0.6191],\n",
      "        [0.6202],\n",
      "        [0.6175],\n",
      "        [0.6269],\n",
      "        [0.6231]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.7250, 0.9000, 0.4250, 0.9000, 0.3750, 0.7000, 0.9500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0116,  0.0081],\n",
      "        [-0.0283, -0.0267, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6681],\n",
      "        [0.6903],\n",
      "        [0.6782],\n",
      "        [0.6940],\n",
      "        [0.6739],\n",
      "        [0.6816],\n",
      "        [0.6768],\n",
      "        [0.6857]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0260, -0.0109,  0.0083],\n",
      "        [-0.0276, -0.0260, -0.0109,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5659],\n",
      "        [0.5691],\n",
      "        [0.5654],\n",
      "        [0.5657],\n",
      "        [0.5683],\n",
      "        [0.5704],\n",
      "        [0.5657],\n",
      "        [0.5661]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0275, -0.0260, -0.0111,  0.0084],\n",
      "        [-0.0276, -0.0260, -0.0110,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5720],\n",
      "        [0.5728],\n",
      "        [0.5716],\n",
      "        [0.5759],\n",
      "        [0.5701],\n",
      "        [0.5698],\n",
      "        [0.5713],\n",
      "        [0.5743]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0263, -0.0112,  0.0082],\n",
      "        [-0.0280, -0.0263, -0.0111,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6103],\n",
      "        [0.6080],\n",
      "        [0.6104],\n",
      "        [0.6123],\n",
      "        [0.6105],\n",
      "        [0.6039],\n",
      "        [0.6056],\n",
      "        [0.6073]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0265, -0.0114,  0.0082],\n",
      "        [-0.0280, -0.0265, -0.0114,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6312],\n",
      "        [0.6215],\n",
      "        [0.6218],\n",
      "        [0.6275],\n",
      "        [0.6177],\n",
      "        [0.6351],\n",
      "        [0.6223],\n",
      "        [0.6242]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0264, -0.0113,  0.0081],\n",
      "        [-0.0280, -0.0265, -0.0114,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6230],\n",
      "        [0.6275]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0118,  0.0081],\n",
      "        [-0.0283, -0.0269, -0.0118,  0.0081]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.6817],\n",
      "        [0.6812],\n",
      "        [0.6810],\n",
      "        [0.6812],\n",
      "        [0.6855]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0269, -0.0117,  0.0081],\n",
      "        [-0.0283, -0.0269, -0.0118,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6814],\n",
      "        [0.6810],\n",
      "        [0.6811],\n",
      "        [0.6812],\n",
      "        [0.6842],\n",
      "        [0.6829],\n",
      "        [0.6812],\n",
      "        [0.6817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6814],\n",
      "        [0.6810],\n",
      "        [0.6811],\n",
      "        [0.6812],\n",
      "        [0.6842],\n",
      "        [0.6829],\n",
      "        [0.6812],\n",
      "        [0.6817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.5750, 0.8500, 0.5750, 0.6500, 0.6750, 0.6750, 0.7000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0268, -0.0119,  0.0082],\n",
      "        [-0.0282, -0.0268, -0.0118,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6783],\n",
      "        [0.6781],\n",
      "        [0.6784],\n",
      "        [0.6778],\n",
      "        [0.6768],\n",
      "        [0.6783],\n",
      "        [0.6772],\n",
      "        [0.6780]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0117,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6556],\n",
      "        [0.6553],\n",
      "        [0.6559],\n",
      "        [0.6575],\n",
      "        [0.6582],\n",
      "        [0.6583],\n",
      "        [0.6556],\n",
      "        [0.6553]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0116,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6561],\n",
      "        [0.6538],\n",
      "        [0.6609],\n",
      "        [0.6553],\n",
      "        [0.6608],\n",
      "        [0.6536],\n",
      "        [0.6542],\n",
      "        [0.6536]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0116,  0.0081],\n",
      "        [-0.0283, -0.0267, -0.0115,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6561],\n",
      "        [0.6592],\n",
      "        [0.6570],\n",
      "        [0.6580],\n",
      "        [0.6574],\n",
      "        [0.6565],\n",
      "        [0.6575],\n",
      "        [0.6612]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0280, -0.0267, -0.0117,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6511],\n",
      "        [0.6506],\n",
      "        [0.6587],\n",
      "        [0.6538],\n",
      "        [0.6524],\n",
      "        [0.6509],\n",
      "        [0.6508],\n",
      "        [0.6524]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0116,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6479],\n",
      "        [0.6504]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0266, -0.0116,  0.0082]], device='cuda:0')\n",
      "after fc out tensor([[0.6451],\n",
      "        [0.6466],\n",
      "        [0.6455],\n",
      "        [0.6469],\n",
      "        [0.6541]], device='cuda:0')\n",
      "Epoch:  10. Loss: 0.0328. mean_squared_error.: 0.05447470396757126\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0116,  0.0082],\n",
      "        [-0.0282, -0.0266, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6450],\n",
      "        [0.6481],\n",
      "        [0.6457],\n",
      "        [0.6538],\n",
      "        [0.6479],\n",
      "        [0.6472],\n",
      "        [0.6452],\n",
      "        [0.6454]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6450],\n",
      "        [0.6481],\n",
      "        [0.6457],\n",
      "        [0.6538],\n",
      "        [0.6479],\n",
      "        [0.6472],\n",
      "        [0.6452],\n",
      "        [0.6454]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7500, 0.5000, 0.5750, 0.2750, 0.4250, 0.6500, 0.4000, 0.7000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0261, -0.0109,  0.0082],\n",
      "        [-0.0277, -0.0261, -0.0110,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5730],\n",
      "        [0.5752],\n",
      "        [0.5755],\n",
      "        [0.5790],\n",
      "        [0.5697],\n",
      "        [0.5725],\n",
      "        [0.5705],\n",
      "        [0.5730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0266, -0.0113,  0.0081],\n",
      "        [-0.0282, -0.0266, -0.0112,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6305],\n",
      "        [0.6354],\n",
      "        [0.6204],\n",
      "        [0.6239],\n",
      "        [0.6221],\n",
      "        [0.6222],\n",
      "        [0.6232],\n",
      "        [0.6185]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0265, -0.0115,  0.0083],\n",
      "        [-0.0279, -0.0265, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6175],\n",
      "        [0.6183],\n",
      "        [0.6266],\n",
      "        [0.6256],\n",
      "        [0.6178],\n",
      "        [0.6331],\n",
      "        [0.6296],\n",
      "        [0.6223]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0262, -0.0110,  0.0082],\n",
      "        [-0.0280, -0.0262, -0.0109,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5813],\n",
      "        [0.5800],\n",
      "        [0.5848],\n",
      "        [0.5753],\n",
      "        [0.5839],\n",
      "        [0.5731],\n",
      "        [0.5921],\n",
      "        [0.5770]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0115,  0.0081],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6377],\n",
      "        [0.6387],\n",
      "        [0.6378],\n",
      "        [0.6424],\n",
      "        [0.6409],\n",
      "        [0.6384],\n",
      "        [0.6404],\n",
      "        [0.6422]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0116,  0.0081],\n",
      "        [-0.0283, -0.0268, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6632],\n",
      "        [0.6587]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0116,  0.0082]], device='cuda:0')\n",
      "after fc out tensor([[0.6418],\n",
      "        [0.6450],\n",
      "        [0.6430],\n",
      "        [0.6455],\n",
      "        [0.6550]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0282, -0.0267, -0.0115,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6418],\n",
      "        [0.6467],\n",
      "        [0.6421],\n",
      "        [0.6455],\n",
      "        [0.6426],\n",
      "        [0.6469],\n",
      "        [0.6425],\n",
      "        [0.6462]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6418],\n",
      "        [0.6467],\n",
      "        [0.6421],\n",
      "        [0.6455],\n",
      "        [0.6426],\n",
      "        [0.6469],\n",
      "        [0.6425],\n",
      "        [0.6462]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7500, 0.6000, 0.5750, 0.8500, 0.5500, 0.4250, 0.4250, 0.6500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0266, -0.0114,  0.0082],\n",
      "        [-0.0281, -0.0266, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6318],\n",
      "        [0.6292],\n",
      "        [0.6409],\n",
      "        [0.6273],\n",
      "        [0.6331],\n",
      "        [0.6307],\n",
      "        [0.6262],\n",
      "        [0.6285]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0266, -0.0114,  0.0081],\n",
      "        [-0.0281, -0.0266, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6272],\n",
      "        [0.6319],\n",
      "        [0.6276],\n",
      "        [0.6254],\n",
      "        [0.6373],\n",
      "        [0.6282],\n",
      "        [0.6259],\n",
      "        [0.6317]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6402],\n",
      "        [0.6351],\n",
      "        [0.6341],\n",
      "        [0.6340],\n",
      "        [0.6412],\n",
      "        [0.6368],\n",
      "        [0.6397],\n",
      "        [0.6381]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0266, -0.0115,  0.0082],\n",
      "        [-0.0282, -0.0266, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6272],\n",
      "        [0.6386],\n",
      "        [0.6389],\n",
      "        [0.6328],\n",
      "        [0.6323],\n",
      "        [0.6351],\n",
      "        [0.6390],\n",
      "        [0.6311]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0115,  0.0082],\n",
      "        [-0.0280, -0.0266, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6287],\n",
      "        [0.6317],\n",
      "        [0.6296],\n",
      "        [0.6341],\n",
      "        [0.6330],\n",
      "        [0.6374],\n",
      "        [0.6314],\n",
      "        [0.6302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0266, -0.0114,  0.0081],\n",
      "        [-0.0279, -0.0266, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6359],\n",
      "        [0.6302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0115,  0.0082],\n",
      "        [-0.0280, -0.0266, -0.0115,  0.0082]], device='cuda:0')\n",
      "after fc out tensor([[0.6290],\n",
      "        [0.6324],\n",
      "        [0.6303],\n",
      "        [0.6330],\n",
      "        [0.6428]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0115,  0.0082],\n",
      "        [-0.0282, -0.0266, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6337],\n",
      "        [0.6392],\n",
      "        [0.6304],\n",
      "        [0.6341],\n",
      "        [0.6305],\n",
      "        [0.6298],\n",
      "        [0.6293],\n",
      "        [0.6302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6337],\n",
      "        [0.6392],\n",
      "        [0.6304],\n",
      "        [0.6341],\n",
      "        [0.6305],\n",
      "        [0.6298],\n",
      "        [0.6293],\n",
      "        [0.6302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.3750, 0.9000, 0.5750, 0.4750, 0.4250, 0.6750, 0.6250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0264, -0.0113,  0.0082],\n",
      "        [-0.0279, -0.0264, -0.0112,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5974],\n",
      "        [0.6021],\n",
      "        [0.6037],\n",
      "        [0.6043],\n",
      "        [0.6049],\n",
      "        [0.6059],\n",
      "        [0.5998],\n",
      "        [0.5975]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0284, -0.0267, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6452],\n",
      "        [0.6468],\n",
      "        [0.6456],\n",
      "        [0.6482],\n",
      "        [0.6455],\n",
      "        [0.6474],\n",
      "        [0.6517],\n",
      "        [0.6469]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0115,  0.0081],\n",
      "        [-0.0283, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6385],\n",
      "        [0.6423],\n",
      "        [0.6385],\n",
      "        [0.6413],\n",
      "        [0.6394],\n",
      "        [0.6382],\n",
      "        [0.6405],\n",
      "        [0.6392]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0115,  0.0082],\n",
      "        [-0.0282, -0.0266, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6307],\n",
      "        [0.6355],\n",
      "        [0.6338],\n",
      "        [0.6306],\n",
      "        [0.6332],\n",
      "        [0.6380],\n",
      "        [0.6326],\n",
      "        [0.6340]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0265, -0.0114,  0.0082],\n",
      "        [-0.0279, -0.0265, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6198],\n",
      "        [0.6191],\n",
      "        [0.6224],\n",
      "        [0.6193],\n",
      "        [0.6254],\n",
      "        [0.6193],\n",
      "        [0.6272],\n",
      "        [0.6191]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0265, -0.0113,  0.0082],\n",
      "        [-0.0280, -0.0265, -0.0113,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6151],\n",
      "        [0.6141]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0116,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.6445],\n",
      "        [0.6454],\n",
      "        [0.6446],\n",
      "        [0.6455],\n",
      "        [0.6510]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0117,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0116,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.6444],\n",
      "        [0.6444],\n",
      "        [0.6466],\n",
      "        [0.6488],\n",
      "        [0.6491],\n",
      "        [0.6449],\n",
      "        [0.6447],\n",
      "        [0.6444]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6444],\n",
      "        [0.6444],\n",
      "        [0.6466],\n",
      "        [0.6488],\n",
      "        [0.6491],\n",
      "        [0.6449],\n",
      "        [0.6447],\n",
      "        [0.6444]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.7500, 0.7000, 0.3750, 0.5750, 0.7000, 0.5750, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0266, -0.0114,  0.0081],\n",
      "        [-0.0279, -0.0266, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6263],\n",
      "        [0.6261],\n",
      "        [0.6272],\n",
      "        [0.6315],\n",
      "        [0.6263],\n",
      "        [0.6283],\n",
      "        [0.6260],\n",
      "        [0.6277]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0115,  0.0081],\n",
      "        [-0.0281, -0.0268, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6508],\n",
      "        [0.6509],\n",
      "        [0.6505],\n",
      "        [0.6502],\n",
      "        [0.6510],\n",
      "        [0.6505],\n",
      "        [0.6505],\n",
      "        [0.6506]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0116,  0.0081],\n",
      "        [-0.0282, -0.0268, -0.0117,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6608],\n",
      "        [0.6607],\n",
      "        [0.6618],\n",
      "        [0.6609],\n",
      "        [0.6636],\n",
      "        [0.6605],\n",
      "        [0.6621],\n",
      "        [0.6612]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0282, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6420],\n",
      "        [0.6457],\n",
      "        [0.6424],\n",
      "        [0.6442],\n",
      "        [0.6440],\n",
      "        [0.6423],\n",
      "        [0.6421],\n",
      "        [0.6425]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0115,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6396],\n",
      "        [0.6392],\n",
      "        [0.6400],\n",
      "        [0.6394],\n",
      "        [0.6395],\n",
      "        [0.6398],\n",
      "        [0.6402],\n",
      "        [0.6386]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0115,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0116,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6380],\n",
      "        [0.6378]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0082]], device='cuda:0')\n",
      "after fc out tensor([[0.6378],\n",
      "        [0.6380],\n",
      "        [0.6375],\n",
      "        [0.6381],\n",
      "        [0.6422]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6386],\n",
      "        [0.6394],\n",
      "        [0.6377],\n",
      "        [0.6376],\n",
      "        [0.6375],\n",
      "        [0.6382],\n",
      "        [0.6387],\n",
      "        [0.6375]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6386],\n",
      "        [0.6394],\n",
      "        [0.6377],\n",
      "        [0.6376],\n",
      "        [0.6375],\n",
      "        [0.6382],\n",
      "        [0.6387],\n",
      "        [0.6375]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.8750, 0.5500, 0.2750, 0.5750, 0.4750, 0.4000, 0.4250, 0.9000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0262, -0.0112,  0.0083],\n",
      "        [-0.0277, -0.0262, -0.0112,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5818],\n",
      "        [0.5818],\n",
      "        [0.5814],\n",
      "        [0.5872],\n",
      "        [0.5844],\n",
      "        [0.5831],\n",
      "        [0.5845],\n",
      "        [0.5813]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0261, -0.0108,  0.0082],\n",
      "        [-0.0276, -0.0261, -0.0109,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5645],\n",
      "        [0.5630],\n",
      "        [0.5709],\n",
      "        [0.5624],\n",
      "        [0.5662],\n",
      "        [0.5618],\n",
      "        [0.5689],\n",
      "        [0.5644]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0264, -0.0112,  0.0082],\n",
      "        [-0.0281, -0.0264, -0.0111,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6014],\n",
      "        [0.6089],\n",
      "        [0.5987],\n",
      "        [0.5986],\n",
      "        [0.5981],\n",
      "        [0.5968],\n",
      "        [0.5996],\n",
      "        [0.6035]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6328],\n",
      "        [0.6315],\n",
      "        [0.6322],\n",
      "        [0.6335],\n",
      "        [0.6315],\n",
      "        [0.6343],\n",
      "        [0.6331],\n",
      "        [0.6316]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0268, -0.0116,  0.0081],\n",
      "        [-0.0282, -0.0268, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6518],\n",
      "        [0.6508],\n",
      "        [0.6535],\n",
      "        [0.6509],\n",
      "        [0.6512],\n",
      "        [0.6505],\n",
      "        [0.6513],\n",
      "        [0.6509]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0269, -0.0117,  0.0081],\n",
      "        [-0.0282, -0.0269, -0.0117,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6665],\n",
      "        [0.6658]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0271, -0.0120,  0.0081],\n",
      "        [-0.0284, -0.0271, -0.0119,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.6976],\n",
      "        [0.6968],\n",
      "        [0.6968],\n",
      "        [0.6966],\n",
      "        [0.6998]], device='cuda:0')\n",
      "Epoch:  15. Loss: 0.0041. mean_squared_error.: 0.06776035577058792\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0271, -0.0117,  0.0079],\n",
      "        [-0.0284, -0.0271, -0.0120,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6974],\n",
      "        [0.6966],\n",
      "        [0.6972],\n",
      "        [0.6971],\n",
      "        [0.6970],\n",
      "        [0.6972],\n",
      "        [0.6965],\n",
      "        [0.6969]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6974],\n",
      "        [0.6966],\n",
      "        [0.6972],\n",
      "        [0.6971],\n",
      "        [0.6970],\n",
      "        [0.6972],\n",
      "        [0.6965],\n",
      "        [0.6969]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.8000, 0.4750, 0.5750, 0.4250, 0.4250, 0.6750, 0.6500, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0283, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6431],\n",
      "        [0.6400],\n",
      "        [0.6397],\n",
      "        [0.6403],\n",
      "        [0.6416],\n",
      "        [0.6391],\n",
      "        [0.6390],\n",
      "        [0.6392]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6323],\n",
      "        [0.6316],\n",
      "        [0.6319],\n",
      "        [0.6319],\n",
      "        [0.6316],\n",
      "        [0.6315],\n",
      "        [0.6317],\n",
      "        [0.6329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6301],\n",
      "        [0.6288],\n",
      "        [0.6291],\n",
      "        [0.6315],\n",
      "        [0.6295],\n",
      "        [0.6288],\n",
      "        [0.6288],\n",
      "        [0.6294]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0115,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0116,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6375],\n",
      "        [0.6377],\n",
      "        [0.6379],\n",
      "        [0.6387],\n",
      "        [0.6379],\n",
      "        [0.6393],\n",
      "        [0.6392],\n",
      "        [0.6387]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0114,  0.0080],\n",
      "        [-0.0283, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6428],\n",
      "        [0.6412],\n",
      "        [0.6410],\n",
      "        [0.6418],\n",
      "        [0.6422],\n",
      "        [0.6415],\n",
      "        [0.6410],\n",
      "        [0.6410]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6392],\n",
      "        [0.6409]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0116,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.6397],\n",
      "        [0.6387],\n",
      "        [0.6388],\n",
      "        [0.6386],\n",
      "        [0.6412]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0113,  0.0080],\n",
      "        [-0.0283, -0.0267, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6404],\n",
      "        [0.6391],\n",
      "        [0.6398],\n",
      "        [0.6396],\n",
      "        [0.6409],\n",
      "        [0.6393],\n",
      "        [0.6388],\n",
      "        [0.6387]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6404],\n",
      "        [0.6391],\n",
      "        [0.6398],\n",
      "        [0.6396],\n",
      "        [0.6409],\n",
      "        [0.6393],\n",
      "        [0.6388],\n",
      "        [0.6387]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.8000, 0.3750, 0.9250, 0.8000, 0.5500, 0.2750, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0266, -0.0114,  0.0082],\n",
      "        [-0.0281, -0.0265, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6170],\n",
      "        [0.6161],\n",
      "        [0.6174],\n",
      "        [0.6161],\n",
      "        [0.6183],\n",
      "        [0.6185],\n",
      "        [0.6167],\n",
      "        [0.6177]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0266, -0.0113,  0.0081],\n",
      "        [-0.0280, -0.0266, -0.0113,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6173],\n",
      "        [0.6170],\n",
      "        [0.6172],\n",
      "        [0.6170],\n",
      "        [0.6172],\n",
      "        [0.6171],\n",
      "        [0.6173],\n",
      "        [0.6170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0116,  0.0081],\n",
      "        [-0.0283, -0.0268, -0.0115,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6485],\n",
      "        [0.6496],\n",
      "        [0.6485],\n",
      "        [0.6479],\n",
      "        [0.6503],\n",
      "        [0.6496],\n",
      "        [0.6477],\n",
      "        [0.6498]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0115,  0.0080],\n",
      "        [-0.0284, -0.0268, -0.0115,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6556],\n",
      "        [0.6572],\n",
      "        [0.6513],\n",
      "        [0.6511],\n",
      "        [0.6511],\n",
      "        [0.6511],\n",
      "        [0.6508],\n",
      "        [0.6506]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0264, -0.0112,  0.0082],\n",
      "        [-0.0280, -0.0265, -0.0111,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5999],\n",
      "        [0.5997],\n",
      "        [0.6012],\n",
      "        [0.6025],\n",
      "        [0.5994],\n",
      "        [0.6032],\n",
      "        [0.5996],\n",
      "        [0.5997]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0114,  0.0082],\n",
      "        [-0.0280, -0.0266, -0.0115,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6234],\n",
      "        [0.6220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0115,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.6303],\n",
      "        [0.6289],\n",
      "        [0.6293],\n",
      "        [0.6287],\n",
      "        [0.6301]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0281, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.6286],\n",
      "        [0.6286],\n",
      "        [0.6287],\n",
      "        [0.6298],\n",
      "        [0.6287],\n",
      "        [0.6287],\n",
      "        [0.6291],\n",
      "        [0.6322]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6286],\n",
      "        [0.6286],\n",
      "        [0.6287],\n",
      "        [0.6298],\n",
      "        [0.6287],\n",
      "        [0.6287],\n",
      "        [0.6291],\n",
      "        [0.6322]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5000, 0.7000, 0.8750, 0.5500, 0.6000, 0.5000, 0.5750, 0.7250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0115,  0.0082],\n",
      "        [-0.0282, -0.0267, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6293],\n",
      "        [0.6285],\n",
      "        [0.6282],\n",
      "        [0.6293],\n",
      "        [0.6307],\n",
      "        [0.6285],\n",
      "        [0.6319],\n",
      "        [0.6283]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0114,  0.0080],\n",
      "        [-0.0281, -0.0268, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6416],\n",
      "        [0.6434],\n",
      "        [0.6411],\n",
      "        [0.6429],\n",
      "        [0.6424],\n",
      "        [0.6421],\n",
      "        [0.6452],\n",
      "        [0.6431]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0115,  0.0081],\n",
      "        [-0.0282, -0.0268, -0.0116,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6439],\n",
      "        [0.6439],\n",
      "        [0.6442],\n",
      "        [0.6477],\n",
      "        [0.6445],\n",
      "        [0.6451],\n",
      "        [0.6441],\n",
      "        [0.6453]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0114,  0.0080],\n",
      "        [-0.0283, -0.0268, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6433],\n",
      "        [0.6430],\n",
      "        [0.6448],\n",
      "        [0.6475],\n",
      "        [0.6466],\n",
      "        [0.6426],\n",
      "        [0.6429],\n",
      "        [0.6430]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0267, -0.0114,  0.0081],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6353],\n",
      "        [0.6368],\n",
      "        [0.6359],\n",
      "        [0.6381],\n",
      "        [0.6402],\n",
      "        [0.6373],\n",
      "        [0.6369],\n",
      "        [0.6367]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0115,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6341],\n",
      "        [0.6344]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0115,  0.0082],\n",
      "        [-0.0281, -0.0267, -0.0115,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.6364],\n",
      "        [0.6344],\n",
      "        [0.6351],\n",
      "        [0.6340],\n",
      "        [0.6342]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0115,  0.0081],\n",
      "        [-0.0282, -0.0267, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6348],\n",
      "        [0.6340],\n",
      "        [0.6352],\n",
      "        [0.6338],\n",
      "        [0.6383],\n",
      "        [0.6362],\n",
      "        [0.6344],\n",
      "        [0.6335]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6348],\n",
      "        [0.6340],\n",
      "        [0.6352],\n",
      "        [0.6338],\n",
      "        [0.6383],\n",
      "        [0.6362],\n",
      "        [0.6344],\n",
      "        [0.6335]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.8500, 0.6250, 0.8750, 0.8000, 0.7500, 0.6750, 0.7000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0273, -0.0120,  0.0080],\n",
      "        [-0.0286, -0.0273, -0.0120,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7123],\n",
      "        [0.7157],\n",
      "        [0.7104],\n",
      "        [0.7184],\n",
      "        [0.7267],\n",
      "        [0.7130],\n",
      "        [0.7102],\n",
      "        [0.7198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0265, -0.0112,  0.0081],\n",
      "        [-0.0281, -0.0265, -0.0112,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6035],\n",
      "        [0.5981],\n",
      "        [0.6209],\n",
      "        [0.6007],\n",
      "        [0.6108],\n",
      "        [0.6105],\n",
      "        [0.6059],\n",
      "        [0.6055]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0276, -0.0262, -0.0110,  0.0083],\n",
      "        [-0.0277, -0.0261, -0.0109,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5610],\n",
      "        [0.5529],\n",
      "        [0.5557],\n",
      "        [0.5659],\n",
      "        [0.5593],\n",
      "        [0.5668],\n",
      "        [0.5563],\n",
      "        [0.5534]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0268, -0.0114,  0.0081],\n",
      "        [-0.0281, -0.0268, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6439],\n",
      "        [0.6208],\n",
      "        [0.6376],\n",
      "        [0.6410],\n",
      "        [0.6098],\n",
      "        [0.6213],\n",
      "        [0.6391],\n",
      "        [0.6505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0265, -0.0112,  0.0082],\n",
      "        [-0.0280, -0.0264, -0.0110,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5940],\n",
      "        [0.5872],\n",
      "        [0.5842],\n",
      "        [0.5949],\n",
      "        [0.5913],\n",
      "        [0.6014],\n",
      "        [0.5843],\n",
      "        [0.5947]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0115,  0.0081],\n",
      "        [-0.0282, -0.0268, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6388],\n",
      "        [0.6312]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0263, -0.0110,  0.0082],\n",
      "        [-0.0277, -0.0263, -0.0110,  0.0082]], device='cuda:0')\n",
      "after fc out tensor([[0.5774],\n",
      "        [0.5686],\n",
      "        [0.5727],\n",
      "        [0.5668],\n",
      "        [0.5541]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0262, -0.0109,  0.0082],\n",
      "        [-0.0277, -0.0264, -0.0110,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5574],\n",
      "        [0.5834],\n",
      "        [0.5576],\n",
      "        [0.5683],\n",
      "        [0.5673],\n",
      "        [0.5624],\n",
      "        [0.5757],\n",
      "        [0.5780]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5574],\n",
      "        [0.5834],\n",
      "        [0.5576],\n",
      "        [0.5683],\n",
      "        [0.5673],\n",
      "        [0.5624],\n",
      "        [0.5757],\n",
      "        [0.5780]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.6750, 0.3750, 0.8000, 0.6750, 0.6750, 0.5750, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0264, -0.0111,  0.0082],\n",
      "        [-0.0279, -0.0263, -0.0110,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5831],\n",
      "        [0.5729],\n",
      "        [0.5728],\n",
      "        [0.5839],\n",
      "        [0.5737],\n",
      "        [0.5718],\n",
      "        [0.5838],\n",
      "        [0.5756]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0112,  0.0081],\n",
      "        [-0.0279, -0.0266, -0.0113,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5936],\n",
      "        [0.6112],\n",
      "        [0.5896],\n",
      "        [0.5925],\n",
      "        [0.5952],\n",
      "        [0.5996],\n",
      "        [0.6048],\n",
      "        [0.6025]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0113,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6145],\n",
      "        [0.6266],\n",
      "        [0.6263],\n",
      "        [0.6093],\n",
      "        [0.6141],\n",
      "        [0.6221],\n",
      "        [0.6108],\n",
      "        [0.6249]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0266, -0.0113,  0.0081],\n",
      "        [-0.0280, -0.0266, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6027],\n",
      "        [0.6089],\n",
      "        [0.6023],\n",
      "        [0.6097],\n",
      "        [0.6171],\n",
      "        [0.6051],\n",
      "        [0.6026],\n",
      "        [0.6082]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0113,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6120],\n",
      "        [0.6158],\n",
      "        [0.6058],\n",
      "        [0.6158],\n",
      "        [0.6114],\n",
      "        [0.5977],\n",
      "        [0.5999],\n",
      "        [0.6057]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0266, -0.0112,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6128],\n",
      "        [0.6198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0113,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0113,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.6160],\n",
      "        [0.6087],\n",
      "        [0.6120],\n",
      "        [0.6073],\n",
      "        [0.5976]], device='cuda:0')\n",
      "Epoch:  20. Loss: 0.0251. mean_squared_error.: 0.04784006252884865\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0113,  0.0081],\n",
      "        [-0.0282, -0.0266, -0.0111,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6146],\n",
      "        [0.6116],\n",
      "        [0.6038],\n",
      "        [0.6211],\n",
      "        [0.6086],\n",
      "        [0.6074],\n",
      "        [0.6115],\n",
      "        [0.6091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6146],\n",
      "        [0.6116],\n",
      "        [0.6038],\n",
      "        [0.6211],\n",
      "        [0.6086],\n",
      "        [0.6074],\n",
      "        [0.6115],\n",
      "        [0.6091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.9250, 0.6750, 0.6750, 0.8000, 0.8500, 0.6750, 0.9000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0275, -0.0120,  0.0079],\n",
      "        [-0.0288, -0.0275, -0.0120,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7429],\n",
      "        [0.7230],\n",
      "        [0.7250],\n",
      "        [0.7305],\n",
      "        [0.7310],\n",
      "        [0.7187],\n",
      "        [0.7087],\n",
      "        [0.7349]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0271, -0.0117,  0.0079],\n",
      "        [-0.0284, -0.0273, -0.0119,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6693],\n",
      "        [0.6939],\n",
      "        [0.6808],\n",
      "        [0.6625],\n",
      "        [0.6800],\n",
      "        [0.6756],\n",
      "        [0.6850],\n",
      "        [0.6676]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0270, -0.0115,  0.0080],\n",
      "        [-0.0283, -0.0271, -0.0116,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6490],\n",
      "        [0.6661],\n",
      "        [0.6595],\n",
      "        [0.6371],\n",
      "        [0.6639],\n",
      "        [0.6476],\n",
      "        [0.6480],\n",
      "        [0.6481]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0266, -0.0112,  0.0081],\n",
      "        [-0.0280, -0.0266, -0.0111,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6047],\n",
      "        [0.5903],\n",
      "        [0.5997],\n",
      "        [0.5969],\n",
      "        [0.5962],\n",
      "        [0.5851],\n",
      "        [0.6013],\n",
      "        [0.5951]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0262, -0.0107,  0.0082],\n",
      "        [-0.0276, -0.0262, -0.0109,  0.0083]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5471],\n",
      "        [0.5507],\n",
      "        [0.5513],\n",
      "        [0.5537],\n",
      "        [0.5485],\n",
      "        [0.5483],\n",
      "        [0.5484],\n",
      "        [0.5480]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0263, -0.0109,  0.0082],\n",
      "        [-0.0278, -0.0263, -0.0109,  0.0082]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.5563],\n",
      "        [0.5589]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0115,  0.0081],\n",
      "        [-0.0282, -0.0269, -0.0114,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.6291],\n",
      "        [0.6253],\n",
      "        [0.6269],\n",
      "        [0.6245],\n",
      "        [0.6200]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0114,  0.0081],\n",
      "        [-0.0283, -0.0269, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6280],\n",
      "        [0.6234],\n",
      "        [0.6270],\n",
      "        [0.6210],\n",
      "        [0.6238],\n",
      "        [0.6276],\n",
      "        [0.6327],\n",
      "        [0.6212]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6280],\n",
      "        [0.6234],\n",
      "        [0.6270],\n",
      "        [0.6210],\n",
      "        [0.6238],\n",
      "        [0.6276],\n",
      "        [0.6327],\n",
      "        [0.6212]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5500, 0.5000, 0.9250, 0.3750, 0.5750, 0.5000, 0.7000, 0.7750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0113,  0.0080],\n",
      "        [-0.0283, -0.0268, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6192],\n",
      "        [0.6165],\n",
      "        [0.6187],\n",
      "        [0.6172],\n",
      "        [0.6180],\n",
      "        [0.6226],\n",
      "        [0.6232],\n",
      "        [0.6201]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0112,  0.0081],\n",
      "        [-0.0281, -0.0267, -0.0112,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6052],\n",
      "        [0.6017],\n",
      "        [0.6080],\n",
      "        [0.6015],\n",
      "        [0.6051],\n",
      "        [0.6030],\n",
      "        [0.6010],\n",
      "        [0.6064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0114,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6314],\n",
      "        [0.6184],\n",
      "        [0.6269],\n",
      "        [0.6293],\n",
      "        [0.6172],\n",
      "        [0.6189],\n",
      "        [0.6196],\n",
      "        [0.6162]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0114,  0.0080],\n",
      "        [-0.0281, -0.0270, -0.0115,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6248],\n",
      "        [0.6325],\n",
      "        [0.6202],\n",
      "        [0.6182],\n",
      "        [0.6245],\n",
      "        [0.6281],\n",
      "        [0.6306],\n",
      "        [0.6248]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0269, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6173],\n",
      "        [0.6306],\n",
      "        [0.6170],\n",
      "        [0.6187],\n",
      "        [0.6230],\n",
      "        [0.6300],\n",
      "        [0.6108],\n",
      "        [0.6223]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0269, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6226],\n",
      "        [0.6249]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0114,  0.0081],\n",
      "        [-0.0282, -0.0269, -0.0114,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.6276],\n",
      "        [0.6217],\n",
      "        [0.6244],\n",
      "        [0.6204],\n",
      "        [0.6122]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0113,  0.0080],\n",
      "        [-0.0283, -0.0268, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6143],\n",
      "        [0.6143],\n",
      "        [0.6180],\n",
      "        [0.6272],\n",
      "        [0.6314],\n",
      "        [0.6217],\n",
      "        [0.6196],\n",
      "        [0.6296]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6143],\n",
      "        [0.6143],\n",
      "        [0.6180],\n",
      "        [0.6272],\n",
      "        [0.6314],\n",
      "        [0.6217],\n",
      "        [0.6196],\n",
      "        [0.6296]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.3750, 0.7250, 0.7500, 0.8000, 0.6750, 0.6500, 0.4000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0269, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6233],\n",
      "        [0.6212],\n",
      "        [0.6116],\n",
      "        [0.6228],\n",
      "        [0.6209],\n",
      "        [0.6232],\n",
      "        [0.6192],\n",
      "        [0.6212]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0267, -0.0113,  0.0081],\n",
      "        [-0.0279, -0.0267, -0.0112,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6000],\n",
      "        [0.5995],\n",
      "        [0.5923],\n",
      "        [0.5946],\n",
      "        [0.5931],\n",
      "        [0.5984],\n",
      "        [0.5917],\n",
      "        [0.5993]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0275, -0.0118,  0.0079],\n",
      "        [-0.0286, -0.0273, -0.0117,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7114],\n",
      "        [0.6814],\n",
      "        [0.6905],\n",
      "        [0.6774],\n",
      "        [0.6634],\n",
      "        [0.6921],\n",
      "        [0.6711],\n",
      "        [0.6899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0273, -0.0117,  0.0079],\n",
      "        [-0.0285, -0.0273, -0.0117,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6588],\n",
      "        [0.6615],\n",
      "        [0.6725],\n",
      "        [0.6847],\n",
      "        [0.6821],\n",
      "        [0.6519],\n",
      "        [0.6766],\n",
      "        [0.6800]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0268, -0.0113,  0.0081],\n",
      "        [-0.0281, -0.0268, -0.0112,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6010],\n",
      "        [0.6001],\n",
      "        [0.5995],\n",
      "        [0.6020],\n",
      "        [0.6111],\n",
      "        [0.5978],\n",
      "        [0.6003],\n",
      "        [0.6096]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0112,  0.0080],\n",
      "        [-0.0281, -0.0268, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6031],\n",
      "        [0.6069]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0267, -0.0111,  0.0081],\n",
      "        [-0.0279, -0.0266, -0.0111,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.5928],\n",
      "        [0.5836],\n",
      "        [0.5879],\n",
      "        [0.5817],\n",
      "        [0.5678]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0265, -0.0110,  0.0081],\n",
      "        [-0.0279, -0.0267, -0.0112,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5955],\n",
      "        [0.5990],\n",
      "        [0.5875],\n",
      "        [0.5804],\n",
      "        [0.5818],\n",
      "        [0.5874],\n",
      "        [0.5885],\n",
      "        [0.5896]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5955],\n",
      "        [0.5990],\n",
      "        [0.5875],\n",
      "        [0.5804],\n",
      "        [0.5818],\n",
      "        [0.5874],\n",
      "        [0.5885],\n",
      "        [0.5896]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.6750, 0.9000, 0.6500, 0.8500, 0.4750, 0.6250, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0268, -0.0113,  0.0081],\n",
      "        [-0.0281, -0.0268, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6075],\n",
      "        [0.6076],\n",
      "        [0.5960],\n",
      "        [0.5945],\n",
      "        [0.5985],\n",
      "        [0.6020],\n",
      "        [0.6190],\n",
      "        [0.6078]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0112,  0.0080],\n",
      "        [-0.0281, -0.0270, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6014],\n",
      "        [0.6278],\n",
      "        [0.6338],\n",
      "        [0.6201],\n",
      "        [0.6132],\n",
      "        [0.6012],\n",
      "        [0.6261],\n",
      "        [0.6078]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0114,  0.0080],\n",
      "        [-0.0281, -0.0270, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6335],\n",
      "        [0.6212],\n",
      "        [0.6087],\n",
      "        [0.6314],\n",
      "        [0.6148],\n",
      "        [0.6143],\n",
      "        [0.6097],\n",
      "        [0.6099]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0268, -0.0113,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6144],\n",
      "        [0.6148],\n",
      "        [0.6070],\n",
      "        [0.6301],\n",
      "        [0.6129],\n",
      "        [0.6020],\n",
      "        [0.6278],\n",
      "        [0.6288]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0114,  0.0081],\n",
      "        [-0.0281, -0.0269, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6244],\n",
      "        [0.6118],\n",
      "        [0.6112],\n",
      "        [0.6153],\n",
      "        [0.6012],\n",
      "        [0.6243],\n",
      "        [0.6298],\n",
      "        [0.6348]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0114,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6164],\n",
      "        [0.6213]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0114,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0113,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.6268],\n",
      "        [0.6160],\n",
      "        [0.6211],\n",
      "        [0.6139],\n",
      "        [0.5973]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0114,  0.0080],\n",
      "        [-0.0281, -0.0270, -0.0114,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6356],\n",
      "        [0.6232],\n",
      "        [0.6206],\n",
      "        [0.6157],\n",
      "        [0.6115],\n",
      "        [0.6202],\n",
      "        [0.6122],\n",
      "        [0.6261]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6356],\n",
      "        [0.6232],\n",
      "        [0.6206],\n",
      "        [0.6157],\n",
      "        [0.6115],\n",
      "        [0.6202],\n",
      "        [0.6122],\n",
      "        [0.6261]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7000, 0.4250, 0.4750, 0.8000, 0.5750, 0.9250, 0.6500, 0.7500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0272, -0.0116,  0.0080],\n",
      "        [-0.0284, -0.0272, -0.0116,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6634],\n",
      "        [0.6432],\n",
      "        [0.6337],\n",
      "        [0.6322],\n",
      "        [0.6435],\n",
      "        [0.6660],\n",
      "        [0.6451],\n",
      "        [0.6463]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0271, -0.0115,  0.0080],\n",
      "        [-0.0282, -0.0270, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6450],\n",
      "        [0.6477],\n",
      "        [0.6349],\n",
      "        [0.6278],\n",
      "        [0.6205],\n",
      "        [0.6233],\n",
      "        [0.6484],\n",
      "        [0.6124]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0271, -0.0115,  0.0080],\n",
      "        [-0.0282, -0.0271, -0.0115,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6491],\n",
      "        [0.6508],\n",
      "        [0.6359],\n",
      "        [0.6406],\n",
      "        [0.6185],\n",
      "        [0.6407],\n",
      "        [0.6363],\n",
      "        [0.6459]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0267, -0.0111,  0.0080],\n",
      "        [-0.0281, -0.0267, -0.0111,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5888],\n",
      "        [0.5948],\n",
      "        [0.5984],\n",
      "        [0.5988],\n",
      "        [0.5941],\n",
      "        [0.5932],\n",
      "        [0.5968],\n",
      "        [0.5957]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0111,  0.0080],\n",
      "        [-0.0280, -0.0267, -0.0111,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5863],\n",
      "        [0.5907],\n",
      "        [0.5867],\n",
      "        [0.5954],\n",
      "        [0.5943],\n",
      "        [0.5926],\n",
      "        [0.5898],\n",
      "        [0.5938]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0271, -0.0114,  0.0079],\n",
      "        [-0.0283, -0.0272, -0.0116,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6390],\n",
      "        [0.6475]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0112,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0111,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.5939],\n",
      "        [0.5892],\n",
      "        [0.5913],\n",
      "        [0.5882],\n",
      "        [0.5818]], device='cuda:0')\n",
      "Epoch:  25. Loss: 0.0126. mean_squared_error.: 0.045448921620845795\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0267, -0.0112,  0.0081],\n",
      "        [-0.0280, -0.0267, -0.0112,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5959],\n",
      "        [0.5955],\n",
      "        [0.5892],\n",
      "        [0.5935],\n",
      "        [0.5929],\n",
      "        [0.5834],\n",
      "        [0.5930],\n",
      "        [0.5875]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5959],\n",
      "        [0.5955],\n",
      "        [0.5892],\n",
      "        [0.5935],\n",
      "        [0.5929],\n",
      "        [0.5834],\n",
      "        [0.5930],\n",
      "        [0.5875]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6000, 0.4000, 0.6750, 0.7500, 0.6750, 0.3750, 0.9500, 0.6500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0112,  0.0080],\n",
      "        [-0.0281, -0.0269, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6009],\n",
      "        [0.6089],\n",
      "        [0.6141],\n",
      "        [0.6078],\n",
      "        [0.6019],\n",
      "        [0.6142],\n",
      "        [0.6027],\n",
      "        [0.6014]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0112,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6034],\n",
      "        [0.6093],\n",
      "        [0.6043],\n",
      "        [0.6128],\n",
      "        [0.6126],\n",
      "        [0.6076],\n",
      "        [0.6126],\n",
      "        [0.6034]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0271, -0.0115,  0.0080],\n",
      "        [-0.0282, -0.0271, -0.0115,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6323],\n",
      "        [0.6364],\n",
      "        [0.6252],\n",
      "        [0.6298],\n",
      "        [0.6343],\n",
      "        [0.6224],\n",
      "        [0.6311],\n",
      "        [0.6274]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0269, -0.0113,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6103],\n",
      "        [0.6119],\n",
      "        [0.6090],\n",
      "        [0.6159],\n",
      "        [0.6090],\n",
      "        [0.6094],\n",
      "        [0.6077],\n",
      "        [0.6070]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0113,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6122],\n",
      "        [0.6107],\n",
      "        [0.6141],\n",
      "        [0.6108],\n",
      "        [0.6181],\n",
      "        [0.6157],\n",
      "        [0.6106],\n",
      "        [0.6107]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0270, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6151],\n",
      "        [0.6150]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0114,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0113,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.6187],\n",
      "        [0.6151],\n",
      "        [0.6166],\n",
      "        [0.6143],\n",
      "        [0.6100]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0114,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6164],\n",
      "        [0.6212],\n",
      "        [0.6179],\n",
      "        [0.6138],\n",
      "        [0.6173],\n",
      "        [0.6110],\n",
      "        [0.6126],\n",
      "        [0.6134]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6164],\n",
      "        [0.6212],\n",
      "        [0.6179],\n",
      "        [0.6138],\n",
      "        [0.6173],\n",
      "        [0.6110],\n",
      "        [0.6126],\n",
      "        [0.6134]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.4750, 0.7000, 0.5750, 0.4250, 0.4250, 0.5750, 0.6750, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0264, -0.0108,  0.0081],\n",
      "        [-0.0280, -0.0264, -0.0108,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5577],\n",
      "        [0.5622],\n",
      "        [0.5629],\n",
      "        [0.5610],\n",
      "        [0.5598],\n",
      "        [0.5594],\n",
      "        [0.5618],\n",
      "        [0.5607]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0267, -0.0111,  0.0081],\n",
      "        [-0.0279, -0.0267, -0.0111,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5838],\n",
      "        [0.5813],\n",
      "        [0.5827],\n",
      "        [0.5801],\n",
      "        [0.5815],\n",
      "        [0.5844],\n",
      "        [0.5849],\n",
      "        [0.5817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0274, -0.0117,  0.0079],\n",
      "        [-0.0287, -0.0273, -0.0116,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6778],\n",
      "        [0.6764],\n",
      "        [0.6894],\n",
      "        [0.6912],\n",
      "        [0.6699],\n",
      "        [0.6870],\n",
      "        [0.6509],\n",
      "        [0.6689]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0274, -0.0117,  0.0079],\n",
      "        [-0.0286, -0.0272, -0.0115,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6865],\n",
      "        [0.6455],\n",
      "        [0.6588],\n",
      "        [0.6767],\n",
      "        [0.6795],\n",
      "        [0.6676],\n",
      "        [0.6508],\n",
      "        [0.6438]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0268, -0.0112,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0112,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6053],\n",
      "        [0.6025],\n",
      "        [0.5996],\n",
      "        [0.6031],\n",
      "        [0.6234],\n",
      "        [0.6207],\n",
      "        [0.6103],\n",
      "        [0.6148]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0273, -0.0115,  0.0079],\n",
      "        [-0.0284, -0.0273, -0.0115,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6385],\n",
      "        [0.6402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0271, -0.0114,  0.0080],\n",
      "        [-0.0282, -0.0271, -0.0113,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.6299],\n",
      "        [0.6169],\n",
      "        [0.6231],\n",
      "        [0.6142],\n",
      "        [0.5932]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0270, -0.0113,  0.0080],\n",
      "        [-0.0282, -0.0270, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6059],\n",
      "        [0.6273],\n",
      "        [0.6220],\n",
      "        [0.6339],\n",
      "        [0.6113],\n",
      "        [0.6137],\n",
      "        [0.6215],\n",
      "        [0.6335]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6059],\n",
      "        [0.6273],\n",
      "        [0.6220],\n",
      "        [0.6339],\n",
      "        [0.6113],\n",
      "        [0.6137],\n",
      "        [0.6215],\n",
      "        [0.6335]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5500, 0.9500, 0.6750, 0.4000, 0.5750, 0.5000, 0.5750, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0113,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0112,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6133],\n",
      "        [0.6018],\n",
      "        [0.5993],\n",
      "        [0.6211],\n",
      "        [0.6281],\n",
      "        [0.6135],\n",
      "        [0.6030],\n",
      "        [0.6249]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0112,  0.0080],\n",
      "        [-0.0282, -0.0268, -0.0112,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6166],\n",
      "        [0.6014],\n",
      "        [0.6135],\n",
      "        [0.6167],\n",
      "        [0.5863],\n",
      "        [0.5984],\n",
      "        [0.6057],\n",
      "        [0.6054]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0113,  0.0080],\n",
      "        [-0.0282, -0.0268, -0.0112,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6233],\n",
      "        [0.5905],\n",
      "        [0.6128],\n",
      "        [0.6145],\n",
      "        [0.6015],\n",
      "        [0.6095],\n",
      "        [0.6039],\n",
      "        [0.6254]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0112,  0.0080],\n",
      "        [-0.0282, -0.0268, -0.0111,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6162],\n",
      "        [0.5854],\n",
      "        [0.6178],\n",
      "        [0.5947],\n",
      "        [0.5853],\n",
      "        [0.5941],\n",
      "        [0.6037],\n",
      "        [0.5959]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0113,  0.0080],\n",
      "        [-0.0283, -0.0268, -0.0111,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6130],\n",
      "        [0.6096],\n",
      "        [0.6037],\n",
      "        [0.6139],\n",
      "        [0.6111],\n",
      "        [0.5984],\n",
      "        [0.5932],\n",
      "        [0.6061]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0112,  0.0080],\n",
      "        [-0.0282, -0.0270, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6111],\n",
      "        [0.6060]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0270, -0.0113,  0.0080],\n",
      "        [-0.0282, -0.0270, -0.0113,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.6212],\n",
      "        [0.6109],\n",
      "        [0.6157],\n",
      "        [0.6088],\n",
      "        [0.5925]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0269, -0.0112,  0.0080],\n",
      "        [-0.0282, -0.0270, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6109],\n",
      "        [0.6183],\n",
      "        [0.6294],\n",
      "        [0.6064],\n",
      "        [0.6164],\n",
      "        [0.5969],\n",
      "        [0.6062],\n",
      "        [0.6149]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6109],\n",
      "        [0.6183],\n",
      "        [0.6294],\n",
      "        [0.6064],\n",
      "        [0.6164],\n",
      "        [0.5969],\n",
      "        [0.6062],\n",
      "        [0.6149]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.5500, 0.7000, 0.6000, 0.6250, 0.5750, 0.8750, 0.9250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0275, -0.0117,  0.0079],\n",
      "        [-0.0287, -0.0274, -0.0116,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6823],\n",
      "        [0.6644],\n",
      "        [0.6965],\n",
      "        [0.6850],\n",
      "        [0.6762],\n",
      "        [0.6783],\n",
      "        [0.6822],\n",
      "        [0.6590]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0269, -0.0112,  0.0079],\n",
      "        [-0.0282, -0.0271, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6010],\n",
      "        [0.6160],\n",
      "        [0.6070],\n",
      "        [0.6127],\n",
      "        [0.6224],\n",
      "        [0.6272],\n",
      "        [0.6286],\n",
      "        [0.6082]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0271, -0.0113,  0.0080],\n",
      "        [-0.0282, -0.0271, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6232],\n",
      "        [0.6162],\n",
      "        [0.6028],\n",
      "        [0.6075],\n",
      "        [0.6097],\n",
      "        [0.6238],\n",
      "        [0.6091],\n",
      "        [0.6089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0271, -0.0113,  0.0080],\n",
      "        [-0.0283, -0.0271, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6173],\n",
      "        [0.6262],\n",
      "        [0.6147],\n",
      "        [0.6170],\n",
      "        [0.6183],\n",
      "        [0.6172],\n",
      "        [0.6253],\n",
      "        [0.6288]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0273, -0.0115,  0.0079],\n",
      "        [-0.0284, -0.0273, -0.0115,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6505],\n",
      "        [0.6513],\n",
      "        [0.6430],\n",
      "        [0.6472],\n",
      "        [0.6564],\n",
      "        [0.6389],\n",
      "        [0.6493],\n",
      "        [0.6504]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0270, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0270, -0.0113,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6073],\n",
      "        [0.6090]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0267, -0.0111,  0.0081],\n",
      "        [-0.0279, -0.0267, -0.0110,  0.0081]], device='cuda:0')\n",
      "after fc out tensor([[0.5763],\n",
      "        [0.5735],\n",
      "        [0.5746],\n",
      "        [0.5728],\n",
      "        [0.5697]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0267, -0.0109,  0.0080],\n",
      "        [-0.0279, -0.0267, -0.0111,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5726],\n",
      "        [0.5775],\n",
      "        [0.5774],\n",
      "        [0.5733],\n",
      "        [0.5703],\n",
      "        [0.5758],\n",
      "        [0.5729],\n",
      "        [0.5744]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5726],\n",
      "        [0.5775],\n",
      "        [0.5774],\n",
      "        [0.5733],\n",
      "        [0.5703],\n",
      "        [0.5758],\n",
      "        [0.5729],\n",
      "        [0.5744]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.4250, 0.6000, 0.5750, 0.6750, 0.3750, 0.9500, 0.5000, 0.4750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0267, -0.0110,  0.0080],\n",
      "        [-0.0280, -0.0267, -0.0110,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5716],\n",
      "        [0.5727],\n",
      "        [0.5763],\n",
      "        [0.5708],\n",
      "        [0.5699],\n",
      "        [0.5740],\n",
      "        [0.5770],\n",
      "        [0.5704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0271, -0.0113,  0.0080],\n",
      "        [-0.0281, -0.0271, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6122],\n",
      "        [0.6128],\n",
      "        [0.6110],\n",
      "        [0.6136],\n",
      "        [0.6121],\n",
      "        [0.6135],\n",
      "        [0.6133],\n",
      "        [0.6152]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0271, -0.0114,  0.0080],\n",
      "        [-0.0284, -0.0271, -0.0112,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6229],\n",
      "        [0.6160],\n",
      "        [0.6178],\n",
      "        [0.6168],\n",
      "        [0.6167],\n",
      "        [0.6235],\n",
      "        [0.6232],\n",
      "        [0.6174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0271, -0.0113,  0.0079],\n",
      "        [-0.0284, -0.0272, -0.0113,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6265],\n",
      "        [0.6279],\n",
      "        [0.6263],\n",
      "        [0.6264],\n",
      "        [0.6297],\n",
      "        [0.6290],\n",
      "        [0.6291],\n",
      "        [0.6267]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0271, -0.0113,  0.0079],\n",
      "        [-0.0283, -0.0272, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6235],\n",
      "        [0.6265],\n",
      "        [0.6253],\n",
      "        [0.6256],\n",
      "        [0.6242],\n",
      "        [0.6217],\n",
      "        [0.6235],\n",
      "        [0.6257]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0271, -0.0112,  0.0079],\n",
      "        [-0.0282, -0.0272, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6207],\n",
      "        [0.6224]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0272, -0.0114,  0.0080],\n",
      "        [-0.0283, -0.0272, -0.0114,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.6255],\n",
      "        [0.6227],\n",
      "        [0.6237],\n",
      "        [0.6219],\n",
      "        [0.6192]], device='cuda:0')\n",
      "Epoch:  30. Loss: 0.0174. mean_squared_error.: 0.04980788379907608\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0272, -0.0114,  0.0080],\n",
      "        [-0.0283, -0.0272, -0.0114,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6242],\n",
      "        [0.6234],\n",
      "        [0.6220],\n",
      "        [0.6208],\n",
      "        [0.6215],\n",
      "        [0.6235],\n",
      "        [0.6213],\n",
      "        [0.6194]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6242],\n",
      "        [0.6234],\n",
      "        [0.6220],\n",
      "        [0.6208],\n",
      "        [0.6215],\n",
      "        [0.6235],\n",
      "        [0.6213],\n",
      "        [0.6194]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5000, 0.5750, 0.8500, 0.6750, 0.5750, 0.4750, 0.7250, 0.2750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0280, -0.0269, -0.0112,  0.0080],\n",
      "        [-0.0282, -0.0268, -0.0110,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5921],\n",
      "        [0.5904],\n",
      "        [0.5964],\n",
      "        [0.5941],\n",
      "        [0.5879],\n",
      "        [0.5834],\n",
      "        [0.5863],\n",
      "        [0.5900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0272, -0.0114,  0.0078],\n",
      "        [-0.0285, -0.0273, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6414],\n",
      "        [0.6415],\n",
      "        [0.6332],\n",
      "        [0.6505],\n",
      "        [0.6438],\n",
      "        [0.6460],\n",
      "        [0.6379],\n",
      "        [0.6466]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0278, -0.0119,  0.0077],\n",
      "        [-0.0288, -0.0280, -0.0121,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7298],\n",
      "        [0.7323],\n",
      "        [0.7078],\n",
      "        [0.7147],\n",
      "        [0.7148],\n",
      "        [0.7264],\n",
      "        [0.7153],\n",
      "        [0.7125]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0275, -0.0116,  0.0078],\n",
      "        [-0.0286, -0.0275, -0.0116,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6594],\n",
      "        [0.6748],\n",
      "        [0.6683],\n",
      "        [0.6619],\n",
      "        [0.6637],\n",
      "        [0.6664],\n",
      "        [0.6709],\n",
      "        [0.6628]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0266, -0.0108,  0.0080],\n",
      "        [-0.0278, -0.0266, -0.0109,  0.0081]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5549],\n",
      "        [0.5549],\n",
      "        [0.5550],\n",
      "        [0.5547],\n",
      "        [0.5544],\n",
      "        [0.5565],\n",
      "        [0.5541],\n",
      "        [0.5567]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0270, -0.0111,  0.0079],\n",
      "        [-0.0283, -0.0269, -0.0110,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5898],\n",
      "        [0.5875]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0111,  0.0080],\n",
      "        [-0.0281, -0.0269, -0.0111,  0.0080]], device='cuda:0')\n",
      "after fc out tensor([[0.5917],\n",
      "        [0.5860],\n",
      "        [0.5885],\n",
      "        [0.5846],\n",
      "        [0.5764]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0269, -0.0111,  0.0080],\n",
      "        [-0.0281, -0.0270, -0.0111,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5889],\n",
      "        [0.5912],\n",
      "        [0.5853],\n",
      "        [0.5968],\n",
      "        [0.5938],\n",
      "        [0.5896],\n",
      "        [0.5834],\n",
      "        [0.5837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5889],\n",
      "        [0.5912],\n",
      "        [0.5853],\n",
      "        [0.5968],\n",
      "        [0.5938],\n",
      "        [0.5896],\n",
      "        [0.5834],\n",
      "        [0.5837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6250, 0.7500, 0.6750, 0.7000, 0.5750, 0.4250, 0.6000, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0281, -0.0270, -0.0111,  0.0080],\n",
      "        [-0.0281, -0.0269, -0.0111,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5932],\n",
      "        [0.5847],\n",
      "        [0.5969],\n",
      "        [0.5863],\n",
      "        [0.5798],\n",
      "        [0.5951],\n",
      "        [0.5917],\n",
      "        [0.5944]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0270, -0.0111,  0.0079],\n",
      "        [-0.0282, -0.0270, -0.0111,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5944],\n",
      "        [0.6006],\n",
      "        [0.6040],\n",
      "        [0.5923],\n",
      "        [0.5936],\n",
      "        [0.5976],\n",
      "        [0.5886],\n",
      "        [0.5960]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0273, -0.0114,  0.0079],\n",
      "        [-0.0285, -0.0271, -0.0112,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6291],\n",
      "        [0.6139],\n",
      "        [0.6219],\n",
      "        [0.6239],\n",
      "        [0.6197],\n",
      "        [0.6171],\n",
      "        [0.6183],\n",
      "        [0.6228]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0273, -0.0113,  0.0079],\n",
      "        [-0.0284, -0.0274, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6257],\n",
      "        [0.6309],\n",
      "        [0.6265],\n",
      "        [0.6393],\n",
      "        [0.6260],\n",
      "        [0.6290],\n",
      "        [0.6246],\n",
      "        [0.6257]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0273, -0.0114,  0.0079],\n",
      "        [-0.0284, -0.0273, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6242],\n",
      "        [0.6344],\n",
      "        [0.6270],\n",
      "        [0.6267],\n",
      "        [0.6271],\n",
      "        [0.6343],\n",
      "        [0.6204],\n",
      "        [0.6177]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0272, -0.0113,  0.0079],\n",
      "        [-0.0283, -0.0273, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6171],\n",
      "        [0.6286]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0273, -0.0114,  0.0079],\n",
      "        [-0.0283, -0.0273, -0.0114,  0.0079]], device='cuda:0')\n",
      "after fc out tensor([[0.6281],\n",
      "        [0.6224],\n",
      "        [0.6248],\n",
      "        [0.6210],\n",
      "        [0.6132]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0272, -0.0113,  0.0079],\n",
      "        [-0.0284, -0.0272, -0.0113,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6182],\n",
      "        [0.6195],\n",
      "        [0.6275],\n",
      "        [0.6225],\n",
      "        [0.6201],\n",
      "        [0.6210],\n",
      "        [0.6283],\n",
      "        [0.6164]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6182],\n",
      "        [0.6195],\n",
      "        [0.6275],\n",
      "        [0.6225],\n",
      "        [0.6201],\n",
      "        [0.6210],\n",
      "        [0.6283],\n",
      "        [0.6164]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7000, 0.5000, 0.7500, 0.8000, 0.6500, 0.5000, 0.4250, 0.6500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0272, -0.0113,  0.0079],\n",
      "        [-0.0283, -0.0273, -0.0113,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6184],\n",
      "        [0.6246],\n",
      "        [0.6242],\n",
      "        [0.6322],\n",
      "        [0.6220],\n",
      "        [0.6258],\n",
      "        [0.6196],\n",
      "        [0.6161]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0268, -0.0110,  0.0080],\n",
      "        [-0.0280, -0.0268, -0.0110,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5726],\n",
      "        [0.5754],\n",
      "        [0.5712],\n",
      "        [0.5626],\n",
      "        [0.5767],\n",
      "        [0.5756],\n",
      "        [0.5683],\n",
      "        [0.5673]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0281, -0.0269, -0.0111,  0.0080],\n",
      "        [-0.0282, -0.0269, -0.0110,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5900],\n",
      "        [0.5856],\n",
      "        [0.5835],\n",
      "        [0.5879],\n",
      "        [0.5849],\n",
      "        [0.5889],\n",
      "        [0.5937],\n",
      "        [0.5868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0273, -0.0114,  0.0079],\n",
      "        [-0.0283, -0.0273, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6244],\n",
      "        [0.6260],\n",
      "        [0.6274],\n",
      "        [0.6277],\n",
      "        [0.6161],\n",
      "        [0.6250],\n",
      "        [0.6315],\n",
      "        [0.6245]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0276, -0.0116,  0.0078],\n",
      "        [-0.0287, -0.0276, -0.0116,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6603],\n",
      "        [0.6697],\n",
      "        [0.6684],\n",
      "        [0.6706],\n",
      "        [0.6951],\n",
      "        [0.6766],\n",
      "        [0.6709],\n",
      "        [0.6714]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0275, -0.0115,  0.0078],\n",
      "        [-0.0286, -0.0276, -0.0116,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6432],\n",
      "        [0.6796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0275, -0.0115,  0.0079],\n",
      "        [-0.0285, -0.0275, -0.0115,  0.0078]], device='cuda:0')\n",
      "after fc out tensor([[0.6519],\n",
      "        [0.6438],\n",
      "        [0.6474],\n",
      "        [0.6419],\n",
      "        [0.6294]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0275, -0.0115,  0.0078],\n",
      "        [-0.0285, -0.0275, -0.0115,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6466],\n",
      "        [0.6406],\n",
      "        [0.6512],\n",
      "        [0.6488],\n",
      "        [0.6405],\n",
      "        [0.6376],\n",
      "        [0.6505],\n",
      "        [0.6546]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6466],\n",
      "        [0.6406],\n",
      "        [0.6512],\n",
      "        [0.6488],\n",
      "        [0.6405],\n",
      "        [0.6376],\n",
      "        [0.6505],\n",
      "        [0.6546]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.2750, 0.6500, 0.7500, 0.5000, 0.4250, 0.6750, 0.9500, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0272, -0.0113,  0.0079],\n",
      "        [-0.0283, -0.0274, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6242],\n",
      "        [0.6308],\n",
      "        [0.6263],\n",
      "        [0.6184],\n",
      "        [0.6139],\n",
      "        [0.6198],\n",
      "        [0.6164],\n",
      "        [0.6125]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0273, -0.0113,  0.0079],\n",
      "        [-0.0283, -0.0273, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6146],\n",
      "        [0.6204],\n",
      "        [0.6111],\n",
      "        [0.6178],\n",
      "        [0.6116],\n",
      "        [0.6127],\n",
      "        [0.6204],\n",
      "        [0.6173]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0274, -0.0114,  0.0079],\n",
      "        [-0.0284, -0.0273, -0.0113,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6267],\n",
      "        [0.6206],\n",
      "        [0.6277],\n",
      "        [0.6285],\n",
      "        [0.6234],\n",
      "        [0.6208],\n",
      "        [0.6133],\n",
      "        [0.6244]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0271, -0.0112,  0.0079],\n",
      "        [-0.0283, -0.0271, -0.0112,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6112],\n",
      "        [0.6055],\n",
      "        [0.6096],\n",
      "        [0.6223],\n",
      "        [0.6080],\n",
      "        [0.6019],\n",
      "        [0.6175],\n",
      "        [0.6138]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0272, -0.0112,  0.0079],\n",
      "        [-0.0282, -0.0273, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6056],\n",
      "        [0.6254],\n",
      "        [0.6270],\n",
      "        [0.6236],\n",
      "        [0.6177],\n",
      "        [0.6114],\n",
      "        [0.6147],\n",
      "        [0.6216]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0273, -0.0114,  0.0079],\n",
      "        [-0.0283, -0.0273, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6305],\n",
      "        [0.6312]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0273, -0.0114,  0.0079],\n",
      "        [-0.0283, -0.0273, -0.0113,  0.0079]], device='cuda:0')\n",
      "after fc out tensor([[0.6276],\n",
      "        [0.6202],\n",
      "        [0.6234],\n",
      "        [0.6184],\n",
      "        [0.6072]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0272, -0.0113,  0.0079],\n",
      "        [-0.0283, -0.0274, -0.0114,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6192],\n",
      "        [0.6321],\n",
      "        [0.6167],\n",
      "        [0.6338],\n",
      "        [0.6263],\n",
      "        [0.6204],\n",
      "        [0.6235],\n",
      "        [0.6145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6192],\n",
      "        [0.6321],\n",
      "        [0.6167],\n",
      "        [0.6338],\n",
      "        [0.6263],\n",
      "        [0.6204],\n",
      "        [0.6235],\n",
      "        [0.6145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.8000, 0.8750, 0.7000, 0.9500, 0.9000, 0.9250, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0287, -0.0124,  0.0075],\n",
      "        [-0.0296, -0.0286, -0.0124,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.8441],\n",
      "        [0.7842],\n",
      "        [0.8446],\n",
      "        [0.8173],\n",
      "        [0.8266],\n",
      "        [0.8537],\n",
      "        [0.8147],\n",
      "        [0.8318]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0277, -0.0265, -0.0104,  0.0080],\n",
      "        [-0.0277, -0.0265, -0.0104,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.4974],\n",
      "        [0.5023],\n",
      "        [0.4931],\n",
      "        [0.5042],\n",
      "        [0.5004],\n",
      "        [0.4999],\n",
      "        [0.4968],\n",
      "        [0.5008]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0269, -0.0107,  0.0079],\n",
      "        [-0.0278, -0.0269, -0.0108,  0.0080]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5354],\n",
      "        [0.5272],\n",
      "        [0.5413],\n",
      "        [0.5285],\n",
      "        [0.5412],\n",
      "        [0.5285],\n",
      "        [0.5332],\n",
      "        [0.5347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0273, -0.0109,  0.0078],\n",
      "        [-0.0284, -0.0273, -0.0109,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5761],\n",
      "        [0.5710],\n",
      "        [0.5704],\n",
      "        [0.5677],\n",
      "        [0.5614],\n",
      "        [0.5603],\n",
      "        [0.5667],\n",
      "        [0.5634]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0279, -0.0113,  0.0077],\n",
      "        [-0.0288, -0.0279, -0.0112,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6192],\n",
      "        [0.6278],\n",
      "        [0.6181],\n",
      "        [0.6164],\n",
      "        [0.6141],\n",
      "        [0.6109],\n",
      "        [0.6087],\n",
      "        [0.6268]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0277, -0.0112,  0.0077],\n",
      "        [-0.0285, -0.0277, -0.0112,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5983],\n",
      "        [0.6076]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0276, -0.0112,  0.0078],\n",
      "        [-0.0285, -0.0277, -0.0112,  0.0077]], device='cuda:0')\n",
      "after fc out tensor([[0.5931],\n",
      "        [0.6023],\n",
      "        [0.5974],\n",
      "        [0.6038],\n",
      "        [0.6214]], device='cuda:0')\n",
      "Epoch:  35. Loss: 0.0007. mean_squared_error.: 0.04673147574067116\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0285, -0.0277, -0.0112,  0.0077],\n",
      "        [-0.0285, -0.0277, -0.0112,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6064],\n",
      "        [0.6061],\n",
      "        [0.6024],\n",
      "        [0.5987],\n",
      "        [0.6093],\n",
      "        [0.6068],\n",
      "        [0.5909],\n",
      "        [0.6015]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6064],\n",
      "        [0.6061],\n",
      "        [0.6024],\n",
      "        [0.5987],\n",
      "        [0.6093],\n",
      "        [0.6068],\n",
      "        [0.5909],\n",
      "        [0.6015]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5250, 0.5750, 0.6000, 0.2750, 0.6750, 0.8750, 0.4000, 0.9000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0277, -0.0112,  0.0077],\n",
      "        [-0.0285, -0.0277, -0.0112,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5972],\n",
      "        [0.5978],\n",
      "        [0.6156],\n",
      "        [0.6108],\n",
      "        [0.5960],\n",
      "        [0.5887],\n",
      "        [0.5941],\n",
      "        [0.5998]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0279, -0.0112,  0.0076],\n",
      "        [-0.0285, -0.0278, -0.0114,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6326],\n",
      "        [0.6064],\n",
      "        [0.6160],\n",
      "        [0.6133],\n",
      "        [0.6368],\n",
      "        [0.6165],\n",
      "        [0.6160],\n",
      "        [0.6152]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0277, -0.0112,  0.0078],\n",
      "        [-0.0286, -0.0277, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5923],\n",
      "        [0.6180],\n",
      "        [0.6075],\n",
      "        [0.5977],\n",
      "        [0.6109],\n",
      "        [0.5994],\n",
      "        [0.6178],\n",
      "        [0.6071]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0113,  0.0077],\n",
      "        [-0.0286, -0.0278, -0.0113,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6146],\n",
      "        [0.6230],\n",
      "        [0.6107],\n",
      "        [0.6243],\n",
      "        [0.6251],\n",
      "        [0.6270],\n",
      "        [0.6066],\n",
      "        [0.6094]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0113,  0.0077],\n",
      "        [-0.0285, -0.0278, -0.0114,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6229],\n",
      "        [0.6112],\n",
      "        [0.6216],\n",
      "        [0.6206],\n",
      "        [0.6252],\n",
      "        [0.6212],\n",
      "        [0.6132],\n",
      "        [0.6131]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0278, -0.0114,  0.0078],\n",
      "        [-0.0288, -0.0279, -0.0112,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6085],\n",
      "        [0.6254]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0113,  0.0077],\n",
      "        [-0.0286, -0.0278, -0.0113,  0.0077]], device='cuda:0')\n",
      "after fc out tensor([[0.6120],\n",
      "        [0.6204],\n",
      "        [0.6158],\n",
      "        [0.6217],\n",
      "        [0.6377]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0113,  0.0077],\n",
      "        [-0.0287, -0.0279, -0.0112,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6122],\n",
      "        [0.6225],\n",
      "        [0.6140],\n",
      "        [0.6212],\n",
      "        [0.6244],\n",
      "        [0.6196],\n",
      "        [0.6252],\n",
      "        [0.6145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6122],\n",
      "        [0.6225],\n",
      "        [0.6140],\n",
      "        [0.6212],\n",
      "        [0.6244],\n",
      "        [0.6196],\n",
      "        [0.6252],\n",
      "        [0.6145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7500, 0.5000, 0.9500, 0.8000, 0.8750, 0.9000, 0.5000, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0286, -0.0117,  0.0075],\n",
      "        [-0.0292, -0.0286, -0.0118,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7150],\n",
      "        [0.7083],\n",
      "        [0.7050],\n",
      "        [0.7200],\n",
      "        [0.7052],\n",
      "        [0.6890],\n",
      "        [0.7091],\n",
      "        [0.6981]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0274, -0.0109,  0.0078],\n",
      "        [-0.0283, -0.0274, -0.0109,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5651],\n",
      "        [0.5631],\n",
      "        [0.5678],\n",
      "        [0.5679],\n",
      "        [0.5598],\n",
      "        [0.5609],\n",
      "        [0.5646],\n",
      "        [0.5649]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0277, -0.0111,  0.0077],\n",
      "        [-0.0284, -0.0277, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5884],\n",
      "        [0.5893],\n",
      "        [0.5885],\n",
      "        [0.5946],\n",
      "        [0.5923],\n",
      "        [0.5917],\n",
      "        [0.5901],\n",
      "        [0.5883]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0281, -0.0114,  0.0077],\n",
      "        [-0.0287, -0.0281, -0.0114,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6366],\n",
      "        [0.6361],\n",
      "        [0.6297],\n",
      "        [0.6331],\n",
      "        [0.6335],\n",
      "        [0.6280],\n",
      "        [0.6288],\n",
      "        [0.6327]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0281, -0.0114,  0.0076],\n",
      "        [-0.0287, -0.0282, -0.0114,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6444],\n",
      "        [0.6413],\n",
      "        [0.6422],\n",
      "        [0.6365],\n",
      "        [0.6437],\n",
      "        [0.6406],\n",
      "        [0.6407],\n",
      "        [0.6399]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0278, -0.0111,  0.0076],\n",
      "        [-0.0287, -0.0278, -0.0111,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6087],\n",
      "        [0.6101]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0280, -0.0113,  0.0077],\n",
      "        [-0.0287, -0.0280, -0.0113,  0.0077]], device='cuda:0')\n",
      "after fc out tensor([[0.6171],\n",
      "        [0.6177],\n",
      "        [0.6170],\n",
      "        [0.6173],\n",
      "        [0.6184]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0279, -0.0112,  0.0076],\n",
      "        [-0.0287, -0.0280, -0.0113,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6193],\n",
      "        [0.6172],\n",
      "        [0.6169],\n",
      "        [0.6182],\n",
      "        [0.6177],\n",
      "        [0.6184],\n",
      "        [0.6181],\n",
      "        [0.6173]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6193],\n",
      "        [0.6172],\n",
      "        [0.6169],\n",
      "        [0.6182],\n",
      "        [0.6177],\n",
      "        [0.6184],\n",
      "        [0.6181],\n",
      "        [0.6173]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.6250, 0.5750, 0.5750, 0.3750, 0.7750, 0.6750, 0.7500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0279, -0.0112,  0.0076],\n",
      "        [-0.0286, -0.0280, -0.0113,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6220],\n",
      "        [0.6199],\n",
      "        [0.6212],\n",
      "        [0.6203],\n",
      "        [0.6207],\n",
      "        [0.6202],\n",
      "        [0.6196],\n",
      "        [0.6200]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0276, -0.0110,  0.0077],\n",
      "        [-0.0284, -0.0277, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5842],\n",
      "        [0.5851],\n",
      "        [0.5845],\n",
      "        [0.5848],\n",
      "        [0.5844],\n",
      "        [0.5851],\n",
      "        [0.5841],\n",
      "        [0.5842]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0277, -0.0111,  0.0077],\n",
      "        [-0.0284, -0.0277, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5871],\n",
      "        [0.5875],\n",
      "        [0.5872],\n",
      "        [0.5868],\n",
      "        [0.5884],\n",
      "        [0.5879],\n",
      "        [0.5869],\n",
      "        [0.5873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0111,  0.0076],\n",
      "        [-0.0285, -0.0278, -0.0112,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6006],\n",
      "        [0.6023],\n",
      "        [0.6014],\n",
      "        [0.6020],\n",
      "        [0.6012],\n",
      "        [0.6027],\n",
      "        [0.6014],\n",
      "        [0.6019]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0279, -0.0112,  0.0077],\n",
      "        [-0.0286, -0.0278, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6058],\n",
      "        [0.6048],\n",
      "        [0.6040],\n",
      "        [0.6051],\n",
      "        [0.6047],\n",
      "        [0.6036],\n",
      "        [0.6045],\n",
      "        [0.6044]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0279, -0.0112,  0.0077],\n",
      "        [-0.0285, -0.0279, -0.0112,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6088],\n",
      "        [0.6115]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0279, -0.0112,  0.0077],\n",
      "        [-0.0286, -0.0279, -0.0112,  0.0077]], device='cuda:0')\n",
      "after fc out tensor([[0.6111],\n",
      "        [0.6100],\n",
      "        [0.6101],\n",
      "        [0.6093],\n",
      "        [0.6074]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0279, -0.0112,  0.0077],\n",
      "        [-0.0287, -0.0278, -0.0111,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6107],\n",
      "        [0.6102],\n",
      "        [0.6094],\n",
      "        [0.6118],\n",
      "        [0.6116],\n",
      "        [0.6089],\n",
      "        [0.6104],\n",
      "        [0.6089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6107],\n",
      "        [0.6102],\n",
      "        [0.6094],\n",
      "        [0.6118],\n",
      "        [0.6116],\n",
      "        [0.6089],\n",
      "        [0.6104],\n",
      "        [0.6089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7500, 0.6750, 0.7250, 0.4000, 0.6000, 0.5500, 0.6250, 0.6500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0279, -0.0112,  0.0076],\n",
      "        [-0.0287, -0.0280, -0.0113,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6206],\n",
      "        [0.6197],\n",
      "        [0.6219],\n",
      "        [0.6178],\n",
      "        [0.6190],\n",
      "        [0.6196],\n",
      "        [0.6200],\n",
      "        [0.6216]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0284, -0.0116,  0.0075],\n",
      "        [-0.0292, -0.0284, -0.0115,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6770],\n",
      "        [0.6818],\n",
      "        [0.6815],\n",
      "        [0.6797],\n",
      "        [0.6829],\n",
      "        [0.6736],\n",
      "        [0.6809],\n",
      "        [0.6853]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0279, -0.0112,  0.0077],\n",
      "        [-0.0287, -0.0279, -0.0112,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6131],\n",
      "        [0.6105],\n",
      "        [0.6099],\n",
      "        [0.6078],\n",
      "        [0.6118],\n",
      "        [0.6099],\n",
      "        [0.6111],\n",
      "        [0.6130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0279, -0.0112,  0.0077],\n",
      "        [-0.0286, -0.0279, -0.0112,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6058],\n",
      "        [0.6085],\n",
      "        [0.6069],\n",
      "        [0.6051],\n",
      "        [0.6063],\n",
      "        [0.6077],\n",
      "        [0.6064],\n",
      "        [0.6058]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0282, -0.0114,  0.0076],\n",
      "        [-0.0289, -0.0282, -0.0114,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6414],\n",
      "        [0.6438],\n",
      "        [0.6418],\n",
      "        [0.6453],\n",
      "        [0.6447],\n",
      "        [0.6443],\n",
      "        [0.6449],\n",
      "        [0.6431]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0279, -0.0112,  0.0077],\n",
      "        [-0.0285, -0.0279, -0.0112,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6016],\n",
      "        [0.6015]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0280, -0.0113,  0.0077],\n",
      "        [-0.0287, -0.0280, -0.0112,  0.0076]], device='cuda:0')\n",
      "after fc out tensor([[0.6146],\n",
      "        [0.6156],\n",
      "        [0.6147],\n",
      "        [0.6152],\n",
      "        [0.6170]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0280, -0.0112,  0.0076],\n",
      "        [-0.0286, -0.0280, -0.0113,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6152],\n",
      "        [0.6142],\n",
      "        [0.6152],\n",
      "        [0.6145],\n",
      "        [0.6157],\n",
      "        [0.6144],\n",
      "        [0.6149],\n",
      "        [0.6156]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6152],\n",
      "        [0.6142],\n",
      "        [0.6152],\n",
      "        [0.6145],\n",
      "        [0.6157],\n",
      "        [0.6144],\n",
      "        [0.6149],\n",
      "        [0.6156]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9500, 0.8000, 0.5250, 0.9000, 0.6750, 0.7000, 0.7500, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0284, -0.0115,  0.0075],\n",
      "        [-0.0291, -0.0284, -0.0115,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6635],\n",
      "        [0.6615],\n",
      "        [0.6606],\n",
      "        [0.6684],\n",
      "        [0.6624],\n",
      "        [0.6652],\n",
      "        [0.6613],\n",
      "        [0.6659]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0282, -0.0113,  0.0076],\n",
      "        [-0.0289, -0.0281, -0.0113,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6321],\n",
      "        [0.6280],\n",
      "        [0.6389],\n",
      "        [0.6281],\n",
      "        [0.6283],\n",
      "        [0.6340],\n",
      "        [0.6251],\n",
      "        [0.6345]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0280, -0.0113,  0.0076],\n",
      "        [-0.0288, -0.0279, -0.0112,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6162],\n",
      "        [0.6187],\n",
      "        [0.6114],\n",
      "        [0.6172],\n",
      "        [0.6166],\n",
      "        [0.6205],\n",
      "        [0.6162],\n",
      "        [0.6214]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0281, -0.0113,  0.0076],\n",
      "        [-0.0286, -0.0281, -0.0113,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6250],\n",
      "        [0.6264],\n",
      "        [0.6185],\n",
      "        [0.6164],\n",
      "        [0.6218],\n",
      "        [0.6214],\n",
      "        [0.6194],\n",
      "        [0.6203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0280, -0.0112,  0.0076],\n",
      "        [-0.0287, -0.0281, -0.0113,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6144],\n",
      "        [0.6204],\n",
      "        [0.6173],\n",
      "        [0.6239],\n",
      "        [0.6136],\n",
      "        [0.6170],\n",
      "        [0.6213],\n",
      "        [0.6229]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0280, -0.0112,  0.0076],\n",
      "        [-0.0288, -0.0279, -0.0112,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6145],\n",
      "        [0.6181]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0281, -0.0113,  0.0076],\n",
      "        [-0.0287, -0.0281, -0.0113,  0.0076]], device='cuda:0')\n",
      "after fc out tensor([[0.6249],\n",
      "        [0.6210],\n",
      "        [0.6225],\n",
      "        [0.6197],\n",
      "        [0.6125]], device='cuda:0')\n",
      "Epoch:  40. Loss: 0.0750. mean_squared_error.: 0.0493960864841938\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0280, -0.0113,  0.0076],\n",
      "        [-0.0287, -0.0281, -0.0113,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6189],\n",
      "        [0.6222],\n",
      "        [0.6229],\n",
      "        [0.6131],\n",
      "        [0.6264],\n",
      "        [0.6234],\n",
      "        [0.6183],\n",
      "        [0.6183]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6189],\n",
      "        [0.6222],\n",
      "        [0.6229],\n",
      "        [0.6131],\n",
      "        [0.6264],\n",
      "        [0.6234],\n",
      "        [0.6183],\n",
      "        [0.6183]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.9000, 0.6750, 0.2750, 0.4000, 0.9250, 0.5000, 0.7250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0280, -0.0112,  0.0076],\n",
      "        [-0.0289, -0.0281, -0.0113,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6269],\n",
      "        [0.6353],\n",
      "        [0.6362],\n",
      "        [0.6310],\n",
      "        [0.6367],\n",
      "        [0.6275],\n",
      "        [0.6316],\n",
      "        [0.6336]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0284, -0.0115,  0.0075],\n",
      "        [-0.0291, -0.0283, -0.0115,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6617],\n",
      "        [0.6637],\n",
      "        [0.6664],\n",
      "        [0.6628],\n",
      "        [0.6617],\n",
      "        [0.6674],\n",
      "        [0.6717],\n",
      "        [0.6660]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0282, -0.0114,  0.0075],\n",
      "        [-0.0290, -0.0282, -0.0114,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6461],\n",
      "        [0.6481],\n",
      "        [0.6438],\n",
      "        [0.6527],\n",
      "        [0.6535],\n",
      "        [0.6516],\n",
      "        [0.6432],\n",
      "        [0.6561]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0111,  0.0077],\n",
      "        [-0.0285, -0.0278, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5885],\n",
      "        [0.5900],\n",
      "        [0.5867],\n",
      "        [0.5972],\n",
      "        [0.5909],\n",
      "        [0.5907],\n",
      "        [0.5918],\n",
      "        [0.5884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0283, -0.0114,  0.0075],\n",
      "        [-0.0289, -0.0284, -0.0115,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6450],\n",
      "        [0.6539],\n",
      "        [0.6522],\n",
      "        [0.6483],\n",
      "        [0.6499],\n",
      "        [0.6543],\n",
      "        [0.6564],\n",
      "        [0.6490]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0281, -0.0113,  0.0076],\n",
      "        [-0.0287, -0.0281, -0.0113,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6234],\n",
      "        [0.6223]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0279, -0.0271, -0.0107,  0.0079],\n",
      "        [-0.0280, -0.0271, -0.0107,  0.0078]], device='cuda:0')\n",
      "after fc out tensor([[0.5156],\n",
      "        [0.5225],\n",
      "        [0.5188],\n",
      "        [0.5235],\n",
      "        [0.5357]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0272, -0.0105,  0.0077],\n",
      "        [-0.0281, -0.0272, -0.0106,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5353],\n",
      "        [0.5318],\n",
      "        [0.5253],\n",
      "        [0.5286],\n",
      "        [0.5324],\n",
      "        [0.5274],\n",
      "        [0.5254],\n",
      "        [0.5177]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5353],\n",
      "        [0.5318],\n",
      "        [0.5253],\n",
      "        [0.5286],\n",
      "        [0.5324],\n",
      "        [0.5274],\n",
      "        [0.5254],\n",
      "        [0.5177]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.2750, 0.3750, 0.5250, 0.5500, 0.5750, 0.6750, 0.6000, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0278, -0.0270, -0.0107,  0.0079],\n",
      "        [-0.0278, -0.0270, -0.0107,  0.0079]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5049],\n",
      "        [0.5086],\n",
      "        [0.5096],\n",
      "        [0.5128],\n",
      "        [0.5148],\n",
      "        [0.5067],\n",
      "        [0.5111],\n",
      "        [0.5043]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0274, -0.0107,  0.0077],\n",
      "        [-0.0282, -0.0274, -0.0108,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5452],\n",
      "        [0.5462],\n",
      "        [0.5474],\n",
      "        [0.5485],\n",
      "        [0.5467],\n",
      "        [0.5448],\n",
      "        [0.5472],\n",
      "        [0.5478]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0282, -0.0275, -0.0109,  0.0078],\n",
      "        [-0.0284, -0.0275, -0.0108,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5510],\n",
      "        [0.5553],\n",
      "        [0.5545],\n",
      "        [0.5536],\n",
      "        [0.5540],\n",
      "        [0.5512],\n",
      "        [0.5505],\n",
      "        [0.5519]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0277, -0.0109,  0.0077],\n",
      "        [-0.0286, -0.0276, -0.0109,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5684],\n",
      "        [0.5744],\n",
      "        [0.5700],\n",
      "        [0.5697],\n",
      "        [0.5718],\n",
      "        [0.5722],\n",
      "        [0.5716],\n",
      "        [0.5700]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0110,  0.0076],\n",
      "        [-0.0284, -0.0278, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5857],\n",
      "        [0.5827],\n",
      "        [0.5812],\n",
      "        [0.5847],\n",
      "        [0.5875],\n",
      "        [0.5850],\n",
      "        [0.5854],\n",
      "        [0.5830]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0284, -0.0278, -0.0111,  0.0077],\n",
      "        [-0.0286, -0.0278, -0.0110,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5833],\n",
      "        [0.5873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0279, -0.0111,  0.0077],\n",
      "        [-0.0285, -0.0278, -0.0110,  0.0077]], device='cuda:0')\n",
      "after fc out tensor([[0.5862],\n",
      "        [0.5882],\n",
      "        [0.5868],\n",
      "        [0.5881],\n",
      "        [0.5914]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0278, -0.0110,  0.0076],\n",
      "        [-0.0284, -0.0279, -0.0111,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5916],\n",
      "        [0.5851],\n",
      "        [0.5880],\n",
      "        [0.5862],\n",
      "        [0.5881],\n",
      "        [0.5898],\n",
      "        [0.5866],\n",
      "        [0.5869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5916],\n",
      "        [0.5851],\n",
      "        [0.5880],\n",
      "        [0.5862],\n",
      "        [0.5881],\n",
      "        [0.5898],\n",
      "        [0.5866],\n",
      "        [0.5869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.8000, 0.8500, 0.5750, 0.6500, 0.7250, 0.4250, 0.6250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0284, -0.0114,  0.0075],\n",
      "        [-0.0289, -0.0284, -0.0114,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6484],\n",
      "        [0.6482],\n",
      "        [0.6535],\n",
      "        [0.6511],\n",
      "        [0.6500],\n",
      "        [0.6511],\n",
      "        [0.6503],\n",
      "        [0.6515]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0278, -0.0110,  0.0076],\n",
      "        [-0.0286, -0.0278, -0.0110,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5861],\n",
      "        [0.5820],\n",
      "        [0.5858],\n",
      "        [0.5838],\n",
      "        [0.5849],\n",
      "        [0.5855],\n",
      "        [0.5808],\n",
      "        [0.5834]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0284, -0.0113,  0.0075],\n",
      "        [-0.0291, -0.0283, -0.0113,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6444],\n",
      "        [0.6447],\n",
      "        [0.6445],\n",
      "        [0.6432],\n",
      "        [0.6427],\n",
      "        [0.6429],\n",
      "        [0.6440],\n",
      "        [0.6458]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0275, -0.0107,  0.0077],\n",
      "        [-0.0283, -0.0275, -0.0107,  0.0077]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5473],\n",
      "        [0.5451],\n",
      "        [0.5491],\n",
      "        [0.5506],\n",
      "        [0.5506],\n",
      "        [0.5488],\n",
      "        [0.5411],\n",
      "        [0.5485]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0113,  0.0075],\n",
      "        [-0.0290, -0.0282, -0.0113,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6418],\n",
      "        [0.6305],\n",
      "        [0.6178],\n",
      "        [0.6296],\n",
      "        [0.6437],\n",
      "        [0.6339],\n",
      "        [0.6339],\n",
      "        [0.6289]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0279, -0.0111,  0.0076],\n",
      "        [-0.0287, -0.0282, -0.0111,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6079],\n",
      "        [0.6121]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0294, -0.0118,  0.0073],\n",
      "        [-0.0297, -0.0293, -0.0118,  0.0073]], device='cuda:0')\n",
      "after fc out tensor([[0.7606],\n",
      "        [0.7453],\n",
      "        [0.7524],\n",
      "        [0.7415],\n",
      "        [0.7123]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0294, -0.0118,  0.0073],\n",
      "        [-0.0297, -0.0295, -0.0118,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7613],\n",
      "        [0.7690],\n",
      "        [0.7508],\n",
      "        [0.7378],\n",
      "        [0.7438],\n",
      "        [0.7574],\n",
      "        [0.7576],\n",
      "        [0.7514]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.7613],\n",
      "        [0.7690],\n",
      "        [0.7508],\n",
      "        [0.7378],\n",
      "        [0.7438],\n",
      "        [0.7574],\n",
      "        [0.7576],\n",
      "        [0.7514]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.4250, 0.8000, 0.2750, 0.5750, 0.6000, 0.6750, 0.5750, 0.4750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0112,  0.0075],\n",
      "        [-0.0290, -0.0283, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.6384],\n",
      "        [0.6325],\n",
      "        [0.6334],\n",
      "        [0.6373],\n",
      "        [0.6236],\n",
      "        [0.6274],\n",
      "        [0.6313],\n",
      "        [0.6373]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0285, -0.0113,  0.0074],\n",
      "        [-0.0290, -0.0285, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6437],\n",
      "        [0.6464],\n",
      "        [0.6460],\n",
      "        [0.6421],\n",
      "        [0.6436],\n",
      "        [0.6370],\n",
      "        [0.6490],\n",
      "        [0.6298]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0287, -0.0113,  0.0074],\n",
      "        [-0.0291, -0.0285, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6532],\n",
      "        [0.6347],\n",
      "        [0.6440],\n",
      "        [0.6522],\n",
      "        [0.6421],\n",
      "        [0.6379],\n",
      "        [0.6504],\n",
      "        [0.6439]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0285, -0.0113,  0.0074],\n",
      "        [-0.0291, -0.0285, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6377],\n",
      "        [0.6417],\n",
      "        [0.6374],\n",
      "        [0.6448],\n",
      "        [0.6413],\n",
      "        [0.6408],\n",
      "        [0.6376],\n",
      "        [0.6350]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0286, -0.0113,  0.0074],\n",
      "        [-0.0291, -0.0285, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6539],\n",
      "        [0.6432],\n",
      "        [0.6539],\n",
      "        [0.6417],\n",
      "        [0.6458],\n",
      "        [0.6425],\n",
      "        [0.6403],\n",
      "        [0.6337]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0287, -0.0113,  0.0075],\n",
      "        [-0.0291, -0.0284, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6521],\n",
      "        [0.6331]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0286, -0.0113,  0.0074],\n",
      "        [-0.0290, -0.0286, -0.0113,  0.0074]], device='cuda:0')\n",
      "after fc out tensor([[0.6488],\n",
      "        [0.6425],\n",
      "        [0.6450],\n",
      "        [0.6404],\n",
      "        [0.6275]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0286, -0.0113,  0.0074],\n",
      "        [-0.0290, -0.0286, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6389],\n",
      "        [0.6458],\n",
      "        [0.6376],\n",
      "        [0.6379],\n",
      "        [0.6404],\n",
      "        [0.6363],\n",
      "        [0.6487],\n",
      "        [0.6398]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6389],\n",
      "        [0.6458],\n",
      "        [0.6376],\n",
      "        [0.6379],\n",
      "        [0.6404],\n",
      "        [0.6363],\n",
      "        [0.6487],\n",
      "        [0.6398]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.6250, 0.5250, 0.7250, 0.8500, 0.6750, 0.7500, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0286, -0.0113,  0.0074],\n",
      "        [-0.0292, -0.0285, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6511],\n",
      "        [0.6540],\n",
      "        [0.6503],\n",
      "        [0.6511],\n",
      "        [0.6568],\n",
      "        [0.6632],\n",
      "        [0.6578],\n",
      "        [0.6487]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0280, -0.0110,  0.0075],\n",
      "        [-0.0287, -0.0280, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5815],\n",
      "        [0.5925],\n",
      "        [0.5877],\n",
      "        [0.5866],\n",
      "        [0.5887],\n",
      "        [0.5837],\n",
      "        [0.5884],\n",
      "        [0.5725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0281, -0.0109,  0.0076],\n",
      "        [-0.0286, -0.0279, -0.0109,  0.0076]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5824],\n",
      "        [0.5794],\n",
      "        [0.5755],\n",
      "        [0.5684],\n",
      "        [0.5753],\n",
      "        [0.5719],\n",
      "        [0.5735],\n",
      "        [0.5837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0288, -0.0114,  0.0074],\n",
      "        [-0.0292, -0.0289, -0.0114,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6719],\n",
      "        [0.6719],\n",
      "        [0.6680],\n",
      "        [0.6594],\n",
      "        [0.6693],\n",
      "        [0.6650],\n",
      "        [0.6515],\n",
      "        [0.6663]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0281, -0.0110,  0.0075],\n",
      "        [-0.0287, -0.0283, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5907],\n",
      "        [0.5955],\n",
      "        [0.5968],\n",
      "        [0.5952],\n",
      "        [0.5970],\n",
      "        [0.5921],\n",
      "        [0.5956],\n",
      "        [0.5990]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0286, -0.0112,  0.0074],\n",
      "        [-0.0291, -0.0285, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6388],\n",
      "        [0.6288]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0291, -0.0115,  0.0073],\n",
      "        [-0.0294, -0.0290, -0.0115,  0.0073]], device='cuda:0')\n",
      "after fc out tensor([[0.6902],\n",
      "        [0.6883],\n",
      "        [0.6885],\n",
      "        [0.6869],\n",
      "        [0.6829]], device='cuda:0')\n",
      "Epoch:  45. Loss: 0.0108. mean_squared_error.: 0.06458485126495361\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0290, -0.0115,  0.0073],\n",
      "        [-0.0294, -0.0290, -0.0115,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6871],\n",
      "        [0.6850],\n",
      "        [0.6835],\n",
      "        [0.6870],\n",
      "        [0.6895],\n",
      "        [0.6887],\n",
      "        [0.6916],\n",
      "        [0.6924]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6871],\n",
      "        [0.6850],\n",
      "        [0.6835],\n",
      "        [0.6870],\n",
      "        [0.6895],\n",
      "        [0.6887],\n",
      "        [0.6916],\n",
      "        [0.6924]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6000, 0.7000, 0.3750, 0.7250, 0.7500, 0.6750, 0.7250, 0.7000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0289, -0.0114,  0.0073],\n",
      "        [-0.0293, -0.0289, -0.0114,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6729],\n",
      "        [0.6713],\n",
      "        [0.6698],\n",
      "        [0.6670],\n",
      "        [0.6679],\n",
      "        [0.6714],\n",
      "        [0.6700],\n",
      "        [0.6685]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0285, -0.0112,  0.0074],\n",
      "        [-0.0290, -0.0283, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6212],\n",
      "        [0.6284],\n",
      "        [0.6274],\n",
      "        [0.6230],\n",
      "        [0.6227],\n",
      "        [0.6276],\n",
      "        [0.6327],\n",
      "        [0.6222]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0287, -0.0112,  0.0074],\n",
      "        [-0.0290, -0.0286, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6333],\n",
      "        [0.6307],\n",
      "        [0.6348],\n",
      "        [0.6384],\n",
      "        [0.6261],\n",
      "        [0.6238],\n",
      "        [0.6372],\n",
      "        [0.6238]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0285, -0.0112,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6157],\n",
      "        [0.6218],\n",
      "        [0.6228],\n",
      "        [0.6258],\n",
      "        [0.6151],\n",
      "        [0.6209],\n",
      "        [0.6265],\n",
      "        [0.6202]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6265],\n",
      "        [0.6232],\n",
      "        [0.6192],\n",
      "        [0.6098],\n",
      "        [0.6155],\n",
      "        [0.6221],\n",
      "        [0.6209],\n",
      "        [0.6198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0284, -0.0111,  0.0074],\n",
      "        [-0.0290, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6202],\n",
      "        [0.6174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0286, -0.0112,  0.0074],\n",
      "        [-0.0290, -0.0285, -0.0112,  0.0074]], device='cuda:0')\n",
      "after fc out tensor([[0.6305],\n",
      "        [0.6257],\n",
      "        [0.6274],\n",
      "        [0.6239],\n",
      "        [0.6143]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0285, -0.0112,  0.0074],\n",
      "        [-0.0290, -0.0285, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6227],\n",
      "        [0.6228],\n",
      "        [0.6280],\n",
      "        [0.6295],\n",
      "        [0.6324],\n",
      "        [0.6305],\n",
      "        [0.6345],\n",
      "        [0.6291]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6227],\n",
      "        [0.6228],\n",
      "        [0.6280],\n",
      "        [0.6295],\n",
      "        [0.6324],\n",
      "        [0.6305],\n",
      "        [0.6345],\n",
      "        [0.6291]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.6000, 0.5000, 0.5500, 0.6000, 0.7500, 0.7000, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0284, -0.0111,  0.0074],\n",
      "        [-0.0288, -0.0285, -0.0111,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6138],\n",
      "        [0.6172],\n",
      "        [0.6116],\n",
      "        [0.6160],\n",
      "        [0.6147],\n",
      "        [0.6195],\n",
      "        [0.6170],\n",
      "        [0.6150]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0285, -0.0112,  0.0074],\n",
      "        [-0.0290, -0.0286, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6298],\n",
      "        [0.6405],\n",
      "        [0.6314],\n",
      "        [0.6331],\n",
      "        [0.6304],\n",
      "        [0.6306],\n",
      "        [0.6352],\n",
      "        [0.6340]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0286, -0.0113,  0.0074],\n",
      "        [-0.0291, -0.0286, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6468],\n",
      "        [0.6356],\n",
      "        [0.6437],\n",
      "        [0.6433],\n",
      "        [0.6492],\n",
      "        [0.6453],\n",
      "        [0.6437],\n",
      "        [0.6348]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0287, -0.0113,  0.0073],\n",
      "        [-0.0292, -0.0289, -0.0114,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6658],\n",
      "        [0.6662],\n",
      "        [0.6655],\n",
      "        [0.6564],\n",
      "        [0.6557],\n",
      "        [0.6619],\n",
      "        [0.6559],\n",
      "        [0.6591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0283, -0.0111,  0.0075],\n",
      "        [-0.0289, -0.0283, -0.0110,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6029],\n",
      "        [0.6027],\n",
      "        [0.5983],\n",
      "        [0.5994],\n",
      "        [0.6013],\n",
      "        [0.6026],\n",
      "        [0.6058],\n",
      "        [0.6032]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0285, -0.0111,  0.0075],\n",
      "        [-0.0289, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6150],\n",
      "        [0.6126]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0284, -0.0111,  0.0075],\n",
      "        [-0.0288, -0.0284, -0.0111,  0.0075]], device='cuda:0')\n",
      "after fc out tensor([[0.6082],\n",
      "        [0.6073],\n",
      "        [0.6071],\n",
      "        [0.6062],\n",
      "        [0.6034]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0283, -0.0110,  0.0074],\n",
      "        [-0.0290, -0.0282, -0.0110,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6039],\n",
      "        [0.6064],\n",
      "        [0.6061],\n",
      "        [0.6053],\n",
      "        [0.6067],\n",
      "        [0.6093],\n",
      "        [0.6076],\n",
      "        [0.6059]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6039],\n",
      "        [0.6064],\n",
      "        [0.6061],\n",
      "        [0.6053],\n",
      "        [0.6067],\n",
      "        [0.6093],\n",
      "        [0.6076],\n",
      "        [0.6059]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.2750, 0.6500, 0.6000, 0.6750, 0.4750, 0.7000, 0.7500, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0282, -0.0110,  0.0075],\n",
      "        [-0.0288, -0.0283, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6013],\n",
      "        [0.5978],\n",
      "        [0.5991],\n",
      "        [0.6001],\n",
      "        [0.6006],\n",
      "        [0.5972],\n",
      "        [0.5983],\n",
      "        [0.6009]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0112,  0.0075],\n",
      "        [-0.0290, -0.0285, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6217],\n",
      "        [0.6227],\n",
      "        [0.6206],\n",
      "        [0.6233],\n",
      "        [0.6237],\n",
      "        [0.6211],\n",
      "        [0.6211],\n",
      "        [0.6187]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0285, -0.0111,  0.0075],\n",
      "        [-0.0289, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6164],\n",
      "        [0.6176],\n",
      "        [0.6156],\n",
      "        [0.6154],\n",
      "        [0.6147],\n",
      "        [0.6147],\n",
      "        [0.6158],\n",
      "        [0.6180]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0285, -0.0112,  0.0074],\n",
      "        [-0.0290, -0.0285, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6261],\n",
      "        [0.6233],\n",
      "        [0.6221],\n",
      "        [0.6204],\n",
      "        [0.6283],\n",
      "        [0.6210],\n",
      "        [0.6260],\n",
      "        [0.6267]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0284, -0.0111,  0.0074],\n",
      "        [-0.0290, -0.0283, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6191],\n",
      "        [0.6206],\n",
      "        [0.6230],\n",
      "        [0.6206],\n",
      "        [0.6157],\n",
      "        [0.6184],\n",
      "        [0.6174],\n",
      "        [0.6171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0285, -0.0111,  0.0074],\n",
      "        [-0.0290, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6244],\n",
      "        [0.6216]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0112,  0.0074],\n",
      "        [-0.0289, -0.0285, -0.0112,  0.0074]], device='cuda:0')\n",
      "after fc out tensor([[0.6240],\n",
      "        [0.6222],\n",
      "        [0.6224],\n",
      "        [0.6209],\n",
      "        [0.6164]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0284, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0285, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6245],\n",
      "        [0.6221],\n",
      "        [0.6199],\n",
      "        [0.6182],\n",
      "        [0.6252],\n",
      "        [0.6254],\n",
      "        [0.6220],\n",
      "        [0.6237]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6245],\n",
      "        [0.6221],\n",
      "        [0.6199],\n",
      "        [0.6182],\n",
      "        [0.6252],\n",
      "        [0.6254],\n",
      "        [0.6220],\n",
      "        [0.6237]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9250, 0.5750, 0.5500, 0.7750, 0.7000, 0.5750, 0.4750, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0287, -0.0113,  0.0074],\n",
      "        [-0.0293, -0.0286, -0.0113,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6532],\n",
      "        [0.6559],\n",
      "        [0.6569],\n",
      "        [0.6585],\n",
      "        [0.6552],\n",
      "        [0.6555],\n",
      "        [0.6575],\n",
      "        [0.6567]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0287, -0.0113,  0.0074],\n",
      "        [-0.0292, -0.0286, -0.0113,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6459],\n",
      "        [0.6458],\n",
      "        [0.6410],\n",
      "        [0.6442],\n",
      "        [0.6448],\n",
      "        [0.6443],\n",
      "        [0.6428],\n",
      "        [0.6429]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0282, -0.0110,  0.0075],\n",
      "        [-0.0287, -0.0284, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5920],\n",
      "        [0.6014],\n",
      "        [0.5918],\n",
      "        [0.6027],\n",
      "        [0.5946],\n",
      "        [0.5936],\n",
      "        [0.5962],\n",
      "        [0.5968]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0287, -0.0112,  0.0074],\n",
      "        [-0.0291, -0.0286, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6428],\n",
      "        [0.6395],\n",
      "        [0.6353],\n",
      "        [0.6201],\n",
      "        [0.6290],\n",
      "        [0.6386],\n",
      "        [0.6298],\n",
      "        [0.6377]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0290, -0.0114,  0.0073],\n",
      "        [-0.0293, -0.0290, -0.0114,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6776],\n",
      "        [0.6842],\n",
      "        [0.6705],\n",
      "        [0.6816],\n",
      "        [0.6668],\n",
      "        [0.6695],\n",
      "        [0.6687],\n",
      "        [0.6625]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0284, -0.0110,  0.0075],\n",
      "        [-0.0288, -0.0281, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5948],\n",
      "        [0.5844]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0281, -0.0108,  0.0075],\n",
      "        [-0.0285, -0.0280, -0.0108,  0.0075]], device='cuda:0')\n",
      "after fc out tensor([[0.5704],\n",
      "        [0.5639],\n",
      "        [0.5665],\n",
      "        [0.5616],\n",
      "        [0.5484]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0279, -0.0108,  0.0075],\n",
      "        [-0.0285, -0.0280, -0.0108,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5524],\n",
      "        [0.5666],\n",
      "        [0.5742],\n",
      "        [0.5590],\n",
      "        [0.5644],\n",
      "        [0.5743],\n",
      "        [0.5686],\n",
      "        [0.5574]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5524],\n",
      "        [0.5666],\n",
      "        [0.5742],\n",
      "        [0.5590],\n",
      "        [0.5644],\n",
      "        [0.5743],\n",
      "        [0.5686],\n",
      "        [0.5574]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.5250, 0.7000, 0.7250, 0.8000, 0.6750, 0.6750, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0282, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6119],\n",
      "        [0.6076],\n",
      "        [0.6047],\n",
      "        [0.5955],\n",
      "        [0.6099],\n",
      "        [0.6080],\n",
      "        [0.6200],\n",
      "        [0.6173]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0284, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6028],\n",
      "        [0.6044],\n",
      "        [0.5923],\n",
      "        [0.6028],\n",
      "        [0.6046],\n",
      "        [0.6026],\n",
      "        [0.6155],\n",
      "        [0.6000]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0283, -0.0110,  0.0075],\n",
      "        [-0.0288, -0.0283, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6035],\n",
      "        [0.5924],\n",
      "        [0.6069],\n",
      "        [0.6008],\n",
      "        [0.5932],\n",
      "        [0.5966],\n",
      "        [0.6009],\n",
      "        [0.5903]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0283, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0285, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5971],\n",
      "        [0.6149],\n",
      "        [0.5996],\n",
      "        [0.6108],\n",
      "        [0.6159],\n",
      "        [0.6143],\n",
      "        [0.6127],\n",
      "        [0.6050]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0286, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0286, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6133],\n",
      "        [0.6206],\n",
      "        [0.6052],\n",
      "        [0.6076],\n",
      "        [0.6196],\n",
      "        [0.6110],\n",
      "        [0.6142],\n",
      "        [0.6157]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0284, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0285, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6043],\n",
      "        [0.6118]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0286, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0285, -0.0111,  0.0074]], device='cuda:0')\n",
      "after fc out tensor([[0.6188],\n",
      "        [0.6118],\n",
      "        [0.6146],\n",
      "        [0.6095],\n",
      "        [0.5958]], device='cuda:0')\n",
      "Epoch:  50. Loss: 0.0461. mean_squared_error.: 0.04798615351319313\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0285, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6105],\n",
      "        [0.6080],\n",
      "        [0.6214],\n",
      "        [0.6228],\n",
      "        [0.6124],\n",
      "        [0.6079],\n",
      "        [0.6141],\n",
      "        [0.6049]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6105],\n",
      "        [0.6080],\n",
      "        [0.6214],\n",
      "        [0.6228],\n",
      "        [0.6124],\n",
      "        [0.6079],\n",
      "        [0.6141],\n",
      "        [0.6049]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6000, 0.6500, 0.4000, 0.7000, 0.8000, 0.6000, 0.2750, 0.5500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0280, -0.0109,  0.0075],\n",
      "        [-0.0286, -0.0282, -0.0109,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5815],\n",
      "        [0.5783],\n",
      "        [0.5779],\n",
      "        [0.5694],\n",
      "        [0.5777],\n",
      "        [0.5701],\n",
      "        [0.5775],\n",
      "        [0.5679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0287, -0.0112,  0.0074],\n",
      "        [-0.0290, -0.0287, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6326],\n",
      "        [0.6417],\n",
      "        [0.6399],\n",
      "        [0.6311],\n",
      "        [0.6236],\n",
      "        [0.6323],\n",
      "        [0.6307],\n",
      "        [0.6290]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0288, -0.0113,  0.0073],\n",
      "        [-0.0293, -0.0289, -0.0113,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6617],\n",
      "        [0.6569],\n",
      "        [0.6464],\n",
      "        [0.6745],\n",
      "        [0.6492],\n",
      "        [0.6606],\n",
      "        [0.6676],\n",
      "        [0.6711]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0286, -0.0112,  0.0074],\n",
      "        [-0.0292, -0.0285, -0.0112,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6346],\n",
      "        [0.6207],\n",
      "        [0.6520],\n",
      "        [0.6359],\n",
      "        [0.6417],\n",
      "        [0.6240],\n",
      "        [0.6462],\n",
      "        [0.6357]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0279, -0.0109,  0.0075],\n",
      "        [-0.0286, -0.0281, -0.0109,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5748],\n",
      "        [0.5775],\n",
      "        [0.5619],\n",
      "        [0.5746],\n",
      "        [0.5640],\n",
      "        [0.5837],\n",
      "        [0.5729],\n",
      "        [0.5653]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0288, -0.0113,  0.0073],\n",
      "        [-0.0294, -0.0288, -0.0113,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6604],\n",
      "        [0.6483]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0285, -0.0109,  0.0074],\n",
      "        [-0.0288, -0.0284, -0.0109,  0.0074]], device='cuda:0')\n",
      "after fc out tensor([[0.6111],\n",
      "        [0.5893],\n",
      "        [0.5995],\n",
      "        [0.5840],\n",
      "        [0.5426]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0284, -0.0109,  0.0074],\n",
      "        [-0.0288, -0.0283, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5985],\n",
      "        [0.5842],\n",
      "        [0.5448],\n",
      "        [0.5786],\n",
      "        [0.5545],\n",
      "        [0.5981],\n",
      "        [0.5548],\n",
      "        [0.5591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5985],\n",
      "        [0.5842],\n",
      "        [0.5448],\n",
      "        [0.5786],\n",
      "        [0.5545],\n",
      "        [0.5981],\n",
      "        [0.5548],\n",
      "        [0.5591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5250, 0.8500, 0.2750, 0.5750, 0.5750, 0.4750, 0.3750, 0.6500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0285, -0.0108,  0.0074],\n",
      "        [-0.0287, -0.0282, -0.0109,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5915],\n",
      "        [0.5608],\n",
      "        [0.5629],\n",
      "        [0.6082],\n",
      "        [0.5708],\n",
      "        [0.6112],\n",
      "        [0.5831],\n",
      "        [0.5680]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0286, -0.0110,  0.0074],\n",
      "        [-0.0289, -0.0286, -0.0110,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6379],\n",
      "        [0.5967],\n",
      "        [0.6319],\n",
      "        [0.6078],\n",
      "        [0.6154],\n",
      "        [0.5923],\n",
      "        [0.6170],\n",
      "        [0.6293]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0286, -0.0109,  0.0074],\n",
      "        [-0.0288, -0.0280, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6249],\n",
      "        [0.6042],\n",
      "        [0.6066],\n",
      "        [0.6092],\n",
      "        [0.5922],\n",
      "        [0.5942],\n",
      "        [0.6303],\n",
      "        [0.5827]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0285, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0283, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6298],\n",
      "        [0.6106],\n",
      "        [0.6253],\n",
      "        [0.6005],\n",
      "        [0.5908],\n",
      "        [0.5965],\n",
      "        [0.6513],\n",
      "        [0.6471]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0290, -0.0287, -0.0111,  0.0074],\n",
      "        [-0.0290, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6383],\n",
      "        [0.5964],\n",
      "        [0.6059],\n",
      "        [0.5940],\n",
      "        [0.6358],\n",
      "        [0.6247],\n",
      "        [0.5789],\n",
      "        [0.6341]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0284, -0.0111,  0.0074],\n",
      "        [-0.0289, -0.0283, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6466],\n",
      "        [0.5988]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0288, -0.0111,  0.0073],\n",
      "        [-0.0290, -0.0287, -0.0111,  0.0074]], device='cuda:0')\n",
      "after fc out tensor([[0.6404],\n",
      "        [0.6168],\n",
      "        [0.6279],\n",
      "        [0.6111],\n",
      "        [0.5664]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0289, -0.0110,  0.0073],\n",
      "        [-0.0290, -0.0284, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6534],\n",
      "        [0.5969],\n",
      "        [0.6177],\n",
      "        [0.6318],\n",
      "        [0.5840],\n",
      "        [0.5796],\n",
      "        [0.6267],\n",
      "        [0.6253]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6534],\n",
      "        [0.5969],\n",
      "        [0.6177],\n",
      "        [0.6318],\n",
      "        [0.5840],\n",
      "        [0.5796],\n",
      "        [0.6267],\n",
      "        [0.6253]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.8000, 0.6750, 0.9000, 0.5000, 0.6500, 0.3750, 0.5250, 0.2750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0281, -0.0110,  0.0075],\n",
      "        [-0.0288, -0.0281, -0.0110,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5488],\n",
      "        [0.5576],\n",
      "        [0.6042],\n",
      "        [0.6202],\n",
      "        [0.5808],\n",
      "        [0.5579],\n",
      "        [0.6002],\n",
      "        [0.6051]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0284, -0.0110,  0.0074],\n",
      "        [-0.0289, -0.0283, -0.0110,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6025],\n",
      "        [0.6000],\n",
      "        [0.6320],\n",
      "        [0.6133],\n",
      "        [0.5972],\n",
      "        [0.5977],\n",
      "        [0.6209],\n",
      "        [0.5986]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0286, -0.0111,  0.0074],\n",
      "        [-0.0290, -0.0285, -0.0111,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6319],\n",
      "        [0.6182],\n",
      "        [0.6065],\n",
      "        [0.6256],\n",
      "        [0.6078],\n",
      "        [0.6268],\n",
      "        [0.6111],\n",
      "        [0.6202]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0296, -0.0117,  0.0071],\n",
      "        [-0.0299, -0.0296, -0.0117,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7499],\n",
      "        [0.7535],\n",
      "        [0.7717],\n",
      "        [0.7735],\n",
      "        [0.7468],\n",
      "        [0.7690],\n",
      "        [0.7469],\n",
      "        [0.7687]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0290, -0.0112,  0.0073],\n",
      "        [-0.0292, -0.0290, -0.0112,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6372],\n",
      "        [0.6364],\n",
      "        [0.6358],\n",
      "        [0.6387],\n",
      "        [0.6366],\n",
      "        [0.6373],\n",
      "        [0.6359],\n",
      "        [0.6373]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0285, -0.0109,  0.0074],\n",
      "        [-0.0288, -0.0284, -0.0109,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5828],\n",
      "        [0.5837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0282, -0.0108,  0.0075],\n",
      "        [-0.0286, -0.0282, -0.0108,  0.0075]], device='cuda:0')\n",
      "after fc out tensor([[0.5574],\n",
      "        [0.5594],\n",
      "        [0.5578],\n",
      "        [0.5589],\n",
      "        [0.5605]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0282, -0.0108,  0.0075],\n",
      "        [-0.0286, -0.0282, -0.0108,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5583],\n",
      "        [0.5576],\n",
      "        [0.5602],\n",
      "        [0.5561],\n",
      "        [0.5595],\n",
      "        [0.5571],\n",
      "        [0.5597],\n",
      "        [0.5557]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5583],\n",
      "        [0.5576],\n",
      "        [0.5602],\n",
      "        [0.5561],\n",
      "        [0.5595],\n",
      "        [0.5571],\n",
      "        [0.5597],\n",
      "        [0.5557]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5500, 0.9000, 0.8000, 0.7000, 0.6750, 0.6750, 0.3750, 0.7250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0287, -0.0110,  0.0073],\n",
      "        [-0.0290, -0.0288, -0.0110,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6102],\n",
      "        [0.6097],\n",
      "        [0.6110],\n",
      "        [0.6098],\n",
      "        [0.6083],\n",
      "        [0.6096],\n",
      "        [0.6092],\n",
      "        [0.6100]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0286, -0.0110,  0.0073],\n",
      "        [-0.0290, -0.0287, -0.0110,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6051],\n",
      "        [0.6042],\n",
      "        [0.6073],\n",
      "        [0.6055],\n",
      "        [0.6054],\n",
      "        [0.6058],\n",
      "        [0.6058],\n",
      "        [0.6055]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0286, -0.0110,  0.0073],\n",
      "        [-0.0290, -0.0287, -0.0110,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6078],\n",
      "        [0.6104],\n",
      "        [0.6111],\n",
      "        [0.6099],\n",
      "        [0.6093],\n",
      "        [0.6107],\n",
      "        [0.6112],\n",
      "        [0.6091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0287, -0.0110,  0.0073],\n",
      "        [-0.0290, -0.0287, -0.0110,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6129],\n",
      "        [0.6141],\n",
      "        [0.6122],\n",
      "        [0.6131],\n",
      "        [0.6122],\n",
      "        [0.6125],\n",
      "        [0.6144],\n",
      "        [0.6138]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0288, -0.0111,  0.0073],\n",
      "        [-0.0291, -0.0287, -0.0111,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6167],\n",
      "        [0.6150],\n",
      "        [0.6151],\n",
      "        [0.6170],\n",
      "        [0.6170],\n",
      "        [0.6160],\n",
      "        [0.6152],\n",
      "        [0.6175]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0287, -0.0110,  0.0073],\n",
      "        [-0.0290, -0.0288, -0.0111,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6164],\n",
      "        [0.6167]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0288, -0.0111,  0.0073],\n",
      "        [-0.0290, -0.0288, -0.0111,  0.0073]], device='cuda:0')\n",
      "after fc out tensor([[0.6162],\n",
      "        [0.6159],\n",
      "        [0.6154],\n",
      "        [0.6148],\n",
      "        [0.6122]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0287, -0.0110,  0.0073],\n",
      "        [-0.0291, -0.0287, -0.0110,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6155],\n",
      "        [0.6136],\n",
      "        [0.6151],\n",
      "        [0.6151],\n",
      "        [0.6149],\n",
      "        [0.6162],\n",
      "        [0.6157],\n",
      "        [0.6154]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6155],\n",
      "        [0.6136],\n",
      "        [0.6151],\n",
      "        [0.6151],\n",
      "        [0.6149],\n",
      "        [0.6162],\n",
      "        [0.6157],\n",
      "        [0.6154]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5000, 0.7000, 0.8750, 0.4750, 0.8500, 0.6750, 0.4250, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0291, -0.0112,  0.0073],\n",
      "        [-0.0293, -0.0290, -0.0112,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6491],\n",
      "        [0.6476],\n",
      "        [0.6481],\n",
      "        [0.6495],\n",
      "        [0.6487],\n",
      "        [0.6484],\n",
      "        [0.6499],\n",
      "        [0.6494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0285, -0.0281, -0.0107,  0.0075],\n",
      "        [-0.0285, -0.0282, -0.0107,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5431],\n",
      "        [0.5426],\n",
      "        [0.5424],\n",
      "        [0.5429],\n",
      "        [0.5405],\n",
      "        [0.5435],\n",
      "        [0.5411],\n",
      "        [0.5419]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0283, -0.0280, -0.0106,  0.0075],\n",
      "        [-0.0284, -0.0279, -0.0106,  0.0075]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5237],\n",
      "        [0.5239],\n",
      "        [0.5237],\n",
      "        [0.5235],\n",
      "        [0.5233],\n",
      "        [0.5218],\n",
      "        [0.5247],\n",
      "        [0.5218]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0288, -0.0111,  0.0072],\n",
      "        [-0.0292, -0.0289, -0.0111,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6238],\n",
      "        [0.6247],\n",
      "        [0.6299],\n",
      "        [0.6312],\n",
      "        [0.6348],\n",
      "        [0.6374],\n",
      "        [0.6350],\n",
      "        [0.6299]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0298, -0.0116,  0.0070],\n",
      "        [-0.0301, -0.0298, -0.0116,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7495],\n",
      "        [0.7490],\n",
      "        [0.7579],\n",
      "        [0.7625],\n",
      "        [0.7615],\n",
      "        [0.7543],\n",
      "        [0.7638],\n",
      "        [0.7397]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0288, -0.0110,  0.0072],\n",
      "        [-0.0291, -0.0289, -0.0110,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6056],\n",
      "        [0.6083]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0294, -0.0113,  0.0072],\n",
      "        [-0.0295, -0.0294, -0.0113,  0.0072]], device='cuda:0')\n",
      "after fc out tensor([[0.6633],\n",
      "        [0.6679],\n",
      "        [0.6648],\n",
      "        [0.6676],\n",
      "        [0.6738]], device='cuda:0')\n",
      "Epoch:  55. Loss: 0.0143. mean_squared_error.: 0.05890625715255737\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0294, -0.0112,  0.0071],\n",
      "        [-0.0295, -0.0294, -0.0113,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6670],\n",
      "        [0.6618],\n",
      "        [0.6694],\n",
      "        [0.6687],\n",
      "        [0.6710],\n",
      "        [0.6714],\n",
      "        [0.6691],\n",
      "        [0.6641]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6670],\n",
      "        [0.6618],\n",
      "        [0.6694],\n",
      "        [0.6687],\n",
      "        [0.6710],\n",
      "        [0.6714],\n",
      "        [0.6691],\n",
      "        [0.6641]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9000, 0.6000, 0.8750, 0.5000, 0.5500, 0.3750, 0.5000, 0.7500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0293, -0.0112,  0.0072],\n",
      "        [-0.0294, -0.0292, -0.0112,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6428],\n",
      "        [0.6425],\n",
      "        [0.6474],\n",
      "        [0.6400],\n",
      "        [0.6423],\n",
      "        [0.6406],\n",
      "        [0.6457],\n",
      "        [0.6495]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0293, -0.0112,  0.0071],\n",
      "        [-0.0295, -0.0293, -0.0112,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6609],\n",
      "        [0.6581],\n",
      "        [0.6599],\n",
      "        [0.6587],\n",
      "        [0.6602],\n",
      "        [0.6576],\n",
      "        [0.6604],\n",
      "        [0.6592]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0294, -0.0113,  0.0072],\n",
      "        [-0.0295, -0.0294, -0.0112,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6598],\n",
      "        [0.6602],\n",
      "        [0.6631],\n",
      "        [0.6607],\n",
      "        [0.6629],\n",
      "        [0.6652],\n",
      "        [0.6657],\n",
      "        [0.6622]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0292, -0.0111,  0.0073],\n",
      "        [-0.0293, -0.0291, -0.0111,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6305],\n",
      "        [0.6351],\n",
      "        [0.6308],\n",
      "        [0.6373],\n",
      "        [0.6316],\n",
      "        [0.6395],\n",
      "        [0.6345],\n",
      "        [0.6344]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0291, -0.0111,  0.0072],\n",
      "        [-0.0292, -0.0290, -0.0110,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6221],\n",
      "        [0.6245],\n",
      "        [0.6290],\n",
      "        [0.6230],\n",
      "        [0.6254],\n",
      "        [0.6250],\n",
      "        [0.6223],\n",
      "        [0.6249]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0291, -0.0111,  0.0072],\n",
      "        [-0.0292, -0.0291, -0.0111,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6211],\n",
      "        [0.6236]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0291, -0.0111,  0.0072],\n",
      "        [-0.0293, -0.0291, -0.0111,  0.0072]], device='cuda:0')\n",
      "after fc out tensor([[0.6274],\n",
      "        [0.6304],\n",
      "        [0.6282],\n",
      "        [0.6299],\n",
      "        [0.6331]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0290, -0.0111,  0.0072],\n",
      "        [-0.0293, -0.0291, -0.0111,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6310],\n",
      "        [0.6308],\n",
      "        [0.6273],\n",
      "        [0.6273],\n",
      "        [0.6298],\n",
      "        [0.6294],\n",
      "        [0.6302],\n",
      "        [0.6308]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6310],\n",
      "        [0.6308],\n",
      "        [0.6273],\n",
      "        [0.6273],\n",
      "        [0.6298],\n",
      "        [0.6294],\n",
      "        [0.6302],\n",
      "        [0.6308]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.5000, 0.4000, 0.5000, 0.6500, 0.6000, 0.6750, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0286, -0.0108,  0.0074],\n",
      "        [-0.0288, -0.0285, -0.0108,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5609],\n",
      "        [0.5617],\n",
      "        [0.5617],\n",
      "        [0.5651],\n",
      "        [0.5594],\n",
      "        [0.5618],\n",
      "        [0.5617],\n",
      "        [0.5604]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0297, -0.0113,  0.0071],\n",
      "        [-0.0297, -0.0297, -0.0113,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6904],\n",
      "        [0.6889],\n",
      "        [0.6899],\n",
      "        [0.6925],\n",
      "        [0.6913],\n",
      "        [0.6907],\n",
      "        [0.6882],\n",
      "        [0.6890]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0296, -0.0113,  0.0071],\n",
      "        [-0.0297, -0.0296, -0.0113,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6779],\n",
      "        [0.6791],\n",
      "        [0.6806],\n",
      "        [0.6792],\n",
      "        [0.6795],\n",
      "        [0.6794],\n",
      "        [0.6776],\n",
      "        [0.6820]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0286, -0.0107,  0.0072],\n",
      "        [-0.0289, -0.0286, -0.0107,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5714],\n",
      "        [0.5729],\n",
      "        [0.5613],\n",
      "        [0.5751],\n",
      "        [0.5670],\n",
      "        [0.5706],\n",
      "        [0.5664],\n",
      "        [0.5738]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0291, -0.0110,  0.0072],\n",
      "        [-0.0293, -0.0290, -0.0109,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6074],\n",
      "        [0.6183],\n",
      "        [0.6094],\n",
      "        [0.6061],\n",
      "        [0.6135],\n",
      "        [0.6092],\n",
      "        [0.6000],\n",
      "        [0.5991]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0293, -0.0111,  0.0071],\n",
      "        [-0.0296, -0.0294, -0.0111,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6587],\n",
      "        [0.6507]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0286, -0.0285, -0.0106,  0.0073],\n",
      "        [-0.0286, -0.0284, -0.0106,  0.0073]], device='cuda:0')\n",
      "after fc out tensor([[0.5451],\n",
      "        [0.5351],\n",
      "        [0.5394],\n",
      "        [0.5319],\n",
      "        [0.5113]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0287, -0.0282, -0.0106,  0.0073],\n",
      "        [-0.0286, -0.0283, -0.0106,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5305],\n",
      "        [0.5399],\n",
      "        [0.5386],\n",
      "        [0.5485],\n",
      "        [0.5171],\n",
      "        [0.5393],\n",
      "        [0.5210],\n",
      "        [0.5516]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5305],\n",
      "        [0.5399],\n",
      "        [0.5386],\n",
      "        [0.5485],\n",
      "        [0.5171],\n",
      "        [0.5393],\n",
      "        [0.5210],\n",
      "        [0.5516]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.4250, 0.6750, 0.9000, 0.4000, 0.3750, 0.5250, 0.6500, 0.7250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0287, -0.0107,  0.0073],\n",
      "        [-0.0288, -0.0285, -0.0107,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5711],\n",
      "        [0.5488],\n",
      "        [0.5475],\n",
      "        [0.5514],\n",
      "        [0.5674],\n",
      "        [0.5527],\n",
      "        [0.5532],\n",
      "        [0.5547]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0287, -0.0108,  0.0072],\n",
      "        [-0.0290, -0.0288, -0.0108,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5749],\n",
      "        [0.5914],\n",
      "        [0.5882],\n",
      "        [0.5928],\n",
      "        [0.5860],\n",
      "        [0.5827],\n",
      "        [0.5599],\n",
      "        [0.5904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0291, -0.0109,  0.0072],\n",
      "        [-0.0292, -0.0291, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6076],\n",
      "        [0.6111],\n",
      "        [0.5925],\n",
      "        [0.5970],\n",
      "        [0.5848],\n",
      "        [0.6097],\n",
      "        [0.5845],\n",
      "        [0.6052]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0290, -0.0110,  0.0072],\n",
      "        [-0.0293, -0.0292, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6086],\n",
      "        [0.6177],\n",
      "        [0.6116],\n",
      "        [0.6274],\n",
      "        [0.6199],\n",
      "        [0.6091],\n",
      "        [0.6290],\n",
      "        [0.6048]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0291, -0.0109,  0.0072],\n",
      "        [-0.0292, -0.0292, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6049],\n",
      "        [0.6175],\n",
      "        [0.6011],\n",
      "        [0.6247],\n",
      "        [0.6193],\n",
      "        [0.6034],\n",
      "        [0.6109],\n",
      "        [0.6163]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0292, -0.0109,  0.0072],\n",
      "        [-0.0292, -0.0293, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6062],\n",
      "        [0.6259]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0293, -0.0109,  0.0072],\n",
      "        [-0.0293, -0.0292, -0.0109,  0.0072]], device='cuda:0')\n",
      "after fc out tensor([[0.6216],\n",
      "        [0.6123],\n",
      "        [0.6163],\n",
      "        [0.6093],\n",
      "        [0.5898]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0292, -0.0109,  0.0072],\n",
      "        [-0.0293, -0.0292, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6074],\n",
      "        [0.6155],\n",
      "        [0.6251],\n",
      "        [0.6250],\n",
      "        [0.6096],\n",
      "        [0.6065],\n",
      "        [0.5961],\n",
      "        [0.6073]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6074],\n",
      "        [0.6155],\n",
      "        [0.6251],\n",
      "        [0.6250],\n",
      "        [0.6096],\n",
      "        [0.6065],\n",
      "        [0.5961],\n",
      "        [0.6073]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.2750, 0.6000, 0.5750, 0.5000, 0.5000, 0.7750, 0.6500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0289, -0.0288, -0.0107,  0.0072],\n",
      "        [-0.0289, -0.0286, -0.0108,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5713],\n",
      "        [0.5519],\n",
      "        [0.5632],\n",
      "        [0.5583],\n",
      "        [0.5743],\n",
      "        [0.5585],\n",
      "        [0.5730],\n",
      "        [0.5669]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0295, -0.0112,  0.0070],\n",
      "        [-0.0297, -0.0297, -0.0112,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6749],\n",
      "        [0.6733],\n",
      "        [0.6759],\n",
      "        [0.6733],\n",
      "        [0.6674],\n",
      "        [0.6677],\n",
      "        [0.6711],\n",
      "        [0.6668]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0295, -0.0110,  0.0071],\n",
      "        [-0.0295, -0.0292, -0.0110,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6394],\n",
      "        [0.6303],\n",
      "        [0.6390],\n",
      "        [0.6428],\n",
      "        [0.6399],\n",
      "        [0.6373],\n",
      "        [0.6372],\n",
      "        [0.6251]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0292, -0.0109,  0.0072],\n",
      "        [-0.0292, -0.0292, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6103],\n",
      "        [0.6102],\n",
      "        [0.6051],\n",
      "        [0.6062],\n",
      "        [0.6121],\n",
      "        [0.6078],\n",
      "        [0.6095],\n",
      "        [0.6031]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0292, -0.0109,  0.0072],\n",
      "        [-0.0292, -0.0292, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6089],\n",
      "        [0.6090],\n",
      "        [0.6069],\n",
      "        [0.6059],\n",
      "        [0.6133],\n",
      "        [0.6008],\n",
      "        [0.6132],\n",
      "        [0.6140]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0296, -0.0111,  0.0071],\n",
      "        [-0.0295, -0.0294, -0.0111,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6514],\n",
      "        [0.6412]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0297, -0.0111,  0.0071],\n",
      "        [-0.0296, -0.0296, -0.0111,  0.0071]], device='cuda:0')\n",
      "after fc out "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6605],\n",
      "        [0.6557],\n",
      "        [0.6575],\n",
      "        [0.6537],\n",
      "        [0.6425]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0295, -0.0111,  0.0071],\n",
      "        [-0.0296, -0.0295, -0.0111,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6503],\n",
      "        [0.6525],\n",
      "        [0.6578],\n",
      "        [0.6587],\n",
      "        [0.6499],\n",
      "        [0.6630],\n",
      "        [0.6592],\n",
      "        [0.6603]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6503],\n",
      "        [0.6525],\n",
      "        [0.6578],\n",
      "        [0.6587],\n",
      "        [0.6499],\n",
      "        [0.6630],\n",
      "        [0.6592],\n",
      "        [0.6603]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5500, 0.6000, 0.5250, 0.4250, 0.7000, 0.8000, 0.5750, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0293, -0.0109,  0.0072],\n",
      "        [-0.0292, -0.0292, -0.0109,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6131],\n",
      "        [0.6111],\n",
      "        [0.6132],\n",
      "        [0.6089],\n",
      "        [0.6133],\n",
      "        [0.6016],\n",
      "        [0.6116],\n",
      "        [0.6093]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0293, -0.0111,  0.0071],\n",
      "        [-0.0295, -0.0296, -0.0111,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6407],\n",
      "        [0.6473],\n",
      "        [0.6449],\n",
      "        [0.6437],\n",
      "        [0.6348],\n",
      "        [0.6461],\n",
      "        [0.6525],\n",
      "        [0.6483]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0291, -0.0110,  0.0071],\n",
      "        [-0.0293, -0.0292, -0.0110,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6036],\n",
      "        [0.6149],\n",
      "        [0.6124],\n",
      "        [0.6171],\n",
      "        [0.6307],\n",
      "        [0.6197],\n",
      "        [0.6094],\n",
      "        [0.6028]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0294, -0.0110,  0.0071],\n",
      "        [-0.0294, -0.0293, -0.0110,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6240],\n",
      "        [0.6350],\n",
      "        [0.6257],\n",
      "        [0.6377],\n",
      "        [0.6377],\n",
      "        [0.6302],\n",
      "        [0.6318],\n",
      "        [0.6229]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0293, -0.0110,  0.0071],\n",
      "        [-0.0294, -0.0294, -0.0110,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6190],\n",
      "        [0.6246],\n",
      "        [0.6251],\n",
      "        [0.6272],\n",
      "        [0.6323],\n",
      "        [0.6286],\n",
      "        [0.6178],\n",
      "        [0.6264]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0293, -0.0110,  0.0071],\n",
      "        [-0.0294, -0.0294, -0.0110,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6291],\n",
      "        [0.6215]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0294, -0.0110,  0.0071],\n",
      "        [-0.0294, -0.0294, -0.0110,  0.0071]], device='cuda:0')\n",
      "after fc out tensor([[0.6332],\n",
      "        [0.6265],\n",
      "        [0.6291],\n",
      "        [0.6240],\n",
      "        [0.6095]], device='cuda:0')\n",
      "Epoch:  60. Loss: 0.0016. mean_squared_error.: 0.050179578363895416\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0291, -0.0110,  0.0071],\n",
      "        [-0.0294, -0.0293, -0.0110,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6271],\n",
      "        [0.6263],\n",
      "        [0.6326],\n",
      "        [0.6140],\n",
      "        [0.6322],\n",
      "        [0.6375],\n",
      "        [0.6312],\n",
      "        [0.6383]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds tensor([[0.6271],\n",
      "        [0.6263],\n",
      "        [0.6326],\n",
      "        [0.6140],\n",
      "        [0.6322],\n",
      "        [0.6375],\n",
      "        [0.6312],\n",
      "        [0.6383]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.8000, 0.9000, 0.9500, 0.5750, 0.7500, 0.7250, 0.6750, 0.7000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0306, -0.0116,  0.0069],\n",
      "        [-0.0304, -0.0306, -0.0116,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7939],\n",
      "        [0.7964],\n",
      "        [0.8009],\n",
      "        [0.8109],\n",
      "        [0.7926],\n",
      "        [0.7775],\n",
      "        [0.7849],\n",
      "        [0.7789]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0293, -0.0109,  0.0071],\n",
      "        [-0.0294, -0.0294, -0.0109,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6056],\n",
      "        [0.6233],\n",
      "        [0.6066],\n",
      "        [0.5943],\n",
      "        [0.6230],\n",
      "        [0.6068],\n",
      "        [0.6033],\n",
      "        [0.6218]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0289, -0.0108,  0.0071],\n",
      "        [-0.0291, -0.0292, -0.0108,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5725],\n",
      "        [0.5802],\n",
      "        [0.5654],\n",
      "        [0.5830],\n",
      "        [0.5707],\n",
      "        [0.5809],\n",
      "        [0.5775],\n",
      "        [0.5748]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0289, -0.0107,  0.0072],\n",
      "        [-0.0291, -0.0289, -0.0107,  0.0072]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5652],\n",
      "        [0.5773],\n",
      "        [0.5781],\n",
      "        [0.5652],\n",
      "        [0.5611],\n",
      "        [0.5735],\n",
      "        [0.5638],\n",
      "        [0.5627]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0292, -0.0108,  0.0071],\n",
      "        [-0.0292, -0.0290, -0.0108,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5902],\n",
      "        [0.5858],\n",
      "        [0.5790],\n",
      "        [0.5909],\n",
      "        [0.5918],\n",
      "        [0.5891],\n",
      "        [0.5864],\n",
      "        [0.5895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0290, -0.0108,  0.0071],\n",
      "        [-0.0291, -0.0289, -0.0108,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5819],\n",
      "        [0.5766]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0299, -0.0111,  0.0070],\n",
      "        [-0.0297, -0.0298, -0.0111,  0.0070]], device='cuda:0')\n",
      "after fc out tensor([[0.6671],\n",
      "        [0.6588],\n",
      "        [0.6621],\n",
      "        [0.6559],\n",
      "        [0.6391]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0297, -0.0111,  0.0070],\n",
      "        [-0.0297, -0.0299, -0.0111,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6560],\n",
      "        [0.6721],\n",
      "        [0.6632],\n",
      "        [0.6615],\n",
      "        [0.6653],\n",
      "        [0.6642],\n",
      "        [0.6403],\n",
      "        [0.6505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6560],\n",
      "        [0.6721],\n",
      "        [0.6632],\n",
      "        [0.6615],\n",
      "        [0.6653],\n",
      "        [0.6642],\n",
      "        [0.6403],\n",
      "        [0.6505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.8500, 0.6750, 0.6750, 0.2750, 0.5500, 0.9250, 0.2750, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0296, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0297, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.6291],\n",
      "        [0.6380],\n",
      "        [0.6411],\n",
      "        [0.6315],\n",
      "        [0.6414],\n",
      "        [0.6346],\n",
      "        [0.6376],\n",
      "        [0.6252]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0293, -0.0110,  0.0071],\n",
      "        [-0.0295, -0.0293, -0.0110,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6167],\n",
      "        [0.6075],\n",
      "        [0.6176],\n",
      "        [0.6236],\n",
      "        [0.6305],\n",
      "        [0.6155],\n",
      "        [0.6300],\n",
      "        [0.6213]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0293, -0.0109,  0.0071],\n",
      "        [-0.0293, -0.0293, -0.0109,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5920],\n",
      "        [0.6000],\n",
      "        [0.5992],\n",
      "        [0.5944],\n",
      "        [0.5952],\n",
      "        [0.6046],\n",
      "        [0.5910],\n",
      "        [0.5985]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0297, -0.0110,  0.0071],\n",
      "        [-0.0295, -0.0295, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6332],\n",
      "        [0.6228],\n",
      "        [0.6299],\n",
      "        [0.6228],\n",
      "        [0.6291],\n",
      "        [0.6175],\n",
      "        [0.6327],\n",
      "        [0.6346]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0295, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0297, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6324],\n",
      "        [0.6379],\n",
      "        [0.6302],\n",
      "        [0.6368],\n",
      "        [0.6379],\n",
      "        [0.6355],\n",
      "        [0.6253],\n",
      "        [0.6392]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0296, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0296, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6281],\n",
      "        [0.6268]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0297, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0296, -0.0110,  0.0070]], device='cuda:0')\n",
      "after fc out tensor([[0.6350],\n",
      "        [0.6297],\n",
      "        [0.6315],\n",
      "        [0.6274],\n",
      "        [0.6161]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0296, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0294, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6309],\n",
      "        [0.6190],\n",
      "        [0.6234],\n",
      "        [0.6263],\n",
      "        [0.6313],\n",
      "        [0.6294],\n",
      "        [0.6264],\n",
      "        [0.6274]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6309],\n",
      "        [0.6190],\n",
      "        [0.6234],\n",
      "        [0.6263],\n",
      "        [0.6313],\n",
      "        [0.6294],\n",
      "        [0.6264],\n",
      "        [0.6274]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9000, 0.3750, 0.7000, 0.6000, 0.2750, 0.9000, 0.8750, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0297, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0297, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6385],\n",
      "        [0.6376],\n",
      "        [0.6381],\n",
      "        [0.6377],\n",
      "        [0.6369],\n",
      "        [0.6314],\n",
      "        [0.6357],\n",
      "        [0.6357]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0292, -0.0108,  0.0071],\n",
      "        [-0.0291, -0.0292, -0.0108,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5775],\n",
      "        [0.5777],\n",
      "        [0.5771],\n",
      "        [0.5728],\n",
      "        [0.5731],\n",
      "        [0.5736],\n",
      "        [0.5755],\n",
      "        [0.5779]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0300, -0.0113,  0.0069],\n",
      "        [-0.0299, -0.0303, -0.0112,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6864],\n",
      "        [0.6950],\n",
      "        [0.6864],\n",
      "        [0.6964],\n",
      "        [0.6906],\n",
      "        [0.7020],\n",
      "        [0.6775],\n",
      "        [0.7036]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0293, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0296, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6217],\n",
      "        [0.6312],\n",
      "        [0.6298],\n",
      "        [0.6109],\n",
      "        [0.6158],\n",
      "        [0.6236],\n",
      "        [0.6191],\n",
      "        [0.6262]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0297, -0.0110,  0.0070],\n",
      "        [-0.0295, -0.0296, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6227],\n",
      "        [0.6313],\n",
      "        [0.6208],\n",
      "        [0.6206],\n",
      "        [0.6145],\n",
      "        [0.6225],\n",
      "        [0.6266],\n",
      "        [0.6247]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0294, -0.0109,  0.0070],\n",
      "        [-0.0295, -0.0296, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6256],\n",
      "        [0.6220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0291, -0.0292, -0.0108,  0.0071],\n",
      "        [-0.0292, -0.0292, -0.0108,  0.0071]], device='cuda:0')\n",
      "after fc out tensor([[0.5783],\n",
      "        [0.5778],\n",
      "        [0.5773],\n",
      "        [0.5765],\n",
      "        [0.5743]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0291, -0.0108,  0.0071],\n",
      "        [-0.0291, -0.0293, -0.0108,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5772],\n",
      "        [0.5777],\n",
      "        [0.5792],\n",
      "        [0.5769],\n",
      "        [0.5786],\n",
      "        [0.5747],\n",
      "        [0.5786],\n",
      "        [0.5776]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5772],\n",
      "        [0.5777],\n",
      "        [0.5792],\n",
      "        [0.5769],\n",
      "        [0.5786],\n",
      "        [0.5747],\n",
      "        [0.5786],\n",
      "        [0.5776]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7250, 0.4250, 0.7000, 0.9000, 0.8000, 0.2750, 0.7500, 0.2750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0294, -0.0108,  0.0071],\n",
      "        [-0.0293, -0.0293, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5927],\n",
      "        [0.5904],\n",
      "        [0.5900],\n",
      "        [0.5908],\n",
      "        [0.5917],\n",
      "        [0.5915],\n",
      "        [0.5916],\n",
      "        [0.5929]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0294, -0.0109,  0.0070],\n",
      "        [-0.0294, -0.0295, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6050],\n",
      "        [0.6055],\n",
      "        [0.6047],\n",
      "        [0.6052],\n",
      "        [0.6036],\n",
      "        [0.6052],\n",
      "        [0.6050],\n",
      "        [0.6047]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0296, -0.0109,  0.0071],\n",
      "        [-0.0294, -0.0295, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6106],\n",
      "        [0.6105],\n",
      "        [0.6105],\n",
      "        [0.6112],\n",
      "        [0.6099],\n",
      "        [0.6101],\n",
      "        [0.6114],\n",
      "        [0.6089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0295, -0.0109,  0.0070],\n",
      "        [-0.0295, -0.0294, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6125],\n",
      "        [0.6120],\n",
      "        [0.6121],\n",
      "        [0.6102],\n",
      "        [0.6107],\n",
      "        [0.6104],\n",
      "        [0.6086],\n",
      "        [0.6098]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0294, -0.0109,  0.0070],\n",
      "        [-0.0294, -0.0295, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6070],\n",
      "        [0.6043],\n",
      "        [0.6044],\n",
      "        [0.6066],\n",
      "        [0.6064],\n",
      "        [0.6071],\n",
      "        [0.6081],\n",
      "        [0.6064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0295, -0.0109,  0.0070],\n",
      "        [-0.0295, -0.0294, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6109],\n",
      "        [0.6157]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0296, -0.0109,  0.0070],\n",
      "        [-0.0294, -0.0295, -0.0109,  0.0070]], device='cuda:0')\n",
      "after fc out tensor([[0.6149],\n",
      "        [0.6142],\n",
      "        [0.6138],\n",
      "        [0.6129],\n",
      "        [0.6103]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0294, -0.0109,  0.0070],\n",
      "        [-0.0294, -0.0295, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6163],\n",
      "        [0.6134],\n",
      "        [0.6136],\n",
      "        [0.6124],\n",
      "        [0.6152],\n",
      "        [0.6142],\n",
      "        [0.6140],\n",
      "        [0.6121]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6163],\n",
      "        [0.6134],\n",
      "        [0.6136],\n",
      "        [0.6124],\n",
      "        [0.6152],\n",
      "        [0.6142],\n",
      "        [0.6140],\n",
      "        [0.6121]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.9000, 0.7250, 0.6500, 0.8000, 0.5750, 0.6750, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0304, -0.0113,  0.0069],\n",
      "        [-0.0301, -0.0304, -0.0113,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7158],\n",
      "        [0.7204],\n",
      "        [0.7105],\n",
      "        [0.7177],\n",
      "        [0.7154],\n",
      "        [0.7157],\n",
      "        [0.7205],\n",
      "        [0.7196]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0295, -0.0109,  0.0070],\n",
      "        [-0.0295, -0.0295, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6051],\n",
      "        [0.6062],\n",
      "        [0.6077],\n",
      "        [0.6027],\n",
      "        [0.6028],\n",
      "        [0.6114],\n",
      "        [0.6018],\n",
      "        [0.6130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0298, -0.0110,  0.0069],\n",
      "        [-0.0297, -0.0299, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6476],\n",
      "        [0.6467],\n",
      "        [0.6485],\n",
      "        [0.6563],\n",
      "        [0.6445],\n",
      "        [0.6487],\n",
      "        [0.6417],\n",
      "        [0.6473]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0298, -0.0110,  0.0069],\n",
      "        [-0.0296, -0.0299, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6444],\n",
      "        [0.6324],\n",
      "        [0.6429],\n",
      "        [0.6473],\n",
      "        [0.6433],\n",
      "        [0.6387],\n",
      "        [0.6349],\n",
      "        [0.6460]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0290, -0.0289, -0.0106,  0.0071],\n",
      "        [-0.0290, -0.0290, -0.0106,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5470],\n",
      "        [0.5452],\n",
      "        [0.5444],\n",
      "        [0.5449],\n",
      "        [0.5430],\n",
      "        [0.5449],\n",
      "        [0.5460],\n",
      "        [0.5437]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0292, -0.0294, -0.0107,  0.0071],\n",
      "        [-0.0293, -0.0293, -0.0107,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5785],\n",
      "        [0.5795]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0298, -0.0109,  0.0070],\n",
      "        [-0.0296, -0.0298, -0.0109,  0.0070]], device='cuda:0')\n",
      "after fc out tensor([[0.6264],\n",
      "        [0.6252],\n",
      "        [0.6250],\n",
      "        [0.6238],\n",
      "        [0.6198]], device='cuda:0')\n",
      "Epoch:  65. Loss: 0.0675. mean_squared_error.: 0.04988405853509903\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0297, -0.0109,  0.0070],\n",
      "        [-0.0296, -0.0297, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6232],\n",
      "        [0.6270],\n",
      "        [0.6204],\n",
      "        [0.6205],\n",
      "        [0.6265],\n",
      "        [0.6246],\n",
      "        [0.6276],\n",
      "        [0.6256]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6232],\n",
      "        [0.6270],\n",
      "        [0.6204],\n",
      "        [0.6205],\n",
      "        [0.6265],\n",
      "        [0.6246],\n",
      "        [0.6276],\n",
      "        [0.6256]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5500, 0.9500, 0.2750, 0.3750, 0.5500, 0.4750, 0.9250, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0296, -0.0109,  0.0070],\n",
      "        [-0.0295, -0.0296, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6070],\n",
      "        [0.6072],\n",
      "        [0.6067],\n",
      "        [0.6081],\n",
      "        [0.6107],\n",
      "        [0.6068],\n",
      "        [0.6103],\n",
      "        [0.6127]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0295, -0.0108,  0.0070],\n",
      "        [-0.0293, -0.0296, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5893],\n",
      "        [0.5927],\n",
      "        [0.5870],\n",
      "        [0.5920],\n",
      "        [0.5950],\n",
      "        [0.5901],\n",
      "        [0.5884],\n",
      "        [0.5904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0296, -0.0109,  0.0070],\n",
      "        [-0.0295, -0.0295, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6070],\n",
      "        [0.6078],\n",
      "        [0.6101],\n",
      "        [0.6101],\n",
      "        [0.6116],\n",
      "        [0.6124],\n",
      "        [0.6089],\n",
      "        [0.6112]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0298, -0.0110,  0.0070],\n",
      "        [-0.0296, -0.0299, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6299],\n",
      "        [0.6337],\n",
      "        [0.6347],\n",
      "        [0.6336],\n",
      "        [0.6351],\n",
      "        [0.6273],\n",
      "        [0.6331],\n",
      "        [0.6347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0298, -0.0110,  0.0070],\n",
      "        [-0.0297, -0.0298, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6326],\n",
      "        [0.6276],\n",
      "        [0.6362],\n",
      "        [0.6362],\n",
      "        [0.6360],\n",
      "        [0.6309],\n",
      "        [0.6333],\n",
      "        [0.6300]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0297, -0.0109,  0.0070],\n",
      "        [-0.0296, -0.0299, -0.0109,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6253],\n",
      "        [0.6311]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0299, -0.0110,  0.0070],\n",
      "        [-0.0296, -0.0298, -0.0110,  0.0070]], device='cuda:0')\n",
      "after fc out tensor([[0.6344],\n",
      "        [0.6317],\n",
      "        [0.6323],\n",
      "        [0.6300],\n",
      "        [0.6234]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0299, -0.0110,  0.0070],\n",
      "        [-0.0297, -0.0298, -0.0110,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6369],\n",
      "        [0.6313],\n",
      "        [0.6347],\n",
      "        [0.6255],\n",
      "        [0.6362],\n",
      "        [0.6360],\n",
      "        [0.6241],\n",
      "        [0.6347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6369],\n",
      "        [0.6313],\n",
      "        [0.6347],\n",
      "        [0.6255],\n",
      "        [0.6362],\n",
      "        [0.6360],\n",
      "        [0.6241],\n",
      "        [0.6347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7000, 0.9000, 0.9250, 0.5750, 0.7000, 0.6750, 0.2750, 0.7500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0304, -0.0112,  0.0069],\n",
      "        [-0.0301, -0.0305, -0.0112,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7021],\n",
      "        [0.7050],\n",
      "        [0.7037],\n",
      "        [0.6987],\n",
      "        [0.6968],\n",
      "        [0.7000],\n",
      "        [0.7038],\n",
      "        [0.7020]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0295, -0.0107,  0.0070],\n",
      "        [-0.0292, -0.0295, -0.0107,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5806],\n",
      "        [0.5790],\n",
      "        [0.5813],\n",
      "        [0.5762],\n",
      "        [0.5779],\n",
      "        [0.5775],\n",
      "        [0.5802],\n",
      "        [0.5750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0299, -0.0109,  0.0070],\n",
      "        [-0.0297, -0.0296, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6197],\n",
      "        [0.6201],\n",
      "        [0.6194],\n",
      "        [0.6188],\n",
      "        [0.6196],\n",
      "        [0.6197],\n",
      "        [0.6204],\n",
      "        [0.6191]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0300, -0.0110,  0.0069],\n",
      "        [-0.0298, -0.0301, -0.0110,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6576],\n",
      "        [0.6523],\n",
      "        [0.6525],\n",
      "        [0.6552],\n",
      "        [0.6532],\n",
      "        [0.6529],\n",
      "        [0.6544],\n",
      "        [0.6564]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0300, -0.0110,  0.0069],\n",
      "        [-0.0298, -0.0301, -0.0110,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6473],\n",
      "        [0.6463],\n",
      "        [0.6463],\n",
      "        [0.6456],\n",
      "        [0.6476],\n",
      "        [0.6466],\n",
      "        [0.6451],\n",
      "        [0.6476]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0296, -0.0108,  0.0070],\n",
      "        [-0.0293, -0.0296, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5946],\n",
      "        [0.5916]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0288, -0.0289, -0.0105,  0.0071],\n",
      "        [-0.0288, -0.0289, -0.0105,  0.0071]], device='cuda:0')\n",
      "after fc out tensor([[0.5212],\n",
      "        [0.5257],\n",
      "        [0.5228],\n",
      "        [0.5256],\n",
      "        [0.5329]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0288, -0.0105,  0.0070],\n",
      "        [-0.0288, -0.0289, -0.0105,  0.0071]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5255],\n",
      "        [0.5249],\n",
      "        [0.5262],\n",
      "        [0.5218],\n",
      "        [0.5267],\n",
      "        [0.5238],\n",
      "        [0.5210],\n",
      "        [0.5248]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds tensor([[0.5255],\n",
      "        [0.5249],\n",
      "        [0.5262],\n",
      "        [0.5218],\n",
      "        [0.5267],\n",
      "        [0.5238],\n",
      "        [0.5210],\n",
      "        [0.5248]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9250, 0.6000, 0.5250, 0.5000, 0.6750, 0.5250, 0.7500, 0.9000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0296, -0.0108,  0.0070],\n",
      "        [-0.0294, -0.0296, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5904],\n",
      "        [0.5866],\n",
      "        [0.5856],\n",
      "        [0.5874],\n",
      "        [0.5898],\n",
      "        [0.5948],\n",
      "        [0.5935],\n",
      "        [0.5943]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0299, -0.0109,  0.0069],\n",
      "        [-0.0297, -0.0299, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6304],\n",
      "        [0.6297],\n",
      "        [0.6300],\n",
      "        [0.6289],\n",
      "        [0.6313],\n",
      "        [0.6307],\n",
      "        [0.6273],\n",
      "        [0.6315]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0297, -0.0109,  0.0069],\n",
      "        [-0.0296, -0.0297, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6153],\n",
      "        [0.6156],\n",
      "        [0.6138],\n",
      "        [0.6140],\n",
      "        [0.6140],\n",
      "        [0.6153],\n",
      "        [0.6141],\n",
      "        [0.6150]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0297, -0.0108,  0.0069],\n",
      "        [-0.0295, -0.0297, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6009],\n",
      "        [0.6004],\n",
      "        [0.5993],\n",
      "        [0.6022],\n",
      "        [0.6026],\n",
      "        [0.6002],\n",
      "        [0.6023],\n",
      "        [0.6015]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0298, -0.0108,  0.0070],\n",
      "        [-0.0296, -0.0297, -0.0108,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6063],\n",
      "        [0.6083],\n",
      "        [0.6048],\n",
      "        [0.6062],\n",
      "        [0.6076],\n",
      "        [0.6073],\n",
      "        [0.6044],\n",
      "        [0.6086]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0296, -0.0108,  0.0069],\n",
      "        [-0.0295, -0.0298, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6111],\n",
      "        [0.6071]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0298, -0.0108,  0.0070],\n",
      "        [-0.0295, -0.0298, -0.0108,  0.0070]], device='cuda:0')\n",
      "after fc out tensor([[0.6073],\n",
      "        [0.6091],\n",
      "        [0.6074],\n",
      "        [0.6083],\n",
      "        [0.6107]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0297, -0.0108,  0.0069],\n",
      "        [-0.0295, -0.0297, -0.0108,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6084],\n",
      "        [0.6082],\n",
      "        [0.6099],\n",
      "        [0.6070],\n",
      "        [0.6090],\n",
      "        [0.6079],\n",
      "        [0.6093],\n",
      "        [0.6070]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6084],\n",
      "        [0.6082],\n",
      "        [0.6099],\n",
      "        [0.6070],\n",
      "        [0.6090],\n",
      "        [0.6079],\n",
      "        [0.6093],\n",
      "        [0.6070]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9000, 0.7000, 0.6750, 0.5750, 0.6000, 0.7500, 0.3750, 0.6000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0301, -0.0110,  0.0069],\n",
      "        [-0.0299, -0.0301, -0.0110,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6549],\n",
      "        [0.6533],\n",
      "        [0.6554],\n",
      "        [0.6551],\n",
      "        [0.6539],\n",
      "        [0.6521],\n",
      "        [0.6514],\n",
      "        [0.6527]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0297, -0.0108,  0.0070],\n",
      "        [-0.0295, -0.0297, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5964],\n",
      "        [0.6005],\n",
      "        [0.5971],\n",
      "        [0.5941],\n",
      "        [0.5933],\n",
      "        [0.6000],\n",
      "        [0.6004],\n",
      "        [0.5965]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0300, -0.0109,  0.0069],\n",
      "        [-0.0297, -0.0300, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6261],\n",
      "        [0.6341],\n",
      "        [0.6326],\n",
      "        [0.6301],\n",
      "        [0.6417],\n",
      "        [0.6297],\n",
      "        [0.6250],\n",
      "        [0.6374]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0295, -0.0107,  0.0069],\n",
      "        [-0.0293, -0.0296, -0.0108,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5897],\n",
      "        [0.5817],\n",
      "        [0.5892],\n",
      "        [0.5853],\n",
      "        [0.5867],\n",
      "        [0.5865],\n",
      "        [0.5869],\n",
      "        [0.5840]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0299, -0.0109,  0.0068],\n",
      "        [-0.0298, -0.0300, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6319],\n",
      "        [0.6365],\n",
      "        [0.6296],\n",
      "        [0.6357],\n",
      "        [0.6435],\n",
      "        [0.6356],\n",
      "        [0.6209],\n",
      "        [0.6379]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0301, -0.0110,  0.0070],\n",
      "        [-0.0297, -0.0300, -0.0110,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6277],\n",
      "        [0.6340]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0304, -0.0111,  0.0069],\n",
      "        [-0.0300, -0.0303, -0.0111,  0.0069]], device='cuda:0')\n",
      "after fc out tensor([[0.6707],\n",
      "        [0.6735],\n",
      "        [0.6712],\n",
      "        [0.6728],\n",
      "        [0.6767]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0302, -0.0111,  0.0068],\n",
      "        [-0.0300, -0.0304, -0.0111,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6754],\n",
      "        [0.6702],\n",
      "        [0.6726],\n",
      "        [0.6700],\n",
      "        [0.6747],\n",
      "        [0.6724],\n",
      "        [0.6740],\n",
      "        [0.6746]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6754],\n",
      "        [0.6702],\n",
      "        [0.6726],\n",
      "        [0.6700],\n",
      "        [0.6747],\n",
      "        [0.6724],\n",
      "        [0.6740],\n",
      "        [0.6746]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7250, 0.7500, 0.9000, 0.6000, 0.9250, 0.5250, 0.6750, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0303, -0.0111,  0.0068],\n",
      "        [-0.0301, -0.0304, -0.0111,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6875],\n",
      "        [0.6844],\n",
      "        [0.6851],\n",
      "        [0.6838],\n",
      "        [0.6821],\n",
      "        [0.6855],\n",
      "        [0.6854],\n",
      "        [0.6825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0302, -0.0110,  0.0068],\n",
      "        [-0.0299, -0.0303, -0.0111,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6691],\n",
      "        [0.6619],\n",
      "        [0.6593],\n",
      "        [0.6618],\n",
      "        [0.6657],\n",
      "        [0.6603],\n",
      "        [0.6613],\n",
      "        [0.6643]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0299, -0.0109,  0.0069],\n",
      "        [-0.0296, -0.0299, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6227],\n",
      "        [0.6208],\n",
      "        [0.6237],\n",
      "        [0.6235],\n",
      "        [0.6237],\n",
      "        [0.6224],\n",
      "        [0.6186],\n",
      "        [0.6242]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0300, -0.0109,  0.0069],\n",
      "        [-0.0297, -0.0299, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6214],\n",
      "        [0.6206],\n",
      "        [0.6232],\n",
      "        [0.6245],\n",
      "        [0.6168],\n",
      "        [0.6200],\n",
      "        [0.6253],\n",
      "        [0.6307]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0300, -0.0109,  0.0069],\n",
      "        [-0.0297, -0.0300, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6265],\n",
      "        [0.6310],\n",
      "        [0.6278],\n",
      "        [0.6244],\n",
      "        [0.6353],\n",
      "        [0.6315],\n",
      "        [0.6334],\n",
      "        [0.6348]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0299, -0.0109,  0.0069],\n",
      "        [-0.0296, -0.0300, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6313],\n",
      "        [0.6240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0300, -0.0109,  0.0069],\n",
      "        [-0.0297, -0.0300, -0.0109,  0.0069]], device='cuda:0')\n",
      "after fc out tensor([[0.6214],\n",
      "        [0.6252],\n",
      "        [0.6225],\n",
      "        [0.6247],\n",
      "        [0.6303]], device='cuda:0')\n",
      "Epoch:  70. Loss: 0.0330. mean_squared_error.: 0.04987422376871109\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0300, -0.0109,  0.0069],\n",
      "        [-0.0298, -0.0299, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6222],\n",
      "        [0.6268],\n",
      "        [0.6259],\n",
      "        [0.6249],\n",
      "        [0.6248],\n",
      "        [0.6260],\n",
      "        [0.6193],\n",
      "        [0.6218]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6222],\n",
      "        [0.6268],\n",
      "        [0.6259],\n",
      "        [0.6249],\n",
      "        [0.6248],\n",
      "        [0.6260],\n",
      "        [0.6193],\n",
      "        [0.6218]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.4250, 0.5000, 0.6000, 0.5250, 0.6500, 0.5000, 0.8000, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0293, -0.0106,  0.0070],\n",
      "        [-0.0292, -0.0294, -0.0106,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5631],\n",
      "        [0.5612],\n",
      "        [0.5656],\n",
      "        [0.5627],\n",
      "        [0.5645],\n",
      "        [0.5586],\n",
      "        [0.5600],\n",
      "        [0.5638]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0301, -0.0109,  0.0069],\n",
      "        [-0.0298, -0.0301, -0.0109,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6320],\n",
      "        [0.6375],\n",
      "        [0.6308],\n",
      "        [0.6332],\n",
      "        [0.6365],\n",
      "        [0.6374],\n",
      "        [0.6339],\n",
      "        [0.6346]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0301, -0.0110,  0.0069],\n",
      "        [-0.0298, -0.0302, -0.0110,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6437],\n",
      "        [0.6418],\n",
      "        [0.6412],\n",
      "        [0.6439],\n",
      "        [0.6424],\n",
      "        [0.6454],\n",
      "        [0.6409],\n",
      "        [0.6455]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0312, -0.0115,  0.0067],\n",
      "        [-0.0308, -0.0312, -0.0115,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7891],\n",
      "        [0.7887],\n",
      "        [0.7919],\n",
      "        [0.7916],\n",
      "        [0.7921],\n",
      "        [0.7937],\n",
      "        [0.7884],\n",
      "        [0.7870]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0290, -0.0293, -0.0104,  0.0070],\n",
      "        [-0.0290, -0.0293, -0.0104,  0.0070]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5214],\n",
      "        [0.5185],\n",
      "        [0.5160],\n",
      "        [0.5240],\n",
      "        [0.5241],\n",
      "        [0.5222],\n",
      "        [0.5151],\n",
      "        [0.5182]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0296, -0.0106,  0.0069],\n",
      "        [-0.0293, -0.0297, -0.0106,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5555],\n",
      "        [0.5569]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0303, -0.0108,  0.0069],\n",
      "        [-0.0298, -0.0302, -0.0108,  0.0069]], device='cuda:0')\n",
      "after fc out tensor([[0.6141],\n",
      "        [0.6145],\n",
      "        [0.6136],\n",
      "        [0.6135],\n",
      "        [0.6137]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0301, -0.0108,  0.0068],\n",
      "        [-0.0298, -0.0303, -0.0108,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6134],\n",
      "        [0.6135],\n",
      "        [0.6150],\n",
      "        [0.6143],\n",
      "        [0.6143],\n",
      "        [0.6129],\n",
      "        [0.6143],\n",
      "        [0.6151]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6134],\n",
      "        [0.6135],\n",
      "        [0.6150],\n",
      "        [0.6143],\n",
      "        [0.6143],\n",
      "        [0.6129],\n",
      "        [0.6143],\n",
      "        [0.6151]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.7500, 0.6750, 0.5250, 0.6000, 0.7000, 0.7000, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0304, -0.0109,  0.0068],\n",
      "        [-0.0301, -0.0304, -0.0109,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6424],\n",
      "        [0.6452],\n",
      "        [0.6431],\n",
      "        [0.6442],\n",
      "        [0.6423],\n",
      "        [0.6431],\n",
      "        [0.6426],\n",
      "        [0.6436]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0300, -0.0107,  0.0068],\n",
      "        [-0.0298, -0.0300, -0.0107,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6012],\n",
      "        [0.6017],\n",
      "        [0.6025],\n",
      "        [0.6034],\n",
      "        [0.6030],\n",
      "        [0.6023],\n",
      "        [0.6028],\n",
      "        [0.6015]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0304, -0.0108,  0.0069],\n",
      "        [-0.0300, -0.0302, -0.0108,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6267],\n",
      "        [0.6265],\n",
      "        [0.6258],\n",
      "        [0.6266],\n",
      "        [0.6257],\n",
      "        [0.6265],\n",
      "        [0.6262],\n",
      "        [0.6271]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0302, -0.0108,  0.0069],\n",
      "        [-0.0297, -0.0303, -0.0108,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6091],\n",
      "        [0.6100],\n",
      "        [0.6091],\n",
      "        [0.6120],\n",
      "        [0.6082],\n",
      "        [0.6102],\n",
      "        [0.6110],\n",
      "        [0.6103]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0301, -0.0108,  0.0068],\n",
      "        [-0.0299, -0.0302, -0.0108,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6185],\n",
      "        [0.6177],\n",
      "        [0.6186],\n",
      "        [0.6178],\n",
      "        [0.6224],\n",
      "        [0.6204],\n",
      "        [0.6226],\n",
      "        [0.6192]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0304, -0.0108,  0.0069],\n",
      "        [-0.0299, -0.0304, -0.0108,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6257],\n",
      "        [0.6275]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0303, -0.0108,  0.0069],\n",
      "        [-0.0298, -0.0303, -0.0108,  0.0069]], device='cuda:0')\n",
      "after fc out tensor([[0.6198],\n",
      "        [0.6186],\n",
      "        [0.6185],\n",
      "        [0.6173],\n",
      "        [0.6147]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0301, -0.0108,  0.0068],\n",
      "        [-0.0298, -0.0304, -0.0108,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6209],\n",
      "        [0.6206],\n",
      "        [0.6180],\n",
      "        [0.6155],\n",
      "        [0.6215],\n",
      "        [0.6173],\n",
      "        [0.6158],\n",
      "        [0.6160]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6209],\n",
      "        [0.6206],\n",
      "        [0.6180],\n",
      "        [0.6155],\n",
      "        [0.6215],\n",
      "        [0.6173],\n",
      "        [0.6158],\n",
      "        [0.6160]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9250, 0.8000, 0.5000, 0.5750, 0.7000, 0.8500, 0.7000, 0.7750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0314, -0.0112,  0.0067],\n",
      "        [-0.0308, -0.0314, -0.0113,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7615],\n",
      "        [0.7601],\n",
      "        [0.7639],\n",
      "        [0.7629],\n",
      "        [0.7620],\n",
      "        [0.7607],\n",
      "        [0.7603],\n",
      "        [0.7577]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0293, -0.0297, -0.0105,  0.0069],\n",
      "        [-0.0293, -0.0297, -0.0105,  0.0069]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5480],\n",
      "        [0.5427],\n",
      "        [0.5425],\n",
      "        [0.5466],\n",
      "        [0.5242],\n",
      "        [0.5405],\n",
      "        [0.5469],\n",
      "        [0.5408]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0299, -0.0107,  0.0068],\n",
      "        [-0.0295, -0.0299, -0.0106,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5633],\n",
      "        [0.5751],\n",
      "        [0.5809],\n",
      "        [0.5711],\n",
      "        [0.5686],\n",
      "        [0.5634],\n",
      "        [0.5718],\n",
      "        [0.5671]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0313, -0.0111,  0.0066],\n",
      "        [-0.0305, -0.0312, -0.0111,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7132],\n",
      "        [0.6998],\n",
      "        [0.7091],\n",
      "        [0.7009],\n",
      "        [0.7221],\n",
      "        [0.6916],\n",
      "        [0.7174],\n",
      "        [0.7095]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0294, -0.0297, -0.0105,  0.0068],\n",
      "        [-0.0293, -0.0300, -0.0104,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5373],\n",
      "        [0.5439],\n",
      "        [0.5297],\n",
      "        [0.5494],\n",
      "        [0.5245],\n",
      "        [0.5311],\n",
      "        [0.5388],\n",
      "        [0.5391]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0298, -0.0106,  0.0068],\n",
      "        [-0.0295, -0.0302, -0.0105,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5537],\n",
      "        [0.5629]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0310, -0.0108,  0.0067],\n",
      "        [-0.0302, -0.0309, -0.0108,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.6480],\n",
      "        [0.6421],\n",
      "        [0.6440],\n",
      "        [0.6396],\n",
      "        [0.6295]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0306, -0.0109,  0.0067],\n",
      "        [-0.0302, -0.0308, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6380],\n",
      "        [0.6417],\n",
      "        [0.6385],\n",
      "        [0.6505],\n",
      "        [0.6385],\n",
      "        [0.6402],\n",
      "        [0.6518],\n",
      "        [0.6425]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6380],\n",
      "        [0.6417],\n",
      "        [0.6385],\n",
      "        [0.6505],\n",
      "        [0.6385],\n",
      "        [0.6402],\n",
      "        [0.6518],\n",
      "        [0.6425]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7250, 0.9000, 0.6000, 0.6000, 0.5000, 0.5000, 0.7000, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0309, -0.0108,  0.0067],\n",
      "        [-0.0302, -0.0309, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6428],\n",
      "        [0.6480],\n",
      "        [0.6503],\n",
      "        [0.6448],\n",
      "        [0.6572],\n",
      "        [0.6474],\n",
      "        [0.6553],\n",
      "        [0.6557]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0306, -0.0108,  0.0067],\n",
      "        [-0.0300, -0.0308, -0.0107,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6321],\n",
      "        [0.6292],\n",
      "        [0.6191],\n",
      "        [0.6324],\n",
      "        [0.6213],\n",
      "        [0.6287],\n",
      "        [0.6218],\n",
      "        [0.6245]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0305, -0.0107,  0.0068],\n",
      "        [-0.0300, -0.0306, -0.0107,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6085],\n",
      "        [0.6087],\n",
      "        [0.6132],\n",
      "        [0.6128],\n",
      "        [0.6088],\n",
      "        [0.6097],\n",
      "        [0.6137],\n",
      "        [0.6132]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0305, -0.0107,  0.0068],\n",
      "        [-0.0300, -0.0306, -0.0107,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6105],\n",
      "        [0.6172],\n",
      "        [0.6189],\n",
      "        [0.6165],\n",
      "        [0.6117],\n",
      "        [0.6101],\n",
      "        [0.6139],\n",
      "        [0.6171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0307, -0.0108,  0.0067],\n",
      "        [-0.0301, -0.0308, -0.0108,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6298],\n",
      "        [0.6263],\n",
      "        [0.6208],\n",
      "        [0.6275],\n",
      "        [0.6231],\n",
      "        [0.6203],\n",
      "        [0.6271],\n",
      "        [0.6194]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0305, -0.0108,  0.0067],\n",
      "        [-0.0301, -0.0304, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6222],\n",
      "        [0.6231]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0308, -0.0107,  0.0068],\n",
      "        [-0.0301, -0.0308, -0.0108,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.6287],\n",
      "        [0.6251],\n",
      "        [0.6259],\n",
      "        [0.6232],\n",
      "        [0.6172]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0306, -0.0108,  0.0067],\n",
      "        [-0.0300, -0.0308, -0.0108,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6209],\n",
      "        [0.6281],\n",
      "        [0.6303],\n",
      "        [0.6282],\n",
      "        [0.6204],\n",
      "        [0.6289],\n",
      "        [0.6311],\n",
      "        [0.6220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6209],\n",
      "        [0.6281],\n",
      "        [0.6303],\n",
      "        [0.6282],\n",
      "        [0.6204],\n",
      "        [0.6289],\n",
      "        [0.6311],\n",
      "        [0.6220]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.5500, 0.6000, 0.4250, 0.7000, 0.7500, 0.5750, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0305, -0.0106,  0.0068],\n",
      "        [-0.0298, -0.0304, -0.0107,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5966],\n",
      "        [0.5948],\n",
      "        [0.5913],\n",
      "        [0.5942],\n",
      "        [0.5912],\n",
      "        [0.5909],\n",
      "        [0.5934],\n",
      "        [0.5889]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0305, -0.0311, -0.0110,  0.0067],\n",
      "        [-0.0305, -0.0312, -0.0110,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6823],\n",
      "        [0.6809],\n",
      "        [0.6828],\n",
      "        [0.6819],\n",
      "        [0.6816],\n",
      "        [0.6819],\n",
      "        [0.6821],\n",
      "        [0.6820]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0305, -0.0105,  0.0067],\n",
      "        [-0.0296, -0.0301, -0.0106,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5779],\n",
      "        [0.5626],\n",
      "        [0.5657],\n",
      "        [0.5763],\n",
      "        [0.5783],\n",
      "        [0.5655],\n",
      "        [0.5574],\n",
      "        [0.5700]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0308, -0.0110,  0.0068],\n",
      "        [-0.0304, -0.0314, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6278],\n",
      "        [0.6688],\n",
      "        [0.6632],\n",
      "        [0.6548],\n",
      "        [0.6626],\n",
      "        [0.6575],\n",
      "        [0.6474],\n",
      "        [0.6521]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0305, -0.0104,  0.0067],\n",
      "        [-0.0296, -0.0303, -0.0105,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5899],\n",
      "        [0.5684],\n",
      "        [0.5768],\n",
      "        [0.5915],\n",
      "        [0.5531],\n",
      "        [0.5514],\n",
      "        [0.5377],\n",
      "        [0.5704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0303, -0.0109,  0.0068],\n",
      "        [-0.0301, -0.0309, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6331],\n",
      "        [0.6102]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0317, -0.0109,  0.0066],\n",
      "        [-0.0307, -0.0316, -0.0109,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.7182],\n",
      "        [0.6991],\n",
      "        [0.7075],\n",
      "        [0.6938],\n",
      "        [0.6598]], device='cuda:0')\n",
      "Epoch:  75. Loss: 0.0508. mean_squared_error.: 0.06795552372932434\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0316, -0.0109,  0.0067],\n",
      "        [-0.0307, -0.0318, -0.0109,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6966],\n",
      "        [0.7255],\n",
      "        [0.6909],\n",
      "        [0.7295],\n",
      "        [0.6856],\n",
      "        [0.7162],\n",
      "        [0.7249],\n",
      "        [0.6825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6966],\n",
      "        [0.7255],\n",
      "        [0.6909],\n",
      "        [0.7295],\n",
      "        [0.6856],\n",
      "        [0.7162],\n",
      "        [0.7249],\n",
      "        [0.6825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6000, 0.6000, 0.4250, 0.7000, 0.7250, 0.7500, 0.5750, 0.7000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0308, -0.0109,  0.0067],\n",
      "        [-0.0303, -0.0309, -0.0109,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6473],\n",
      "        [0.6265],\n",
      "        [0.6410],\n",
      "        [0.6447],\n",
      "        [0.6539],\n",
      "        [0.6596],\n",
      "        [0.6352],\n",
      "        [0.6489]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0311, -0.0111,  0.0067],\n",
      "        [-0.0307, -0.0316, -0.0109,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6962],\n",
      "        [0.6993],\n",
      "        [0.6988],\n",
      "        [0.6918],\n",
      "        [0.6881],\n",
      "        [0.7181],\n",
      "        [0.6890],\n",
      "        [0.6870]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0309, -0.0109,  0.0067],\n",
      "        [-0.0304, -0.0312, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6293],\n",
      "        [0.6441],\n",
      "        [0.6583],\n",
      "        [0.6686],\n",
      "        [0.6461],\n",
      "        [0.6562],\n",
      "        [0.6530],\n",
      "        [0.6417]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0311, -0.0106,  0.0067],\n",
      "        [-0.0301, -0.0309, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6411],\n",
      "        [0.6265],\n",
      "        [0.6135],\n",
      "        [0.6273],\n",
      "        [0.6296],\n",
      "        [0.6295],\n",
      "        [0.6400],\n",
      "        [0.6000]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0310, -0.0107,  0.0067],\n",
      "        [-0.0301, -0.0306, -0.0108,  0.0068]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6190],\n",
      "        [0.6099],\n",
      "        [0.6363],\n",
      "        [0.6447],\n",
      "        [0.6332],\n",
      "        [0.6322],\n",
      "        [0.6378],\n",
      "        [0.6375]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0307, -0.0108,  0.0067],\n",
      "        [-0.0302, -0.0310, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6065],\n",
      "        [0.6314]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0311, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0310, -0.0107,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.6369],\n",
      "        [0.6245],\n",
      "        [0.6296],\n",
      "        [0.6206],\n",
      "        [0.5983]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0310, -0.0107,  0.0067],\n",
      "        [-0.0301, -0.0307, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6309],\n",
      "        [0.6191],\n",
      "        [0.6323],\n",
      "        [0.6340],\n",
      "        [0.6161],\n",
      "        [0.6178],\n",
      "        [0.6207],\n",
      "        [0.6210]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6309],\n",
      "        [0.6191],\n",
      "        [0.6323],\n",
      "        [0.6340],\n",
      "        [0.6161],\n",
      "        [0.6178],\n",
      "        [0.6207],\n",
      "        [0.6210]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6250, 0.4250, 0.4250, 0.5500, 0.5000, 0.8750, 0.8500, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0304, -0.0107,  0.0068],\n",
      "        [-0.0299, -0.0309, -0.0105,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5839],\n",
      "        [0.6111],\n",
      "        [0.5796],\n",
      "        [0.5798],\n",
      "        [0.6094],\n",
      "        [0.6074],\n",
      "        [0.5712],\n",
      "        [0.6024]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0309, -0.0108,  0.0067],\n",
      "        [-0.0303, -0.0311, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6415],\n",
      "        [0.6586],\n",
      "        [0.6308],\n",
      "        [0.6243],\n",
      "        [0.6278],\n",
      "        [0.6197],\n",
      "        [0.6588],\n",
      "        [0.6349]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0305, -0.0108,  0.0067],\n",
      "        [-0.0301, -0.0306, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6107],\n",
      "        [0.5940],\n",
      "        [0.6140],\n",
      "        [0.6236],\n",
      "        [0.6172],\n",
      "        [0.6196],\n",
      "        [0.6090],\n",
      "        [0.6124]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0305, -0.0105,  0.0067],\n",
      "        [-0.0297, -0.0305, -0.0105,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5666],\n",
      "        [0.5824],\n",
      "        [0.5724],\n",
      "        [0.5640],\n",
      "        [0.5747],\n",
      "        [0.5640],\n",
      "        [0.5639],\n",
      "        [0.5703]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0310, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0310, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6262],\n",
      "        [0.6263],\n",
      "        [0.6170],\n",
      "        [0.6315],\n",
      "        [0.6234],\n",
      "        [0.6361],\n",
      "        [0.6175],\n",
      "        [0.6297]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0316, -0.0108,  0.0066],\n",
      "        [-0.0306, -0.0311, -0.0110,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6854],\n",
      "        [0.6861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0318, -0.0109,  0.0066],\n",
      "        [-0.0307, -0.0317, -0.0110,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.7149],\n",
      "        [0.7030],\n",
      "        [0.7079],\n",
      "        [0.6993],\n",
      "        [0.6780]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0315, -0.0110,  0.0067],\n",
      "        [-0.0307, -0.0316, -0.0110,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7030],\n",
      "        [0.7080],\n",
      "        [0.7092],\n",
      "        [0.6795],\n",
      "        [0.7146],\n",
      "        [0.7121],\n",
      "        [0.7246],\n",
      "        [0.7099]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.7030],\n",
      "        [0.7080],\n",
      "        [0.7092],\n",
      "        [0.6795],\n",
      "        [0.7146],\n",
      "        [0.7121],\n",
      "        [0.7246],\n",
      "        [0.7099]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9000, 0.5250, 0.6250, 0.2750, 0.7500, 0.5750, 0.7000, 0.9250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0305, -0.0315, -0.0108,  0.0066],\n",
      "        [-0.0305, -0.0310, -0.0110,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6833],\n",
      "        [0.6686],\n",
      "        [0.6651],\n",
      "        [0.6805],\n",
      "        [0.6826],\n",
      "        [0.6683],\n",
      "        [0.6824],\n",
      "        [0.6535]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0313, -0.0108,  0.0067],\n",
      "        [-0.0304, -0.0312, -0.0109,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6572],\n",
      "        [0.6546],\n",
      "        [0.6528],\n",
      "        [0.6544],\n",
      "        [0.6661],\n",
      "        [0.6665],\n",
      "        [0.6456],\n",
      "        [0.6556]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0311, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0310, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6346],\n",
      "        [0.6291],\n",
      "        [0.6239],\n",
      "        [0.6261],\n",
      "        [0.6239],\n",
      "        [0.6270],\n",
      "        [0.6272],\n",
      "        [0.6364]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0311, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0310, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6241],\n",
      "        [0.6204],\n",
      "        [0.6333],\n",
      "        [0.6282],\n",
      "        [0.6310],\n",
      "        [0.6150],\n",
      "        [0.6241],\n",
      "        [0.6349]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0312, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0311, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6406],\n",
      "        [0.6312],\n",
      "        [0.6339],\n",
      "        [0.6228],\n",
      "        [0.6310],\n",
      "        [0.6353],\n",
      "        [0.6409],\n",
      "        [0.6419]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0311, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0307, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6334],\n",
      "        [0.6166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0311, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0311, -0.0107,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.6366],\n",
      "        [0.6286],\n",
      "        [0.6316],\n",
      "        [0.6256],\n",
      "        [0.6111]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0312, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0311, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6364],\n",
      "        [0.6353],\n",
      "        [0.6307],\n",
      "        [0.6257],\n",
      "        [0.6207],\n",
      "        [0.6188],\n",
      "        [0.6239],\n",
      "        [0.6305]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6364],\n",
      "        [0.6353],\n",
      "        [0.6307],\n",
      "        [0.6257],\n",
      "        [0.6207],\n",
      "        [0.6188],\n",
      "        [0.6239],\n",
      "        [0.6305]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.4250, 0.7500, 0.4750, 0.8500, 0.5500, 0.6500, 0.6500, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0309, -0.0107,  0.0067],\n",
      "        [-0.0301, -0.0309, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6080],\n",
      "        [0.6096],\n",
      "        [0.6277],\n",
      "        [0.6176],\n",
      "        [0.6191],\n",
      "        [0.6208],\n",
      "        [0.6123],\n",
      "        [0.6118]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0312, -0.0108,  0.0067],\n",
      "        [-0.0303, -0.0312, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6418],\n",
      "        [0.6415],\n",
      "        [0.6315],\n",
      "        [0.6350],\n",
      "        [0.6347],\n",
      "        [0.6272],\n",
      "        [0.6435],\n",
      "        [0.6450]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0308, -0.0108,  0.0067],\n",
      "        [-0.0303, -0.0311, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6405],\n",
      "        [0.6391],\n",
      "        [0.6478],\n",
      "        [0.6316],\n",
      "        [0.6326],\n",
      "        [0.6351],\n",
      "        [0.6212],\n",
      "        [0.6353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0306, -0.0315, -0.0109,  0.0067],\n",
      "        [-0.0306, -0.0313, -0.0110,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6912],\n",
      "        [0.6940],\n",
      "        [0.6862],\n",
      "        [0.6888],\n",
      "        [0.6767],\n",
      "        [0.6879],\n",
      "        [0.6933],\n",
      "        [0.6946]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0306, -0.0106,  0.0067],\n",
      "        [-0.0300, -0.0307, -0.0106,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5919],\n",
      "        [0.5906],\n",
      "        [0.5901],\n",
      "        [0.5910],\n",
      "        [0.5904],\n",
      "        [0.5914],\n",
      "        [0.5890],\n",
      "        [0.5918]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0298, -0.0307, -0.0106,  0.0067],\n",
      "        [-0.0300, -0.0306, -0.0106,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5819],\n",
      "        [0.5830]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0313, -0.0108,  0.0067],\n",
      "        [-0.0304, -0.0313, -0.0108,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.6478],\n",
      "        [0.6467],\n",
      "        [0.6464],\n",
      "        [0.6453],\n",
      "        [0.6436]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0311, -0.0108,  0.0066],\n",
      "        [-0.0304, -0.0312, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6460],\n",
      "        [0.6471],\n",
      "        [0.6462],\n",
      "        [0.6461],\n",
      "        [0.6453],\n",
      "        [0.6465],\n",
      "        [0.6479],\n",
      "        [0.6476]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6460],\n",
      "        [0.6471],\n",
      "        [0.6462],\n",
      "        [0.6461],\n",
      "        [0.6453],\n",
      "        [0.6465],\n",
      "        [0.6479],\n",
      "        [0.6476]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7250, 0.5250, 0.4250, 0.9000, 0.5500, 0.6500, 0.5500, 0.8000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0313, -0.0108,  0.0067],\n",
      "        [-0.0304, -0.0312, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6449],\n",
      "        [0.6444],\n",
      "        [0.6459],\n",
      "        [0.6431],\n",
      "        [0.6416],\n",
      "        [0.6453],\n",
      "        [0.6431],\n",
      "        [0.6430]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0312, -0.0108,  0.0067],\n",
      "        [-0.0303, -0.0314, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6478],\n",
      "        [0.6461],\n",
      "        [0.6452],\n",
      "        [0.6473],\n",
      "        [0.6433],\n",
      "        [0.6448],\n",
      "        [0.6431],\n",
      "        [0.6456]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0313, -0.0108,  0.0067],\n",
      "        [-0.0305, -0.0312, -0.0108,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6552],\n",
      "        [0.6546],\n",
      "        [0.6539],\n",
      "        [0.6576],\n",
      "        [0.6598],\n",
      "        [0.6558],\n",
      "        [0.6578],\n",
      "        [0.6560]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0305, -0.0312, -0.0108,  0.0066],\n",
      "        [-0.0305, -0.0312, -0.0108,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6527],\n",
      "        [0.6506],\n",
      "        [0.6513],\n",
      "        [0.6557],\n",
      "        [0.6555],\n",
      "        [0.6531],\n",
      "        [0.6540],\n",
      "        [0.6543]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0313, -0.0107,  0.0067],\n",
      "        [-0.0303, -0.0310, -0.0108,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6406],\n",
      "        [0.6407],\n",
      "        [0.6406],\n",
      "        [0.6325],\n",
      "        [0.6402],\n",
      "        [0.6360],\n",
      "        [0.6338],\n",
      "        [0.6340]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0313, -0.0107,  0.0067],\n",
      "        [-0.0303, -0.0312, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6414],\n",
      "        [0.6377]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0312, -0.0107,  0.0067],\n",
      "        [-0.0303, -0.0311, -0.0107,  0.0067]], device='cuda:0')\n",
      "after fc out tensor([[0.6345],\n",
      "        [0.6326],\n",
      "        [0.6327],\n",
      "        [0.6310],\n",
      "        [0.6277]], device='cuda:0')\n",
      "Epoch:  80. Loss: 0.0671. mean_squared_error.: 0.05126158148050308\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0311, -0.0107,  0.0067],\n",
      "        [-0.0302, -0.0312, -0.0107,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6334],\n",
      "        [0.6340],\n",
      "        [0.6318],\n",
      "        [0.6333],\n",
      "        [0.6280],\n",
      "        [0.6333],\n",
      "        [0.6313],\n",
      "        [0.6306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6334],\n",
      "        [0.6340],\n",
      "        [0.6318],\n",
      "        [0.6333],\n",
      "        [0.6280],\n",
      "        [0.6333],\n",
      "        [0.6313],\n",
      "        [0.6306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5250, 0.4250, 0.5000, 0.6250, 0.3750, 0.6750, 0.7250, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0303, -0.0104,  0.0067],\n",
      "        [-0.0296, -0.0303, -0.0104,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5407],\n",
      "        [0.5361],\n",
      "        [0.5383],\n",
      "        [0.5334],\n",
      "        [0.5407],\n",
      "        [0.5378],\n",
      "        [0.5365],\n",
      "        [0.5383]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0307, -0.0106,  0.0066],\n",
      "        [-0.0300, -0.0308, -0.0106,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5914],\n",
      "        [0.5895],\n",
      "        [0.5894],\n",
      "        [0.5914],\n",
      "        [0.5892],\n",
      "        [0.5897],\n",
      "        [0.5909],\n",
      "        [0.5919]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0323, -0.0110,  0.0066],\n",
      "        [-0.0310, -0.0318, -0.0111,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7546],\n",
      "        [0.7255],\n",
      "        [0.7521],\n",
      "        [0.7376],\n",
      "        [0.7345],\n",
      "        [0.7518],\n",
      "        [0.7451],\n",
      "        [0.7474]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0314, -0.0107,  0.0066],\n",
      "        [-0.0303, -0.0313, -0.0107,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6340],\n",
      "        [0.6358],\n",
      "        [0.6379],\n",
      "        [0.6339],\n",
      "        [0.6363],\n",
      "        [0.6301],\n",
      "        [0.6348],\n",
      "        [0.6329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0306, -0.0106,  0.0066],\n",
      "        [-0.0300, -0.0306, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5776],\n",
      "        [0.5765],\n",
      "        [0.5762],\n",
      "        [0.5761],\n",
      "        [0.5759],\n",
      "        [0.5751],\n",
      "        [0.5748],\n",
      "        [0.5751]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0314, -0.0108,  0.0066],\n",
      "        [-0.0304, -0.0315, -0.0108,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6564],\n",
      "        [0.6484]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0309, -0.0106,  0.0066],\n",
      "        [-0.0300, -0.0309, -0.0106,  0.0066]], device='cuda:0')\n",
      "after fc out tensor([[0.5811],\n",
      "        [0.5830],\n",
      "        [0.5813],\n",
      "        [0.5823],\n",
      "        [0.5860]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0308, -0.0106,  0.0066],\n",
      "        [-0.0301, -0.0308, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5832],\n",
      "        [0.5837],\n",
      "        [0.5810],\n",
      "        [0.5830],\n",
      "        [0.5801],\n",
      "        [0.5803],\n",
      "        [0.5838],\n",
      "        [0.5808]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5832],\n",
      "        [0.5837],\n",
      "        [0.5810],\n",
      "        [0.5830],\n",
      "        [0.5801],\n",
      "        [0.5803],\n",
      "        [0.5838],\n",
      "        [0.5808]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.4250, 0.4750, 0.5000, 0.7250, 0.6750, 0.8000, 0.6000],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0311, -0.0106,  0.0066],\n",
      "        [-0.0301, -0.0310, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5959],\n",
      "        [0.5959],\n",
      "        [0.5958],\n",
      "        [0.5961],\n",
      "        [0.5995],\n",
      "        [0.5963],\n",
      "        [0.5966],\n",
      "        [0.5960]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0310, -0.0107,  0.0066],\n",
      "        [-0.0302, -0.0311, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6087],\n",
      "        [0.6080],\n",
      "        [0.6081],\n",
      "        [0.6088],\n",
      "        [0.6085],\n",
      "        [0.6077],\n",
      "        [0.6103],\n",
      "        [0.6093]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0311, -0.0106,  0.0066],\n",
      "        [-0.0301, -0.0311, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5984],\n",
      "        [0.5984],\n",
      "        [0.5993],\n",
      "        [0.5991],\n",
      "        [0.5976],\n",
      "        [0.5977],\n",
      "        [0.5988],\n",
      "        [0.5988]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0309, -0.0106,  0.0066],\n",
      "        [-0.0301, -0.0309, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5894],\n",
      "        [0.5888],\n",
      "        [0.5891],\n",
      "        [0.5891],\n",
      "        [0.5896],\n",
      "        [0.5898],\n",
      "        [0.5883],\n",
      "        [0.5894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0309, -0.0106,  0.0066],\n",
      "        [-0.0302, -0.0310, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6035],\n",
      "        [0.6020],\n",
      "        [0.6013],\n",
      "        [0.6054],\n",
      "        [0.6033],\n",
      "        [0.6040],\n",
      "        [0.6021],\n",
      "        [0.6018]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0311, -0.0106,  0.0066],\n",
      "        [-0.0302, -0.0311, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6083],\n",
      "        [0.6080]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0312, -0.0106,  0.0066],\n",
      "        [-0.0302, -0.0312, -0.0106,  0.0066]], device='cuda:0')\n",
      "after fc out tensor([[0.6098],\n",
      "        [0.6115],\n",
      "        [0.6099],\n",
      "        [0.6108],\n",
      "        [0.6144]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0311, -0.0107,  0.0066],\n",
      "        [-0.0303, -0.0311, -0.0107,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6116],\n",
      "        [0.6118],\n",
      "        [0.6123],\n",
      "        [0.6095],\n",
      "        [0.6122],\n",
      "        [0.6122],\n",
      "        [0.6139],\n",
      "        [0.6090]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6116],\n",
      "        [0.6118],\n",
      "        [0.6123],\n",
      "        [0.6095],\n",
      "        [0.6122],\n",
      "        [0.6122],\n",
      "        [0.6139],\n",
      "        [0.6090]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.6750, 0.5000, 0.6000, 0.6750, 0.4250, 0.7750, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0312, -0.0107,  0.0066],\n",
      "        [-0.0304, -0.0313, -0.0107,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6269],\n",
      "        [0.6275],\n",
      "        [0.6279],\n",
      "        [0.6279],\n",
      "        [0.6278],\n",
      "        [0.6282],\n",
      "        [0.6262],\n",
      "        [0.6270]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0315, -0.0108,  0.0066],\n",
      "        [-0.0307, -0.0315, -0.0108,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6638],\n",
      "        [0.6657],\n",
      "        [0.6603],\n",
      "        [0.6589],\n",
      "        [0.6607],\n",
      "        [0.6553],\n",
      "        [0.6584],\n",
      "        [0.6574]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0309, -0.0105,  0.0066],\n",
      "        [-0.0300, -0.0308, -0.0105,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5757],\n",
      "        [0.5771],\n",
      "        [0.5789],\n",
      "        [0.5770],\n",
      "        [0.5780],\n",
      "        [0.5753],\n",
      "        [0.5756],\n",
      "        [0.5780]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0320, -0.0109,  0.0066],\n",
      "        [-0.0308, -0.0320, -0.0109,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6960],\n",
      "        [0.6952],\n",
      "        [0.6971],\n",
      "        [0.6926],\n",
      "        [0.6968],\n",
      "        [0.6926],\n",
      "        [0.6933],\n",
      "        [0.7005]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0299, -0.0310, -0.0105,  0.0066],\n",
      "        [-0.0300, -0.0308, -0.0105,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5758],\n",
      "        [0.5689],\n",
      "        [0.5725],\n",
      "        [0.5691],\n",
      "        [0.5754],\n",
      "        [0.5736],\n",
      "        [0.5718],\n",
      "        [0.5735]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0313, -0.0106,  0.0066],\n",
      "        [-0.0302, -0.0314, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6102],\n",
      "        [0.6096]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0312, -0.0106,  0.0066],\n",
      "        [-0.0302, -0.0312, -0.0106,  0.0066]], device='cuda:0')\n",
      "after fc out tensor([[0.6011],\n",
      "        [0.6017],\n",
      "        [0.6006],\n",
      "        [0.6006],\n",
      "        [0.6018]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0313, -0.0106,  0.0066],\n",
      "        [-0.0303, -0.0310, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6009],\n",
      "        [0.6035],\n",
      "        [0.6014],\n",
      "        [0.6015],\n",
      "        [0.6009],\n",
      "        [0.6007],\n",
      "        [0.6022],\n",
      "        [0.6020]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6009],\n",
      "        [0.6035],\n",
      "        [0.6014],\n",
      "        [0.6015],\n",
      "        [0.6009],\n",
      "        [0.6007],\n",
      "        [0.6022],\n",
      "        [0.6020]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7250, 0.6500, 0.5000, 0.7500, 0.8000, 0.3750, 0.5750, 0.7750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0315, -0.0107,  0.0066],\n",
      "        [-0.0305, -0.0313, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6256],\n",
      "        [0.6272],\n",
      "        [0.6253],\n",
      "        [0.6260],\n",
      "        [0.6269],\n",
      "        [0.6255],\n",
      "        [0.6260],\n",
      "        [0.6251]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0312, -0.0106,  0.0066],\n",
      "        [-0.0302, -0.0312, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6001],\n",
      "        [0.5999],\n",
      "        [0.6019],\n",
      "        [0.5998],\n",
      "        [0.6010],\n",
      "        [0.5997],\n",
      "        [0.6034],\n",
      "        [0.6006]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0313, -0.0106,  0.0066],\n",
      "        [-0.0302, -0.0313, -0.0106,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc out tensor([[0.6037],\n",
      "        [0.6047],\n",
      "        [0.6067],\n",
      "        [0.6050],\n",
      "        [0.6063],\n",
      "        [0.6045],\n",
      "        [0.6076],\n",
      "        [0.6076]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0305, -0.0313, -0.0107,  0.0065],\n",
      "        [-0.0303, -0.0315, -0.0107,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6274],\n",
      "        [0.6246],\n",
      "        [0.6252],\n",
      "        [0.6284],\n",
      "        [0.6259],\n",
      "        [0.6255],\n",
      "        [0.6268],\n",
      "        [0.6269]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0313, -0.0107,  0.0066],\n",
      "        [-0.0303, -0.0314, -0.0107,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6222],\n",
      "        [0.6200],\n",
      "        [0.6200],\n",
      "        [0.6216],\n",
      "        [0.6214],\n",
      "        [0.6234],\n",
      "        [0.6200],\n",
      "        [0.6207]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0313, -0.0107,  0.0066],\n",
      "        [-0.0303, -0.0314, -0.0107,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6218],\n",
      "        [0.6205]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0315, -0.0107,  0.0066],\n",
      "        [-0.0304, -0.0314, -0.0107,  0.0066]], device='cuda:0')\n",
      "after fc out tensor([[0.6228],\n",
      "        [0.6244],\n",
      "        [0.6227],\n",
      "        [0.6236],\n",
      "        [0.6269]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0313, -0.0107,  0.0065],\n",
      "        [-0.0305, -0.0313, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6236],\n",
      "        [0.6257],\n",
      "        [0.6243],\n",
      "        [0.6219],\n",
      "        [0.6234],\n",
      "        [0.6246],\n",
      "        [0.6237],\n",
      "        [0.6251]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6236],\n",
      "        [0.6257],\n",
      "        [0.6243],\n",
      "        [0.6219],\n",
      "        [0.6234],\n",
      "        [0.6246],\n",
      "        [0.6237],\n",
      "        [0.6251]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.7250, 0.6750, 0.7250, 0.5250, 0.6750, 0.7000, 0.5000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0305, -0.0316, -0.0107,  0.0066],\n",
      "        [-0.0305, -0.0315, -0.0107,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6396],\n",
      "        [0.6410],\n",
      "        [0.6395],\n",
      "        [0.6411],\n",
      "        [0.6419],\n",
      "        [0.6426],\n",
      "        [0.6416],\n",
      "        [0.6394]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0314, -0.0107,  0.0066],\n",
      "        [-0.0304, -0.0313, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6235],\n",
      "        [0.6265],\n",
      "        [0.6230],\n",
      "        [0.6233],\n",
      "        [0.6242],\n",
      "        [0.6259],\n",
      "        [0.6230],\n",
      "        [0.6234]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0297, -0.0303, -0.0103,  0.0065],\n",
      "        [-0.0296, -0.0305, -0.0103,  0.0066]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5259],\n",
      "        [0.5236],\n",
      "        [0.5293],\n",
      "        [0.5226],\n",
      "        [0.5245],\n",
      "        [0.5249],\n",
      "        [0.5214],\n",
      "        [0.5245]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0322, -0.0108,  0.0066],\n",
      "        [-0.0310, -0.0320, -0.0109,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6884],\n",
      "        [0.6949],\n",
      "        [0.6873],\n",
      "        [0.7016],\n",
      "        [0.6892],\n",
      "        [0.6993],\n",
      "        [0.7010],\n",
      "        [0.6902]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0311, -0.0104,  0.0065],\n",
      "        [-0.0300, -0.0310, -0.0105,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5660],\n",
      "        [0.5641],\n",
      "        [0.5634],\n",
      "        [0.5674],\n",
      "        [0.5680],\n",
      "        [0.5601],\n",
      "        [0.5671],\n",
      "        [0.5652]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0322, -0.0108,  0.0065],\n",
      "        [-0.0309, -0.0322, -0.0108,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6857],\n",
      "        [0.6852]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0295, -0.0306, -0.0102,  0.0065],\n",
      "        [-0.0296, -0.0306, -0.0102,  0.0065]], device='cuda:0')\n",
      "after fc out tensor([[0.5032],\n",
      "        [0.5073],\n",
      "        [0.5046],\n",
      "        [0.5072],\n",
      "        [0.5149]], device='cuda:0')\n",
      "Epoch:  85. Loss: 0.0860. mean_squared_error.: 0.043766461312770844\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0296, -0.0305, -0.0102,  0.0064],\n",
      "        [-0.0296, -0.0306, -0.0102,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5087],\n",
      "        [0.5044],\n",
      "        [0.5085],\n",
      "        [0.5045],\n",
      "        [0.5079],\n",
      "        [0.5054],\n",
      "        [0.5138],\n",
      "        [0.5012]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.5087],\n",
      "        [0.5044],\n",
      "        [0.5085],\n",
      "        [0.5045],\n",
      "        [0.5079],\n",
      "        [0.5054],\n",
      "        [0.5138],\n",
      "        [0.5012]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5000, 0.9500, 0.6000, 0.4750, 0.5250, 0.2750, 0.6500, 0.8000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0309, -0.0103,  0.0064],\n",
      "        [-0.0299, -0.0310, -0.0103,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5504],\n",
      "        [0.5378],\n",
      "        [0.5428],\n",
      "        [0.5445],\n",
      "        [0.5403],\n",
      "        [0.5441],\n",
      "        [0.5461],\n",
      "        [0.5455]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0313, -0.0104,  0.0065],\n",
      "        [-0.0302, -0.0312, -0.0104,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5655],\n",
      "        [0.5776],\n",
      "        [0.5700],\n",
      "        [0.5720],\n",
      "        [0.5694],\n",
      "        [0.5613],\n",
      "        [0.5650],\n",
      "        [0.5685]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0315, -0.0105,  0.0064],\n",
      "        [-0.0303, -0.0315, -0.0105,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5908],\n",
      "        [0.5959],\n",
      "        [0.5934],\n",
      "        [0.5873],\n",
      "        [0.5950],\n",
      "        [0.5800],\n",
      "        [0.5806],\n",
      "        [0.5920]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0316, -0.0106,  0.0064],\n",
      "        [-0.0304, -0.0317, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6173],\n",
      "        [0.6050],\n",
      "        [0.6095],\n",
      "        [0.6105],\n",
      "        [0.6049],\n",
      "        [0.6052],\n",
      "        [0.6058],\n",
      "        [0.6032]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0317, -0.0106,  0.0064],\n",
      "        [-0.0306, -0.0317, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6275],\n",
      "        [0.6320],\n",
      "        [0.6065],\n",
      "        [0.6245],\n",
      "        [0.6192],\n",
      "        [0.6069],\n",
      "        [0.6089],\n",
      "        [0.6130]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0317, -0.0106,  0.0065],\n",
      "        [-0.0304, -0.0317, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6069],\n",
      "        [0.6093]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0317, -0.0106,  0.0065],\n",
      "        [-0.0305, -0.0317, -0.0106,  0.0065]], device='cuda:0')\n",
      "after fc out tensor([[0.6082],\n",
      "        [0.6151],\n",
      "        [0.6109],\n",
      "        [0.6154],\n",
      "        [0.6286]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0317, -0.0106,  0.0064],\n",
      "        [-0.0306, -0.0317, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6211],\n",
      "        [0.6076],\n",
      "        [0.6080],\n",
      "        [0.6254],\n",
      "        [0.6049],\n",
      "        [0.6041],\n",
      "        [0.6131],\n",
      "        [0.6108]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6211],\n",
      "        [0.6076],\n",
      "        [0.6080],\n",
      "        [0.6254],\n",
      "        [0.6049],\n",
      "        [0.6041],\n",
      "        [0.6131],\n",
      "        [0.6108]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5500, 0.5750, 0.7500, 0.7750, 0.7000, 0.7000, 0.6750, 0.6250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0323, -0.0108,  0.0065],\n",
      "        [-0.0310, -0.0322, -0.0108,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6807],\n",
      "        [0.6851],\n",
      "        [0.6842],\n",
      "        [0.6803],\n",
      "        [0.6789],\n",
      "        [0.6850],\n",
      "        [0.6834],\n",
      "        [0.6905]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0314, -0.0105,  0.0064],\n",
      "        [-0.0302, -0.0315, -0.0104,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5770],\n",
      "        [0.5764],\n",
      "        [0.5767],\n",
      "        [0.5778],\n",
      "        [0.5781],\n",
      "        [0.5764],\n",
      "        [0.5771],\n",
      "        [0.5774]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0312, -0.0104,  0.0065],\n",
      "        [-0.0300, -0.0312, -0.0104,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5501],\n",
      "        [0.5510],\n",
      "        [0.5495],\n",
      "        [0.5518],\n",
      "        [0.5536],\n",
      "        [0.5506],\n",
      "        [0.5533],\n",
      "        [0.5522]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0321, -0.0107,  0.0065],\n",
      "        [-0.0309, -0.0320, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6597],\n",
      "        [0.6591],\n",
      "        [0.6628],\n",
      "        [0.6612],\n",
      "        [0.6584],\n",
      "        [0.6604],\n",
      "        [0.6607],\n",
      "        [0.6590]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0320, -0.0106,  0.0065],\n",
      "        [-0.0306, -0.0321, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6309],\n",
      "        [0.6304],\n",
      "        [0.6347],\n",
      "        [0.6329],\n",
      "        [0.6303],\n",
      "        [0.6272],\n",
      "        [0.6302],\n",
      "        [0.6330]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0315, -0.0106,  0.0064],\n",
      "        [-0.0305, -0.0319, -0.0105,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6119],\n",
      "        [0.6115]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0327, -0.0108,  0.0065],\n",
      "        [-0.0312, -0.0326, -0.0108,  0.0065]], device='cuda:0')\n",
      "after fc out tensor([[0.7112],\n",
      "        [0.7064],\n",
      "        [0.7077],\n",
      "        [0.7040],\n",
      "        [0.6957]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0325, -0.0108,  0.0065],\n",
      "        [-0.0312, -0.0324, -0.0109,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7041],\n",
      "        [0.7016],\n",
      "        [0.7074],\n",
      "        [0.7107],\n",
      "        [0.6981],\n",
      "        [0.7144],\n",
      "        [0.7023],\n",
      "        [0.7004]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.7041],\n",
      "        [0.7016],\n",
      "        [0.7074],\n",
      "        [0.7107],\n",
      "        [0.6981],\n",
      "        [0.7144],\n",
      "        [0.7023],\n",
      "        [0.7004]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.8500, 0.5500, 0.8000, 0.9250, 0.5750, 0.6750, 0.5000, 0.7000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0324, -0.0109,  0.0065],\n",
      "        [-0.0312, -0.0326, -0.0108,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6926],\n",
      "        [0.6984],\n",
      "        [0.7072],\n",
      "        [0.6906],\n",
      "        [0.6981],\n",
      "        [0.6913],\n",
      "        [0.6986],\n",
      "        [0.7031]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0317, -0.0105,  0.0064],\n",
      "        [-0.0304, -0.0315, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5846],\n",
      "        [0.5820],\n",
      "        [0.5870],\n",
      "        [0.6053],\n",
      "        [0.6000],\n",
      "        [0.5971],\n",
      "        [0.5974],\n",
      "        [0.5867]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0317, -0.0106,  0.0065],\n",
      "        [-0.0306, -0.0319, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6341],\n",
      "        [0.6364],\n",
      "        [0.6266],\n",
      "        [0.6107],\n",
      "        [0.6377],\n",
      "        [0.6261],\n",
      "        [0.6280],\n",
      "        [0.6360]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0316, -0.0108,  0.0065],\n",
      "        [-0.0307, -0.0317, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6147],\n",
      "        [0.6225],\n",
      "        [0.6568],\n",
      "        [0.6323],\n",
      "        [0.6512],\n",
      "        [0.6242],\n",
      "        [0.6380],\n",
      "        [0.6427]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0319, -0.0107,  0.0065],\n",
      "        [-0.0307, -0.0321, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6266],\n",
      "        [0.6377],\n",
      "        [0.6345],\n",
      "        [0.6326],\n",
      "        [0.6475],\n",
      "        [0.6457],\n",
      "        [0.6384],\n",
      "        [0.6270]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0321, -0.0106,  0.0065],\n",
      "        [-0.0307, -0.0323, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6366],\n",
      "        [0.6381]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0320, -0.0106,  0.0065]], device='cuda:0')\n",
      "after fc out tensor([[0.6397],\n",
      "        [0.6267],\n",
      "        [0.6321],\n",
      "        [0.6226],\n",
      "        [0.5986]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0317, -0.0107,  0.0065],\n",
      "        [-0.0307, -0.0323, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6253],\n",
      "        [0.6470],\n",
      "        [0.6190],\n",
      "        [0.6382],\n",
      "        [0.6334],\n",
      "        [0.6054],\n",
      "        [0.6174],\n",
      "        [0.6142]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6253],\n",
      "        [0.6470],\n",
      "        [0.6190],\n",
      "        [0.6382],\n",
      "        [0.6334],\n",
      "        [0.6054],\n",
      "        [0.6174],\n",
      "        [0.6142]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.8000, 0.5000, 0.9500, 0.6250, 0.5750, 0.5250, 0.5500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0323, -0.0107,  0.0065],\n",
      "        [-0.0309, -0.0325, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6610],\n",
      "        [0.6746],\n",
      "        [0.6548],\n",
      "        [0.6608],\n",
      "        [0.6533],\n",
      "        [0.6544],\n",
      "        [0.6722],\n",
      "        [0.6366]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0300, -0.0313, -0.0103,  0.0064],\n",
      "        [-0.0300, -0.0312, -0.0103,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5498],\n",
      "        [0.5385],\n",
      "        [0.5466],\n",
      "        [0.5388],\n",
      "        [0.5308],\n",
      "        [0.5338],\n",
      "        [0.5442],\n",
      "        [0.5457]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0318, -0.0106,  0.0064],\n",
      "        [-0.0306, -0.0321, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6109],\n",
      "        [0.6151],\n",
      "        [0.6170],\n",
      "        [0.6098],\n",
      "        [0.6191],\n",
      "        [0.6162],\n",
      "        [0.6136],\n",
      "        [0.6093]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0320, -0.0105,  0.0064],\n",
      "        [-0.0306, -0.0319, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6156],\n",
      "        [0.6128],\n",
      "        [0.6128],\n",
      "        [0.6147],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.6118],\n",
      "        [0.6030]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0320, -0.0107,  0.0065],\n",
      "        [-0.0309, -0.0323, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6482],\n",
      "        [0.6483],\n",
      "        [0.6483],\n",
      "        [0.6504],\n",
      "        [0.6530],\n",
      "        [0.6566],\n",
      "        [0.6605],\n",
      "        [0.6488]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0321, -0.0107,  0.0065],\n",
      "        [-0.0309, -0.0323, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6509],\n",
      "        [0.6590]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0326, -0.0107,  0.0065],\n",
      "        [-0.0311, -0.0325, -0.0107,  0.0065]], device='cuda:0')\n",
      "after fc out tensor([[0.6844],\n",
      "        [0.6773],\n",
      "        [0.6797],\n",
      "        [0.6743],\n",
      "        [0.6612]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0324, -0.0108,  0.0065],\n",
      "        [-0.0311, -0.0325, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6744],\n",
      "        [0.6790],\n",
      "        [0.6831],\n",
      "        [0.6830],\n",
      "        [0.6895],\n",
      "        [0.6741],\n",
      "        [0.6845],\n",
      "        [0.6643]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6744],\n",
      "        [0.6790],\n",
      "        [0.6831],\n",
      "        [0.6830],\n",
      "        [0.6895],\n",
      "        [0.6741],\n",
      "        [0.6845],\n",
      "        [0.6643]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.8500, 0.9000, 0.7500, 0.5500, 0.7250, 0.4250, 0.7500, 0.3750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0321, -0.0108,  0.0065],\n",
      "        [-0.0310, -0.0326, -0.0107,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6725],\n",
      "        [0.6735],\n",
      "        [0.6775],\n",
      "        [0.6634],\n",
      "        [0.6704],\n",
      "        [0.6545],\n",
      "        [0.6688],\n",
      "        [0.6713]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0321, -0.0105,  0.0064],\n",
      "        [-0.0306, -0.0318, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6123],\n",
      "        [0.6122],\n",
      "        [0.6146],\n",
      "        [0.6205],\n",
      "        [0.6089],\n",
      "        [0.6071],\n",
      "        [0.6041],\n",
      "        [0.6086]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0318, -0.0106,  0.0064],\n",
      "        [-0.0306, -0.0317, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6088],\n",
      "        [0.6103],\n",
      "        [0.6132],\n",
      "        [0.6100],\n",
      "        [0.6128],\n",
      "        [0.6205],\n",
      "        [0.6153],\n",
      "        [0.6162]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0322, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6338],\n",
      "        [0.6346],\n",
      "        [0.6223],\n",
      "        [0.6241],\n",
      "        [0.6261],\n",
      "        [0.6245],\n",
      "        [0.6288],\n",
      "        [0.6342]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0318, -0.0106,  0.0064],\n",
      "        [-0.0307, -0.0318, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6094],\n",
      "        [0.6118],\n",
      "        [0.6174],\n",
      "        [0.6151],\n",
      "        [0.6204],\n",
      "        [0.6181],\n",
      "        [0.6140],\n",
      "        [0.6227]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0318, -0.0106,  0.0064],\n",
      "        [-0.0306, -0.0322, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6175],\n",
      "        [0.6233]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0321, -0.0106,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.6260],\n",
      "        [0.6225],\n",
      "        [0.6233],\n",
      "        [0.6204],\n",
      "        [0.6138]], device='cuda:0')\n",
      "Epoch:  90. Loss: 0.0019. mean_squared_error.: 0.049479104578495026\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0318, -0.0106,  0.0064],\n",
      "        [-0.0307, -0.0320, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6188],\n",
      "        [0.6195],\n",
      "        [0.6283],\n",
      "        [0.6235],\n",
      "        [0.6263],\n",
      "        [0.6227],\n",
      "        [0.6226],\n",
      "        [0.6284]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6188],\n",
      "        [0.6195],\n",
      "        [0.6283],\n",
      "        [0.6235],\n",
      "        [0.6263],\n",
      "        [0.6227],\n",
      "        [0.6226],\n",
      "        [0.6284]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.5750, 0.6750, 0.5000, 0.7500, 0.9000, 0.4750, 0.7000],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0324, -0.0107,  0.0065],\n",
      "        [-0.0309, -0.0324, -0.0107,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6607],\n",
      "        [0.6601],\n",
      "        [0.6637],\n",
      "        [0.6625],\n",
      "        [0.6670],\n",
      "        [0.6572],\n",
      "        [0.6614],\n",
      "        [0.6559]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0301, -0.0313, -0.0103,  0.0064],\n",
      "        [-0.0301, -0.0313, -0.0103,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5442],\n",
      "        [0.5433],\n",
      "        [0.5460],\n",
      "        [0.5440],\n",
      "        [0.5455],\n",
      "        [0.5476],\n",
      "        [0.5439],\n",
      "        [0.5472]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0318, -0.0104,  0.0064],\n",
      "        [-0.0305, -0.0316, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5836],\n",
      "        [0.5853],\n",
      "        [0.5850],\n",
      "        [0.5858],\n",
      "        [0.5836],\n",
      "        [0.5852],\n",
      "        [0.5855],\n",
      "        [0.5828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0319, -0.0104,  0.0064],\n",
      "        [-0.0304, -0.0318, -0.0104,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5859],\n",
      "        [0.5869],\n",
      "        [0.5881],\n",
      "        [0.5862],\n",
      "        [0.5872],\n",
      "        [0.5853],\n",
      "        [0.5893],\n",
      "        [0.5873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0305, -0.0319, -0.0105,  0.0064],\n",
      "        [-0.0306, -0.0317, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5944],\n",
      "        [0.5972],\n",
      "        [0.5959],\n",
      "        [0.5951],\n",
      "        [0.5974],\n",
      "        [0.5943],\n",
      "        [0.5965],\n",
      "        [0.5956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0317, -0.0332, -0.0110,  0.0065],\n",
      "        [-0.0316, -0.0333, -0.0109,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7606],\n",
      "        [0.7549]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0306, -0.0321, -0.0105,  0.0064],\n",
      "        [-0.0306, -0.0321, -0.0105,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.5938],\n",
      "        [0.6059],\n",
      "        [0.5993],\n",
      "        [0.6074],\n",
      "        [0.6288]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0321, -0.0105,  0.0063],\n",
      "        [-0.0307, -0.0321, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6229],\n",
      "        [0.6132],\n",
      "        [0.6106],\n",
      "        [0.5858],\n",
      "        [0.6233],\n",
      "        [0.6073],\n",
      "        [0.5874],\n",
      "        [0.6281]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6229],\n",
      "        [0.6132],\n",
      "        [0.6106],\n",
      "        [0.5858],\n",
      "        [0.6233],\n",
      "        [0.6073],\n",
      "        [0.5874],\n",
      "        [0.6281]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5750, 0.7000, 0.5250, 0.7000, 0.7750, 0.8500, 0.7000, 0.2750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0106,  0.0065],\n",
      "        [-0.0310, -0.0323, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6055],\n",
      "        [0.6389],\n",
      "        [0.6236],\n",
      "        [0.6068],\n",
      "        [0.6014],\n",
      "        [0.6216],\n",
      "        [0.6214],\n",
      "        [0.6174]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0323, -0.0105,  0.0063],\n",
      "        [-0.0308, -0.0323, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6298],\n",
      "        [0.6189],\n",
      "        [0.6302],\n",
      "        [0.6171],\n",
      "        [0.6201],\n",
      "        [0.6069],\n",
      "        [0.6151],\n",
      "        [0.6349]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0324, -0.0106,  0.0064],\n",
      "        [-0.0309, -0.0324, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6385],\n",
      "        [0.6390],\n",
      "        [0.6315],\n",
      "        [0.6508],\n",
      "        [0.6413],\n",
      "        [0.6314],\n",
      "        [0.6282],\n",
      "        [0.6388]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0320, -0.0105,  0.0063],\n",
      "        [-0.0308, -0.0320, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6046],\n",
      "        [0.6061],\n",
      "        [0.5934],\n",
      "        [0.5914],\n",
      "        [0.5989],\n",
      "        [0.5935],\n",
      "        [0.5900],\n",
      "        [0.5980]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0322, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6198],\n",
      "        [0.6121],\n",
      "        [0.6224],\n",
      "        [0.6075],\n",
      "        [0.6096],\n",
      "        [0.6041],\n",
      "        [0.6202],\n",
      "        [0.6124]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0309, -0.0321, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6083],\n",
      "        [0.6166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0323, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0323, -0.0105,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.6116],\n",
      "        [0.6200],\n",
      "        [0.6151],\n",
      "        [0.6206],\n",
      "        [0.6353]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0322, -0.0105,  0.0063],\n",
      "        [-0.0307, -0.0323, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6182],\n",
      "        [0.6064],\n",
      "        [0.6100],\n",
      "        [0.6124],\n",
      "        [0.6225],\n",
      "        [0.6208],\n",
      "        [0.6105],\n",
      "        [0.6160]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6182],\n",
      "        [0.6064],\n",
      "        [0.6100],\n",
      "        [0.6124],\n",
      "        [0.6225],\n",
      "        [0.6208],\n",
      "        [0.6105],\n",
      "        [0.6160]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9250, 0.7000, 0.4000, 0.6750, 0.5750, 0.8000, 0.5750, 0.5750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0327, -0.0107,  0.0064],\n",
      "        [-0.0312, -0.0326, -0.0107,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6625],\n",
      "        [0.6647],\n",
      "        [0.6679],\n",
      "        [0.6582],\n",
      "        [0.6612],\n",
      "        [0.6725],\n",
      "        [0.6623],\n",
      "        [0.6714]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0304, -0.0319, -0.0104,  0.0064],\n",
      "        [-0.0304, -0.0319, -0.0104,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5695],\n",
      "        [0.5711],\n",
      "        [0.5704],\n",
      "        [0.5732],\n",
      "        [0.5731],\n",
      "        [0.5717],\n",
      "        [0.5717],\n",
      "        [0.5724]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0325, -0.0105,  0.0064],\n",
      "        [-0.0308, -0.0325, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6283],\n",
      "        [0.6294],\n",
      "        [0.6318],\n",
      "        [0.6291],\n",
      "        [0.6345],\n",
      "        [0.6310],\n",
      "        [0.6308],\n",
      "        [0.6321]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0321, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6044],\n",
      "        [0.6048],\n",
      "        [0.6042],\n",
      "        [0.6041],\n",
      "        [0.6057],\n",
      "        [0.6038],\n",
      "        [0.6059],\n",
      "        [0.6059]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0326, -0.0105,  0.0064],\n",
      "        [-0.0309, -0.0324, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6329],\n",
      "        [0.6354],\n",
      "        [0.6399],\n",
      "        [0.6374],\n",
      "        [0.6344],\n",
      "        [0.6352],\n",
      "        [0.6362],\n",
      "        [0.6332]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0308, -0.0323, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6210],\n",
      "        [0.6206]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0314, -0.0331, -0.0107,  0.0065],\n",
      "        [-0.0314, -0.0330, -0.0108,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.7020],\n",
      "        [0.7027],\n",
      "        [0.7013],\n",
      "        [0.7013],\n",
      "        [0.7014]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0314, -0.0329, -0.0108,  0.0064],\n",
      "        [-0.0314, -0.0329, -0.0108,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7017],\n",
      "        [0.7022],\n",
      "        [0.7031],\n",
      "        [0.7027],\n",
      "        [0.7010],\n",
      "        [0.7008],\n",
      "        [0.7024],\n",
      "        [0.7022]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.7017],\n",
      "        [0.7022],\n",
      "        [0.7031],\n",
      "        [0.7027],\n",
      "        [0.7010],\n",
      "        [0.7008],\n",
      "        [0.7024],\n",
      "        [0.7022]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6000, 0.8750, 0.6750, 0.5500, 0.6750, 0.4750, 0.7000, 0.7750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0328, -0.0107,  0.0064],\n",
      "        [-0.0312, -0.0328, -0.0107,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6743],\n",
      "        [0.6724],\n",
      "        [0.6739],\n",
      "        [0.6740],\n",
      "        [0.6731],\n",
      "        [0.6742],\n",
      "        [0.6753],\n",
      "        [0.6730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0321, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0320, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6026],\n",
      "        [0.6010],\n",
      "        [0.6038],\n",
      "        [0.6037],\n",
      "        [0.6035],\n",
      "        [0.6040],\n",
      "        [0.6038],\n",
      "        [0.6019]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0322, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6005],\n",
      "        [0.6047],\n",
      "        [0.6034],\n",
      "        [0.6035],\n",
      "        [0.6029],\n",
      "        [0.6038],\n",
      "        [0.6038],\n",
      "        [0.6029]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0105,  0.0064],\n",
      "        [-0.0308, -0.0320, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6065],\n",
      "        [0.6027],\n",
      "        [0.6037],\n",
      "        [0.6065],\n",
      "        [0.6060],\n",
      "        [0.6050],\n",
      "        [0.6040],\n",
      "        [0.6063]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0323, -0.0105,  0.0064],\n",
      "        [-0.0307, -0.0323, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6072],\n",
      "        [0.6075],\n",
      "        [0.6092],\n",
      "        [0.6078],\n",
      "        [0.6107],\n",
      "        [0.6071],\n",
      "        [0.6102],\n",
      "        [0.6066]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0324, -0.0105,  0.0064],\n",
      "        [-0.0308, -0.0323, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6166],\n",
      "        [0.6138]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0324, -0.0105,  0.0064],\n",
      "        [-0.0308, -0.0323, -0.0105,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.6164],\n",
      "        [0.6161],\n",
      "        [0.6153],\n",
      "        [0.6146],\n",
      "        [0.6129]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0321, -0.0106,  0.0064],\n",
      "        [-0.0308, -0.0321, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6183],\n",
      "        [0.6136],\n",
      "        [0.6167],\n",
      "        [0.6174],\n",
      "        [0.6155],\n",
      "        [0.6169],\n",
      "        [0.6157],\n",
      "        [0.6170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6183],\n",
      "        [0.6136],\n",
      "        [0.6167],\n",
      "        [0.6174],\n",
      "        [0.6155],\n",
      "        [0.6169],\n",
      "        [0.6157],\n",
      "        [0.6170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9250, 0.5750, 0.7250, 0.7000, 0.5000, 0.5500, 0.2750, 0.8000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0309, -0.0324, -0.0106,  0.0064],\n",
      "        [-0.0309, -0.0325, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6354],\n",
      "        [0.6344],\n",
      "        [0.6332],\n",
      "        [0.6340],\n",
      "        [0.6341],\n",
      "        [0.6321],\n",
      "        [0.6344],\n",
      "        [0.6336]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0302, -0.0315, -0.0103,  0.0063],\n",
      "        [-0.0302, -0.0316, -0.0103,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5385],\n",
      "        [0.5390],\n",
      "        [0.5408],\n",
      "        [0.5398],\n",
      "        [0.5401],\n",
      "        [0.5405],\n",
      "        [0.5384],\n",
      "        [0.5398]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0326, -0.0106,  0.0064],\n",
      "        [-0.0310, -0.0325, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6376],\n",
      "        [0.6381],\n",
      "        [0.6398],\n",
      "        [0.6408],\n",
      "        [0.6400],\n",
      "        [0.6396],\n",
      "        [0.6421],\n",
      "        [0.6395]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0320, -0.0102,  0.0063],\n",
      "        [-0.0303, -0.0317, -0.0103,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5629],\n",
      "        [0.5517],\n",
      "        [0.5388],\n",
      "        [0.5633],\n",
      "        [0.5476],\n",
      "        [0.5476],\n",
      "        [0.5476],\n",
      "        [0.5585]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0313, -0.0329, -0.0107,  0.0064],\n",
      "        [-0.0313, -0.0331, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6752],\n",
      "        [0.6761],\n",
      "        [0.6843],\n",
      "        [0.6847],\n",
      "        [0.6835],\n",
      "        [0.6875],\n",
      "        [0.6874],\n",
      "        [0.6703]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0326, -0.0105,  0.0064],\n",
      "        [-0.0310, -0.0325, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6368],\n",
      "        [0.6289]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0319, -0.0338, -0.0108,  0.0065],\n",
      "        [-0.0319, -0.0337, -0.0108,  0.0065]], device='cuda:0')\n",
      "after fc out tensor([[0.7699],\n",
      "        [0.7597],\n",
      "        [0.7637],\n",
      "        [0.7562],\n",
      "        [0.7372]], device='cuda:0')\n",
      "Epoch:  95. Loss: 0.0316. mean_squared_error.: 0.09040335565805435\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0318, -0.0332, -0.0110,  0.0065],\n",
      "        [-0.0319, -0.0339, -0.0108,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7660],\n",
      "        [0.7660],\n",
      "        [0.7540],\n",
      "        [0.7468],\n",
      "        [0.7495],\n",
      "        [0.7576],\n",
      "        [0.7538],\n",
      "        [0.7676]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.7660],\n",
      "        [0.7660],\n",
      "        [0.7540],\n",
      "        [0.7468],\n",
      "        [0.7495],\n",
      "        [0.7576],\n",
      "        [0.7538],\n",
      "        [0.7676]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.9250, 0.4250, 0.6500, 0.6500, 0.7000, 0.6000, 0.6000, 0.5500],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0326, -0.0107,  0.0064],\n",
      "        [-0.0312, -0.0328, -0.0107,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6563],\n",
      "        [0.6537],\n",
      "        [0.6643],\n",
      "        [0.6615],\n",
      "        [0.6636],\n",
      "        [0.6773],\n",
      "        [0.6487],\n",
      "        [0.6456]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0329, -0.0105,  0.0063],\n",
      "        [-0.0311, -0.0328, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6559],\n",
      "        [0.6389],\n",
      "        [0.6411],\n",
      "        [0.6452],\n",
      "        [0.6531],\n",
      "        [0.6387],\n",
      "        [0.6400],\n",
      "        [0.6156]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0325, -0.0106,  0.0064],\n",
      "        [-0.0311, -0.0327, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6184],\n",
      "        [0.6470],\n",
      "        [0.6300],\n",
      "        [0.6134],\n",
      "        [0.6367],\n",
      "        [0.6298],\n",
      "        [0.6257],\n",
      "        [0.6302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0328, -0.0106,  0.0064],\n",
      "        [-0.0311, -0.0327, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6353],\n",
      "        [0.6428],\n",
      "        [0.6572],\n",
      "        [0.6456],\n",
      "        [0.6506],\n",
      "        [0.6574],\n",
      "        [0.6521],\n",
      "        [0.6603]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0329, -0.0105,  0.0064],\n",
      "        [-0.0311, -0.0329, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6617],\n",
      "        [0.6639],\n",
      "        [0.6299],\n",
      "        [0.6480],\n",
      "        [0.6399],\n",
      "        [0.6442],\n",
      "        [0.6410],\n",
      "        [0.6548]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0330, -0.0105,  0.0063],\n",
      "        [-0.0311, -0.0325, -0.0107,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6524],\n",
      "        [0.6376]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0329, -0.0105,  0.0063],\n",
      "        [-0.0311, -0.0328, -0.0105,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.6461],\n",
      "        [0.6360],\n",
      "        [0.6400],\n",
      "        [0.6325],\n",
      "        [0.6138]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0327, -0.0106,  0.0064],\n",
      "        [-0.0310, -0.0326, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6459],\n",
      "        [0.6261],\n",
      "        [0.6421],\n",
      "        [0.6389],\n",
      "        [0.6435],\n",
      "        [0.6186],\n",
      "        [0.6304],\n",
      "        [0.6263]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6459],\n",
      "        [0.6261],\n",
      "        [0.6421],\n",
      "        [0.6389],\n",
      "        [0.6435],\n",
      "        [0.6186],\n",
      "        [0.6304],\n",
      "        [0.6263]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.7500, 0.5500, 0.9250, 0.4750, 0.5750, 0.3750, 0.6500, 0.6750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0310, -0.0327, -0.0105,  0.0063],\n",
      "        [-0.0309, -0.0326, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6379],\n",
      "        [0.6141],\n",
      "        [0.6259],\n",
      "        [0.6185],\n",
      "        [0.6241],\n",
      "        [0.6250],\n",
      "        [0.6240],\n",
      "        [0.6160]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0322, -0.0104,  0.0063],\n",
      "        [-0.0307, -0.0322, -0.0104,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5851],\n",
      "        [0.5833],\n",
      "        [0.5887],\n",
      "        [0.5917],\n",
      "        [0.5897],\n",
      "        [0.5822],\n",
      "        [0.5784],\n",
      "        [0.5876]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0316, -0.0331, -0.0108,  0.0064],\n",
      "        [-0.0316, -0.0332, -0.0108,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7001],\n",
      "        [0.6985],\n",
      "        [0.6985],\n",
      "        [0.7009],\n",
      "        [0.7032],\n",
      "        [0.7036],\n",
      "        [0.6999],\n",
      "        [0.7030]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0326, -0.0104,  0.0064],\n",
      "        [-0.0310, -0.0325, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5993],\n",
      "        [0.6089],\n",
      "        [0.6003],\n",
      "        [0.6027],\n",
      "        [0.6017],\n",
      "        [0.6075],\n",
      "        [0.6068],\n",
      "        [0.6007]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0329, -0.0105,  0.0064],\n",
      "        [-0.0311, -0.0329, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6341],\n",
      "        [0.6354],\n",
      "        [0.6354],\n",
      "        [0.6329],\n",
      "        [0.6416],\n",
      "        [0.6402],\n",
      "        [0.6373],\n",
      "        [0.6382]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0307, -0.0323, -0.0104,  0.0063],\n",
      "        [-0.0307, -0.0322, -0.0104,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5783],\n",
      "        [0.5803]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0314, -0.0332, -0.0107,  0.0064],\n",
      "        [-0.0315, -0.0333, -0.0107,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.6682],\n",
      "        [0.6894],\n",
      "        [0.6785],\n",
      "        [0.6930],\n",
      "        [0.7313]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0314, -0.0333, -0.0107,  0.0064],\n",
      "        [-0.0315, -0.0333, -0.0107,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6742],\n",
      "        [0.6810],\n",
      "        [0.6568],\n",
      "        [0.6961],\n",
      "        [0.6536],\n",
      "        [0.6774],\n",
      "        [0.7006],\n",
      "        [0.6664]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6742],\n",
      "        [0.6810],\n",
      "        [0.6568],\n",
      "        [0.6961],\n",
      "        [0.6536],\n",
      "        [0.6774],\n",
      "        [0.7006],\n",
      "        [0.6664]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.5500, 0.5750, 0.8000, 0.6500, 0.7000, 0.6250, 0.5000, 0.4250],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0330, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0330, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6425],\n",
      "        [0.6491],\n",
      "        [0.6550],\n",
      "        [0.6291],\n",
      "        [0.6244],\n",
      "        [0.6101],\n",
      "        [0.6299],\n",
      "        [0.6493]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0329, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0329, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6030],\n",
      "        [0.6433],\n",
      "        [0.6419],\n",
      "        [0.6181],\n",
      "        [0.6249],\n",
      "        [0.6438],\n",
      "        [0.6345],\n",
      "        [0.6266]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0330, -0.0107,  0.0065],\n",
      "        [-0.0317, -0.0333, -0.0105,  0.0062]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6518],\n",
      "        [0.6584],\n",
      "        [0.6467],\n",
      "        [0.7056],\n",
      "        [0.6328],\n",
      "        [0.6311],\n",
      "        [0.6807],\n",
      "        [0.6967]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0330, -0.0106,  0.0064],\n",
      "        [-0.0314, -0.0331, -0.0106,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6393],\n",
      "        [0.6562],\n",
      "        [0.6659],\n",
      "        [0.6503],\n",
      "        [0.6415],\n",
      "        [0.6334],\n",
      "        [0.6583],\n",
      "        [0.6868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0314, -0.0331, -0.0105,  0.0062],\n",
      "        [-0.0310, -0.0329, -0.0106,  0.0065]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6742],\n",
      "        [0.6316],\n",
      "        [0.6605],\n",
      "        [0.6736],\n",
      "        [0.6577],\n",
      "        [0.6642],\n",
      "        [0.6480],\n",
      "        [0.6502]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0313, -0.0331, -0.0105,  0.0062],\n",
      "        [-0.0313, -0.0330, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6213],\n",
      "        [0.6484]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0329, -0.0106,  0.0064],\n",
      "        [-0.0311, -0.0329, -0.0105,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.6229],\n",
      "        [0.6413],\n",
      "        [0.6319],\n",
      "        [0.6445],\n",
      "        [0.6777]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0313, -0.0330, -0.0105,  0.0062],\n",
      "        [-0.0312, -0.0330, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6549],\n",
      "        [0.6243],\n",
      "        [0.6105],\n",
      "        [0.6684],\n",
      "        [0.6266],\n",
      "        [0.6281],\n",
      "        [0.6544],\n",
      "        [0.6166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds tensor([[0.6549],\n",
      "        [0.6243],\n",
      "        [0.6105],\n",
      "        [0.6684],\n",
      "        [0.6266],\n",
      "        [0.6281],\n",
      "        [0.6544],\n",
      "        [0.6166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6750, 0.7500, 0.7250, 0.5750, 0.9500, 0.5500, 0.7250, 0.6000],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0319, -0.0336, -0.0107,  0.0063],\n",
      "        [-0.0319, -0.0336, -0.0107,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.7387],\n",
      "        [0.7203],\n",
      "        [0.7240],\n",
      "        [0.6997],\n",
      "        [0.7235],\n",
      "        [0.7090],\n",
      "        [0.7275],\n",
      "        [0.7254]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0303, -0.0319, -0.0102,  0.0062],\n",
      "        [-0.0303, -0.0320, -0.0102,  0.0062]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5250],\n",
      "        [0.5241],\n",
      "        [0.5265],\n",
      "        [0.5272],\n",
      "        [0.5232],\n",
      "        [0.5256],\n",
      "        [0.5244],\n",
      "        [0.5242]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0308, -0.0326, -0.0103,  0.0063],\n",
      "        [-0.0307, -0.0326, -0.0103,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.5796],\n",
      "        [0.5761],\n",
      "        [0.5834],\n",
      "        [0.5776],\n",
      "        [0.5780],\n",
      "        [0.5809],\n",
      "        [0.5777],\n",
      "        [0.5785]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0328, -0.0104,  0.0063],\n",
      "        [-0.0311, -0.0328, -0.0104,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6088],\n",
      "        [0.6094],\n",
      "        [0.6087],\n",
      "        [0.6080],\n",
      "        [0.6093],\n",
      "        [0.6060],\n",
      "        [0.6058],\n",
      "        [0.6090]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0331, -0.0105,  0.0064],\n",
      "        [-0.0312, -0.0330, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6278],\n",
      "        [0.6293],\n",
      "        [0.6325],\n",
      "        [0.6284],\n",
      "        [0.6283],\n",
      "        [0.6275],\n",
      "        [0.6307],\n",
      "        [0.6273]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0313, -0.0331, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0332, -0.0105,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6394],\n",
      "        [0.6383]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0315, -0.0336, -0.0106,  0.0064],\n",
      "        [-0.0316, -0.0335, -0.0106,  0.0064]], device='cuda:0')\n",
      "after fc out tensor([[0.6777],\n",
      "        [0.6790],\n",
      "        [0.6776],\n",
      "        [0.6781],\n",
      "        [0.6803]], device='cuda:0')\n",
      "* train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train ** train *\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0316, -0.0335, -0.0106,  0.0064],\n",
      "        [-0.0316, -0.0334, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6781],\n",
      "        [0.6794],\n",
      "        [0.6786],\n",
      "        [0.6776],\n",
      "        [0.6777],\n",
      "        [0.6792],\n",
      "        [0.6771],\n",
      "        [0.6791]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "preds tensor([[0.6781],\n",
      "        [0.6794],\n",
      "        [0.6786],\n",
      "        [0.6776],\n",
      "        [0.6777],\n",
      "        [0.6792],\n",
      "        [0.6771],\n",
      "        [0.6791]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y_batch tensor([0.6500, 0.5000, 0.6750, 0.6000, 0.4250, 0.6750, 0.6750, 0.8750],\n",
      "       device='cuda:0')\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0314, -0.0331, -0.0106,  0.0063],\n",
      "        [-0.0314, -0.0331, -0.0106,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6483],\n",
      "        [0.6487],\n",
      "        [0.6462],\n",
      "        [0.6476],\n",
      "        [0.6462],\n",
      "        [0.6469],\n",
      "        [0.6463],\n",
      "        [0.6473]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0316, -0.0332, -0.0107,  0.0064],\n",
      "        [-0.0315, -0.0335, -0.0106,  0.0064]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6771],\n",
      "        [0.6749],\n",
      "        [0.6744],\n",
      "        [0.6742],\n",
      "        [0.6736],\n",
      "        [0.6735],\n",
      "        [0.6739],\n",
      "        [0.6747]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0313, -0.0329, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0330, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6279],\n",
      "        [0.6292],\n",
      "        [0.6312],\n",
      "        [0.6327],\n",
      "        [0.6290],\n",
      "        [0.6320],\n",
      "        [0.6299],\n",
      "        [0.6320]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0329, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0328, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6221],\n",
      "        [0.6220],\n",
      "        [0.6219],\n",
      "        [0.6232],\n",
      "        [0.6215],\n",
      "        [0.6194],\n",
      "        [0.6221],\n",
      "        [0.6251]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([8, 9, 1])\n",
      "out.shape torch.Size([8, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([8, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0330, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0329, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6239],\n",
      "        [0.6221],\n",
      "        [0.6265],\n",
      "        [0.6251],\n",
      "        [0.6263],\n",
      "        [0.6256],\n",
      "        [0.6211],\n",
      "        [0.6233]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "x torch.Size([2, 9, 1])\n",
      "out.shape torch.Size([2, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([2, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0312, -0.0329, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0328, -0.0105,  0.0063]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6236],\n",
      "        [0.6250]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "* val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val ** val *\n",
      "x torch.Size([5, 9, 1])\n",
      "out.shape torch.Size([5, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([5, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0311, -0.0331, -0.0105,  0.0063],\n",
      "        [-0.0312, -0.0331, -0.0105,  0.0063]], device='cuda:0')\n",
      "after fc out tensor([[0.6262],\n",
      "        [0.6250],\n",
      "        [0.6248],\n",
      "        [0.6236],\n",
      "        [0.6212]], device='cuda:0')\n",
      "Epoch: 100. Loss: 0.0232. mean_squared_error.: 0.0499100387096405\n",
      "Early stopping on epoch 100\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1 # features per time step - ONI = 1\n",
    "hidden_dim = 256\n",
    "layer_dim = 3\n",
    "output_dim = 1\n",
    "seq_dim = bs # amount of months - this is how many time steps in one feature\n",
    "\n",
    "# Dummy EEG data (batch_size=100, seq_length=50, input_dim=10)\n",
    "# X = torch.randn(100, 50, 10)  # (100 samples, 50 time steps, 10 features per time step)\n",
    "\n",
    "lr = 0.0005\n",
    "n_epochs = 500\n",
    "iterations_per_epoch = len(trn_dl)\n",
    "best_mse = 1000\n",
    "patience, trials = 100, 0\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss() # replaced cross entropy\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    print(\"* train *\"*40)\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(trn_dl):\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "        x_batch = x_batch.cuda()\n",
    "        y_batch = y_batch.cuda()\n",
    "        \n",
    "        #print(\"x_batch\", x_batch)\n",
    "        #print(\"y_batch\", y_batch)\n",
    "        \n",
    "        \n",
    "        \n",
    "        opt.zero_grad()\n",
    "        out = model(x_batch)\n",
    "        \n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        sched.step()\n",
    "        \n",
    "        if i == 0:\n",
    "            print(\"preds\", out)\n",
    "            print(\"y_batch\", y_batch)\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(\"* val *\"*40)\n",
    "        \n",
    "        correct, total = 0, 0\n",
    "        for x_val, y_val in val_dl:\n",
    "            x_val, y_val = [t.cuda() for t in (x_val, y_val)]\n",
    "            out = model(x_val)\n",
    "            # preds = F.log_softmax(out, dim=1).argmax(dim=1) # NOT GOOD ...\n",
    "            # preds = out\n",
    "\n",
    "            # correct += (preds == y_val).sum().item()\n",
    "\n",
    "            total += 1#  y_val.size(0)\n",
    "            #print(out.detach().cpu().numpy())\n",
    "            #print(y_val.detach().cpu().numpy())\n",
    "            correct += mean_squared_error(out.detach().cpu().numpy(), y_val.detach().cpu().numpy())\n",
    "        \n",
    "    #print(correct)\n",
    "    mse = correct / total\n",
    "\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        \n",
    "        print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. mean_squared_error.: {mse}')\n",
    "\n",
    "    \n",
    "    if mse > best_mse:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        # torch.save(model.state_dict(), 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break\n",
    "    \n",
    "            \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0ea1413a-c088-40ea-87a7-2ea44201465f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1441293502851995"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score([234, 231, 932], [234, 443, 123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5cef8b7d-d55a-4ea8-817b-d23032f16502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error([234], [239])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8d0b89d3-2dd3-4494-aa9d-0675ef0c8f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (rnn): LSTM(1, 256, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "97c68d0d-470a-40ff-b2e2-f7bc9723cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(create_test_dataset(x_tst), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1dd97510-5ab8-4532-b71d-005ed721a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test dataset\n",
      "tensor([[[ 0.4000],\n",
      "         [-0.1000],\n",
      "         [-0.4000],\n",
      "         [-0.5000],\n",
      "         [-0.6000],\n",
      "         [-0.7000],\n",
      "         [-0.7000],\n",
      "         [-0.6000],\n",
      "         [-0.3000]]])\n",
      "x torch.Size([1, 9, 1])\n",
      "out.shape torch.Size([1, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([1, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0183, -0.0142, -0.0131,  0.0152]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[[ 0.3000],\n",
      "         [ 0.3000],\n",
      "         [ 0.1000],\n",
      "         [-0.1000],\n",
      "         [-0.4000],\n",
      "         [-0.7000],\n",
      "         [-0.8000],\n",
      "         [-1.0000],\n",
      "         [-0.9000]]])\n",
      "x torch.Size([1, 9, 1])\n",
      "out.shape torch.Size([1, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([1, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0183, -0.0142, -0.0131,  0.0152]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6146]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6146]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[[-0.2000],\n",
      "         [ 0.0000],\n",
      "         [ 0.1000],\n",
      "         [ 0.2000],\n",
      "         [ 0.5000],\n",
      "         [ 0.8000],\n",
      "         [ 0.9000],\n",
      "         [ 0.8000],\n",
      "         [ 0.7000]]])\n",
      "x torch.Size([1, 9, 1])\n",
      "out.shape torch.Size([1, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([1, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0183, -0.0140, -0.0131,  0.0153]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6084]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6084]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[[0.5000],\n",
      "         [0.5000],\n",
      "         [0.3000],\n",
      "         [0.1000],\n",
      "         [0.2000],\n",
      "         [0.3000],\n",
      "         [0.5000],\n",
      "         [0.5000],\n",
      "         [0.5000]]])\n",
      "x torch.Size([1, 9, 1])\n",
      "out.shape torch.Size([1, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([1, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0183, -0.0142, -0.0131,  0.0152]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6097]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6097]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[[-0.1000],\n",
      "         [-0.3000],\n",
      "         [-0.4000],\n",
      "         [-0.6000],\n",
      "         [-0.9000],\n",
      "         [-1.2000],\n",
      "         [-1.3000],\n",
      "         [-1.2000],\n",
      "         [-1.0000]]])\n",
      "x torch.Size([1, 9, 1])\n",
      "out.shape torch.Size([1, 9, 256])\n",
      "out[:, -1, :].shape torch.Size([1, 256])\n",
      "out[0:2, 0, 0:4] tensor([[-0.0183, -0.0141, -0.0131,  0.0153]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "after fc out tensor([[0.6166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "print('Predicting on test dataset')\n",
    "for batch, _ in test_dl:\n",
    "    batch = batch.permute(0, 2, 1)\n",
    "    print(batch)\n",
    "    out = model(batch.cuda())\n",
    "    print(out)\n",
    "    # y_hat = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "    test += out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d186c27e-e2df-45b6-94bd-c0ae13540b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6142611503601074],\n",
       " [0.6146284937858582],\n",
       " [0.6083777546882629],\n",
       " [0.6096799969673157],\n",
       " [0.6166022419929504]]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1761be3c-065a-48b3-b356-5fb1c1044547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[134.5704460144043,\n",
       " 134.58513975143433,\n",
       " 134.33511018753052,\n",
       " 134.38719987869263,\n",
       " 134.66408967971802]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(y[0] * (150 - 110) + 110) for y in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8fbd2590-f17d-450a-bb51-3ed37097f1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    0.425\n",
       "56    0.400\n",
       "57    0.425\n",
       "58    0.500\n",
       "59    0.425\n",
       "Name: doy_cherry_peak_bloom, dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a09115a3-5d90-4bb7-afd8-04f08daed776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    127.0\n",
       "56    126.0\n",
       "57    127.0\n",
       "58    130.0\n",
       "59    127.0\n",
       "Name: doy_cherry_peak_bloom, dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tst * (150 - 110) + 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "09cd1d20-092d-4a7e-8471-6b411fbaa338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    0.425\n",
       "56    0.400\n",
       "57    0.425\n",
       "58    0.500\n",
       "59    0.425\n",
       "Name: doy_cherry_peak_bloom, dtype: float64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ef2056-348d-446a-8ed0-e7590caa30f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RNN try, failed ********** ********** **********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aecc262-16ef-4699-99fa-68e11bb8addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        \n",
    "        self.Wx = torch.randn(n_inputs, n_neurons) # n_inputs X n_neurons\n",
    "        self.Wy = torch.randn(n_neurons, n_neurons) # n_neurons X n_neurons\n",
    "        \n",
    "        self.b = torch.zeros(1, n_neurons) # 1 X n_neurons\n",
    "    \n",
    "    def forward(self, X0, X1):\n",
    "        self.Y0 = torch.tanh(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons\n",
    "        \n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) +\n",
    "                            torch.mm(X1, self.Wx) + self.b) # batch_size X n_neurons\n",
    "        \n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdef04-51d1-4e42-a2c5-d04b4f3909c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 3 # number of features in input\n",
    "N_NEURONS = 5 # number of units in layer\n",
    "\n",
    "X0_batch = torch.tensor([[0,1,2], [3,4,5], \n",
    "                         [6,7,8], [9,0,1]],\n",
    "                        dtype = torch.float) #t=0 => 4 X 3\n",
    "\n",
    "X1_batch = torch.tensor([[9,8,7], [0,0,0], \n",
    "                         [6,5,4], [3,2,1]],\n",
    "                        dtype = torch.float) #t=1 => 4 X 3\n",
    "\n",
    "model = BasicRNN(N_INPUT, N_NEURONS)\n",
    "\n",
    "Y0_val, Y1_val = model(X0_batch, X1_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaf9c5-58d9-40af-a012-af5498798750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9b20b-9e76-46c1-8d3d-76109a0f802a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
